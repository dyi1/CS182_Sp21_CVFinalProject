{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "import pathlib\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "from model import ValFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)\n",
    "for param in resnet18.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "resnet18.fc = nn.Linear(512, 200)\n",
    "# resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovered 120000 images\n"
     ]
    }
   ],
   "source": [
    "data_dir = pathlib.Path('./data/tiny-imagenet-200')\n",
    "image_count = len(list(data_dir.glob('**/*.JPEG')))\n",
    "CLASS_NAMES = np.array([item.name for item in (data_dir / 'train').glob('*')])\n",
    "print('Discovered {} images'.format(image_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(WindowsPath('data/tiny-imagenet-200/val'), Compose(\n",
      "    Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.4805, 0.4483, 0.3978), std=(0.4665833258915282, 0.46238512086787564, 0.46216880033165375))\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "# Create the training data generator\n",
    "batch_size = 64\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4805, 0.4483, 0.3978), tuple(np.sqrt((0.2177, 0.2138, 0.2136)))),\n",
    "])\n",
    "train_set = torchvision.datasets.ImageFolder(data_dir / 'train', data_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
    "                                           shuffle=True, num_workers=4, pin_memory=True)\n",
    "    \n",
    "\n",
    "val_set = ValFolder(CLASS_NAMES, data_dir / 'val', data_transforms)\n",
    "# val_set.CLASS_NAMES = CLASS_NAMES\n",
    "val_set.__getitem__(1)\n",
    "# train_set.__getitem__(1)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = 0\n",
    "# std = 0\n",
    "\n",
    "# for images, _ in train_loader:\n",
    "#     batch_samples = images.size(0) # batch size (the last batch can have smaller size!)\n",
    "#     images = images.view(batch_samples, images.size(1), -1)\n",
    "#     mean += images.mean(2).sum(0)\n",
    "#     std += images.std(2).sum(0)\n",
    "    \n",
    "# mean /= len(train_loader.dataset)\n",
    "# std /= len(train_loader.dataset)\n",
    "# print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 0.00%: 0.000. Loss: 5.5833740234375\n",
      "training 0.06%: 0.000. Loss: 5.529906272888184\n",
      "training 0.13%: 0.000. Loss: 5.797832012176514\n",
      "training 0.19%: 0.008. Loss: 5.415841102600098\n",
      "training 0.26%: 0.006. Loss: 5.693954944610596\n",
      "training 0.32%: 0.005. Loss: 5.7727861404418945\n",
      "training 0.38%: 0.004. Loss: 5.966975212097168\n",
      "training 0.45%: 0.004. Loss: 5.726922035217285\n",
      "training 0.51%: 0.003. Loss: 5.577348232269287\n",
      "training 0.58%: 0.005. Loss: 5.776706218719482\n",
      "training 0.64%: 0.006. Loss: 5.660829067230225\n",
      "training 0.70%: 0.008. Loss: 5.510198593139648\n",
      "training 0.77%: 0.007. Loss: 5.632909297943115\n",
      "training 0.83%: 0.009. Loss: 5.626048564910889\n",
      "training 0.90%: 0.010. Loss: 5.385754585266113\n",
      "training 0.96%: 0.012. Loss: 5.386429786682129\n",
      "training 1.02%: 0.014. Loss: 5.105767726898193\n",
      "training 1.09%: 0.014. Loss: 5.3660383224487305\n",
      "training 1.15%: 0.014. Loss: 5.363563537597656\n",
      "training 1.22%: 0.015. Loss: 5.285946369171143\n",
      "training 1.28%: 0.014. Loss: 5.186009407043457\n",
      "training 1.34%: 0.014. Loss: 5.133552551269531\n",
      "training 1.41%: 0.015. Loss: 5.278435707092285\n",
      "training 1.47%: 0.014. Loss: 5.367921829223633\n",
      "training 1.54%: 0.015. Loss: 5.361800670623779\n",
      "training 1.60%: 0.015. Loss: 5.485626220703125\n",
      "training 1.66%: 0.015. Loss: 5.196911811828613\n",
      "training 1.73%: 0.016. Loss: 5.263947010040283\n",
      "training 1.79%: 0.017. Loss: 4.932797908782959\n",
      "training 1.86%: 0.018. Loss: 5.170562267303467\n",
      "training 1.92%: 0.020. Loss: 5.031740665435791\n",
      "training 1.98%: 0.021. Loss: 5.192206382751465\n",
      "training 2.05%: 0.021. Loss: 5.084172248840332\n",
      "training 2.11%: 0.022. Loss: 5.060750484466553\n",
      "training 2.18%: 0.023. Loss: 5.207333087921143\n",
      "training 2.24%: 0.023. Loss: 5.117033958435059\n",
      "training 2.30%: 0.022. Loss: 5.149463653564453\n",
      "training 2.37%: 0.022. Loss: 4.9971818923950195\n",
      "training 2.43%: 0.023. Loss: 4.938457489013672\n",
      "training 2.50%: 0.024. Loss: 4.910212993621826\n",
      "training 2.56%: 0.026. Loss: 4.722465515136719\n",
      "training 2.62%: 0.027. Loss: 4.716803550720215\n",
      "training 2.69%: 0.028. Loss: 4.816335678100586\n",
      "training 2.75%: 0.028. Loss: 4.890078067779541\n",
      "training 2.82%: 0.029. Loss: 5.014616012573242\n",
      "training 2.88%: 0.029. Loss: 4.8799614906311035\n",
      "training 2.94%: 0.029. Loss: 4.722358226776123\n",
      "training 3.01%: 0.030. Loss: 4.826568603515625\n",
      "training 3.07%: 0.030. Loss: 4.8062944412231445\n",
      "training 3.13%: 0.032. Loss: 4.724625587463379\n",
      "training 3.20%: 0.033. Loss: 4.487503528594971\n",
      "training 3.26%: 0.035. Loss: 4.699942588806152\n",
      "training 3.33%: 0.037. Loss: 4.408734321594238\n",
      "training 3.39%: 0.038. Loss: 4.605531692504883\n",
      "training 3.45%: 0.038. Loss: 4.7547831535339355\n",
      "training 3.52%: 0.040. Loss: 4.6922736167907715\n",
      "training 3.58%: 0.040. Loss: 4.822023868560791\n",
      "training 3.65%: 0.040. Loss: 4.841391086578369\n",
      "training 3.71%: 0.040. Loss: 4.70702600479126\n",
      "training 3.77%: 0.041. Loss: 4.669501781463623\n",
      "training 3.84%: 0.041. Loss: 4.460474014282227\n",
      "training 3.90%: 0.043. Loss: 4.429540157318115\n",
      "training 3.97%: 0.046. Loss: 4.456418037414551\n",
      "training 4.03%: 0.047. Loss: 4.619631767272949\n",
      "training 4.09%: 0.050. Loss: 4.499640941619873\n",
      "training 4.16%: 0.052. Loss: 4.407294273376465\n",
      "training 4.22%: 0.053. Loss: 4.433267593383789\n",
      "training 4.29%: 0.055. Loss: 4.561831474304199\n",
      "training 4.35%: 0.056. Loss: 4.504552364349365\n",
      "training 4.41%: 0.057. Loss: 4.439764976501465\n",
      "training 4.48%: 0.058. Loss: 4.403382301330566\n",
      "training 4.54%: 0.058. Loss: 4.625159740447998\n",
      "training 4.61%: 0.059. Loss: 4.367932319641113\n",
      "training 4.67%: 0.060. Loss: 4.340979099273682\n",
      "training 4.73%: 0.061. Loss: 4.471167087554932\n",
      "training 4.80%: 0.061. Loss: 4.526102066040039\n",
      "training 4.86%: 0.063. Loss: 4.350589752197266\n",
      "training 4.93%: 0.065. Loss: 4.176824569702148\n",
      "training 4.99%: 0.066. Loss: 4.362929821014404\n",
      "training 5.05%: 0.067. Loss: 4.502430438995361\n",
      "training 5.12%: 0.069. Loss: 4.011861324310303\n",
      "training 5.18%: 0.070. Loss: 4.319903373718262\n",
      "training 5.25%: 0.072. Loss: 4.238492965698242\n",
      "training 5.31%: 0.072. Loss: 4.209868907928467\n",
      "training 5.37%: 0.073. Loss: 4.297731876373291\n",
      "training 5.44%: 0.075. Loss: 4.193084716796875\n",
      "training 5.50%: 0.077. Loss: 4.07275915145874\n",
      "training 5.57%: 0.078. Loss: 4.2800493240356445\n",
      "training 5.63%: 0.079. Loss: 4.138646125793457\n",
      "training 5.69%: 0.081. Loss: 4.211172580718994\n",
      "training 5.76%: 0.082. Loss: 4.1607866287231445\n",
      "training 5.82%: 0.083. Loss: 4.164398193359375\n",
      "training 5.89%: 0.083. Loss: 4.256137371063232\n",
      "training 5.95%: 0.084. Loss: 4.292288780212402\n",
      "training 6.01%: 0.085. Loss: 4.128105640411377\n",
      "training 6.08%: 0.086. Loss: 4.003974437713623\n",
      "training 6.14%: 0.087. Loss: 4.298825263977051\n",
      "training 6.21%: 0.088. Loss: 3.9960267543792725\n",
      "training 6.27%: 0.088. Loss: 4.3256306648254395\n",
      "training 6.33%: 0.090. Loss: 4.046087265014648\n",
      "training 6.40%: 0.091. Loss: 4.265913963317871\n",
      "training 6.46%: 0.092. Loss: 4.099527835845947\n",
      "training 6.53%: 0.093. Loss: 3.8600878715515137\n",
      "training 6.59%: 0.095. Loss: 3.8318803310394287\n",
      "training 6.65%: 0.096. Loss: 3.9238972663879395\n",
      "training 6.72%: 0.097. Loss: 3.959890604019165\n",
      "training 6.78%: 0.098. Loss: 4.075229167938232\n",
      "training 6.85%: 0.100. Loss: 4.013945579528809\n",
      "training 6.91%: 0.101. Loss: 3.813863754272461\n",
      "training 6.97%: 0.102. Loss: 4.188097953796387\n",
      "training 7.04%: 0.102. Loss: 4.039645195007324\n",
      "training 7.10%: 0.104. Loss: 3.9789857864379883\n",
      "training 7.17%: 0.105. Loss: 3.8871636390686035\n",
      "training 7.23%: 0.105. Loss: 4.278992176055908\n",
      "training 7.29%: 0.106. Loss: 3.9486162662506104\n",
      "training 7.36%: 0.107. Loss: 4.175684452056885\n",
      "training 7.42%: 0.109. Loss: 4.010976314544678\n",
      "training 7.49%: 0.110. Loss: 3.9363558292388916\n",
      "training 7.55%: 0.111. Loss: 3.9491372108459473\n",
      "training 7.61%: 0.112. Loss: 3.9161930084228516\n",
      "training 7.68%: 0.112. Loss: 3.7468152046203613\n",
      "training 7.74%: 0.113. Loss: 3.8389575481414795\n",
      "training 7.81%: 0.115. Loss: 3.7982726097106934\n",
      "training 7.87%: 0.115. Loss: 3.9699807167053223\n",
      "training 7.93%: 0.117. Loss: 3.7202961444854736\n",
      "training 8.00%: 0.119. Loss: 3.60117769241333\n",
      "training 8.06%: 0.120. Loss: 3.665797710418701\n",
      "training 8.13%: 0.120. Loss: 3.8012619018554688\n",
      "training 8.19%: 0.122. Loss: 3.752919912338257\n",
      "training 8.25%: 0.123. Loss: 3.7994487285614014\n",
      "training 8.32%: 0.124. Loss: 3.6646769046783447\n",
      "training 8.38%: 0.125. Loss: 3.536036252975464\n",
      "training 8.45%: 0.128. Loss: 3.4075450897216797\n",
      "training 8.51%: 0.129. Loss: 3.4918837547302246\n",
      "training 8.57%: 0.130. Loss: 3.6057400703430176\n",
      "training 8.64%: 0.131. Loss: 3.8209547996520996\n",
      "training 8.70%: 0.133. Loss: 3.641580820083618\n",
      "training 8.77%: 0.134. Loss: 3.478393316268921\n",
      "training 8.83%: 0.135. Loss: 3.7594282627105713\n",
      "training 8.89%: 0.136. Loss: 3.430072784423828\n",
      "training 8.96%: 0.137. Loss: 3.886878252029419\n",
      "training 9.02%: 0.138. Loss: 3.6592445373535156\n",
      "training 9.09%: 0.139. Loss: 3.4907164573669434\n",
      "training 9.15%: 0.140. Loss: 3.742663860321045\n",
      "training 9.21%: 0.141. Loss: 3.769592761993408\n",
      "training 9.28%: 0.141. Loss: 3.4901318550109863\n",
      "training 9.34%: 0.142. Loss: 3.8600196838378906\n",
      "training 9.40%: 0.144. Loss: 3.1958513259887695\n",
      "training 9.47%: 0.145. Loss: 3.6371893882751465\n",
      "training 9.53%: 0.146. Loss: 3.3599483966827393\n",
      "training 9.60%: 0.147. Loss: 3.756639003753662\n",
      "training 9.66%: 0.148. Loss: 3.5704870223999023\n",
      "training 9.72%: 0.149. Loss: 3.4462778568267822\n",
      "training 9.79%: 0.150. Loss: 3.684821844100952\n",
      "training 9.85%: 0.151. Loss: 3.5148894786834717\n",
      "training 9.92%: 0.151. Loss: 3.5872251987457275\n",
      "training 9.98%: 0.152. Loss: 3.5230307579040527\n",
      "training 10.04%: 0.153. Loss: 3.436441659927368\n",
      "training 10.11%: 0.154. Loss: 3.3880584239959717\n",
      "training 10.17%: 0.155. Loss: 3.4643807411193848\n",
      "training 10.24%: 0.157. Loss: 3.4382805824279785\n",
      "training 10.30%: 0.158. Loss: 3.513637065887451\n",
      "training 10.36%: 0.157. Loss: 3.824673891067505\n",
      "training 10.43%: 0.158. Loss: 3.5420234203338623\n",
      "training 10.49%: 0.159. Loss: 3.3413162231445312\n",
      "training 10.56%: 0.160. Loss: 3.3405983448028564\n",
      "training 10.62%: 0.161. Loss: 3.211336851119995\n",
      "training 10.68%: 0.162. Loss: 3.490446090698242\n",
      "training 10.75%: 0.163. Loss: 3.3811967372894287\n",
      "training 10.81%: 0.164. Loss: 3.3540358543395996\n",
      "training 10.88%: 0.165. Loss: 3.332489252090454\n",
      "training 10.94%: 0.166. Loss: 3.1856942176818848\n",
      "training 11.00%: 0.167. Loss: 3.3292205333709717\n",
      "training 11.07%: 0.167. Loss: 3.8615474700927734\n",
      "training 11.13%: 0.168. Loss: 3.610931873321533\n",
      "training 11.20%: 0.169. Loss: 3.446850061416626\n",
      "training 11.26%: 0.170. Loss: 3.0554239749908447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 11.32%: 0.171. Loss: 3.263794183731079\n",
      "training 11.39%: 0.172. Loss: 3.3495986461639404\n",
      "training 11.45%: 0.173. Loss: 3.3387656211853027\n",
      "training 11.52%: 0.174. Loss: 3.182588815689087\n",
      "training 11.58%: 0.174. Loss: 3.6466262340545654\n",
      "training 11.64%: 0.174. Loss: 3.41721773147583\n",
      "training 11.71%: 0.175. Loss: 3.4072773456573486\n",
      "training 11.77%: 0.175. Loss: 3.536175012588501\n",
      "training 11.84%: 0.176. Loss: 3.2890408039093018\n",
      "training 11.90%: 0.176. Loss: 3.392052173614502\n",
      "training 11.96%: 0.177. Loss: 3.3372342586517334\n",
      "training 12.03%: 0.178. Loss: 2.981855630874634\n",
      "training 12.09%: 0.179. Loss: 3.222072124481201\n",
      "training 12.16%: 0.180. Loss: 3.1079325675964355\n",
      "training 12.22%: 0.181. Loss: 3.275266647338867\n",
      "training 12.28%: 0.182. Loss: 3.212587356567383\n",
      "training 12.35%: 0.183. Loss: 3.258911371231079\n",
      "training 12.41%: 0.184. Loss: 3.080962896347046\n",
      "training 12.48%: 0.185. Loss: 3.4339752197265625\n",
      "training 12.54%: 0.186. Loss: 3.120936632156372\n",
      "training 12.60%: 0.186. Loss: 3.1575655937194824\n",
      "training 12.67%: 0.187. Loss: 3.1767096519470215\n",
      "training 12.73%: 0.187. Loss: 3.1500771045684814\n",
      "training 12.80%: 0.188. Loss: 3.129892110824585\n",
      "training 12.86%: 0.189. Loss: 3.395984411239624\n",
      "training 12.92%: 0.190. Loss: 3.258971691131592\n",
      "training 12.99%: 0.190. Loss: 3.232693910598755\n",
      "training 13.05%: 0.191. Loss: 3.179230213165283\n",
      "training 13.12%: 0.191. Loss: 3.35184907913208\n",
      "training 13.18%: 0.192. Loss: 3.0486576557159424\n",
      "training 13.24%: 0.193. Loss: 3.2177581787109375\n",
      "training 13.31%: 0.194. Loss: 2.9901716709136963\n",
      "training 13.37%: 0.194. Loss: 3.240236759185791\n",
      "training 13.44%: 0.195. Loss: 3.1705312728881836\n",
      "training 13.50%: 0.196. Loss: 3.0964560508728027\n",
      "training 13.56%: 0.197. Loss: 3.0268044471740723\n",
      "training 13.63%: 0.198. Loss: 3.187938928604126\n",
      "training 13.69%: 0.199. Loss: 3.1330184936523438\n",
      "training 13.76%: 0.200. Loss: 3.0178236961364746\n",
      "training 13.82%: 0.200. Loss: 3.259812116622925\n",
      "training 13.88%: 0.201. Loss: 3.005209445953369\n",
      "training 13.95%: 0.202. Loss: 3.3140549659729004\n",
      "training 14.01%: 0.203. Loss: 2.954143762588501\n",
      "training 14.08%: 0.203. Loss: 3.3166346549987793\n",
      "training 14.14%: 0.204. Loss: 2.970677137374878\n",
      "training 14.20%: 0.205. Loss: 2.8577046394348145\n",
      "training 14.27%: 0.206. Loss: 2.936485528945923\n",
      "training 14.33%: 0.207. Loss: 3.0766961574554443\n",
      "training 14.40%: 0.208. Loss: 3.229321241378784\n",
      "training 14.46%: 0.208. Loss: 2.9090354442596436\n",
      "training 14.52%: 0.209. Loss: 2.9070582389831543\n",
      "training 14.59%: 0.209. Loss: 3.313657283782959\n",
      "training 14.65%: 0.210. Loss: 2.9143810272216797\n",
      "training 14.72%: 0.211. Loss: 2.893847942352295\n",
      "training 14.78%: 0.212. Loss: 3.162207841873169\n",
      "training 14.84%: 0.212. Loss: 2.9332375526428223\n",
      "training 14.91%: 0.213. Loss: 3.1921603679656982\n",
      "training 14.97%: 0.214. Loss: 3.0922484397888184\n",
      "training 15.04%: 0.214. Loss: 3.0466179847717285\n",
      "training 15.10%: 0.215. Loss: 3.156440496444702\n",
      "training 15.16%: 0.216. Loss: 2.974311590194702\n",
      "training 15.23%: 0.216. Loss: 2.777526617050171\n",
      "training 15.29%: 0.217. Loss: 3.3549001216888428\n",
      "training 15.36%: 0.217. Loss: 2.9014534950256348\n",
      "training 15.42%: 0.218. Loss: 2.786656141281128\n",
      "training 15.48%: 0.219. Loss: 2.9777348041534424\n",
      "training 15.55%: 0.220. Loss: 3.1219654083251953\n",
      "training 15.61%: 0.220. Loss: 3.045339822769165\n",
      "training 15.67%: 0.221. Loss: 2.7985763549804688\n",
      "training 15.74%: 0.222. Loss: 2.813927173614502\n",
      "training 15.80%: 0.222. Loss: 3.0938286781311035\n",
      "training 15.87%: 0.223. Loss: 2.8976800441741943\n",
      "training 15.93%: 0.224. Loss: 2.6850948333740234\n",
      "training 15.99%: 0.225. Loss: 2.871062755584717\n",
      "training 16.06%: 0.225. Loss: 2.973071336746216\n",
      "training 16.12%: 0.226. Loss: 3.092041492462158\n",
      "training 16.19%: 0.226. Loss: 2.927513360977173\n",
      "training 16.25%: 0.227. Loss: 2.894869327545166\n",
      "training 16.31%: 0.227. Loss: 3.206148147583008\n",
      "training 16.38%: 0.228. Loss: 3.250903367996216\n",
      "training 16.44%: 0.229. Loss: 2.7885406017303467\n",
      "training 16.51%: 0.229. Loss: 3.0577845573425293\n",
      "training 16.57%: 0.230. Loss: 3.0056674480438232\n",
      "training 16.63%: 0.230. Loss: 2.8619534969329834\n",
      "training 16.70%: 0.231. Loss: 3.0475728511810303\n",
      "training 16.76%: 0.232. Loss: 2.9736857414245605\n",
      "training 16.83%: 0.232. Loss: 2.732553243637085\n",
      "training 16.89%: 0.233. Loss: 2.9723317623138428\n",
      "training 16.95%: 0.233. Loss: 3.0847246646881104\n",
      "training 17.02%: 0.234. Loss: 2.8388378620147705\n",
      "training 17.08%: 0.234. Loss: 2.709125518798828\n",
      "training 17.15%: 0.235. Loss: 2.6305291652679443\n",
      "training 17.21%: 0.236. Loss: 2.9121246337890625\n",
      "training 17.27%: 0.237. Loss: 2.845740795135498\n",
      "training 17.34%: 0.237. Loss: 3.008444309234619\n",
      "training 17.40%: 0.238. Loss: 3.0711798667907715\n",
      "training 17.47%: 0.238. Loss: 3.07494854927063\n",
      "training 17.53%: 0.239. Loss: 2.822223663330078\n",
      "training 17.59%: 0.239. Loss: 2.940284013748169\n",
      "training 17.66%: 0.240. Loss: 2.88044810295105\n",
      "training 17.72%: 0.241. Loss: 2.7259488105773926\n",
      "training 17.79%: 0.241. Loss: 2.6252939701080322\n",
      "training 17.85%: 0.242. Loss: 2.8060355186462402\n",
      "training 17.91%: 0.242. Loss: 2.929168224334717\n",
      "training 17.98%: 0.243. Loss: 2.895313024520874\n",
      "training 18.04%: 0.244. Loss: 2.5837669372558594\n",
      "training 18.11%: 0.244. Loss: 2.832227945327759\n",
      "training 18.17%: 0.245. Loss: 2.570556640625\n",
      "training 18.23%: 0.246. Loss: 2.871635913848877\n",
      "training 18.30%: 0.246. Loss: 2.7477855682373047\n",
      "training 18.36%: 0.246. Loss: 2.8914239406585693\n",
      "training 18.43%: 0.247. Loss: 2.8442330360412598\n",
      "training 18.49%: 0.247. Loss: 2.887040615081787\n",
      "training 18.55%: 0.248. Loss: 2.785176992416382\n",
      "training 18.62%: 0.249. Loss: 2.6314122676849365\n",
      "training 18.68%: 0.249. Loss: 2.8178763389587402\n",
      "training 18.75%: 0.250. Loss: 2.613997220993042\n",
      "training 18.81%: 0.250. Loss: 2.7591941356658936\n",
      "training 18.87%: 0.251. Loss: 3.057419776916504\n",
      "training 18.94%: 0.251. Loss: 2.7939517498016357\n",
      "training 19.00%: 0.252. Loss: 2.6958813667297363\n",
      "training 19.07%: 0.252. Loss: 2.6528332233428955\n",
      "training 19.13%: 0.253. Loss: 3.1025631427764893\n",
      "training 19.19%: 0.253. Loss: 3.1009559631347656\n",
      "training 19.26%: 0.254. Loss: 2.4365766048431396\n",
      "training 19.32%: 0.254. Loss: 2.686253309249878\n",
      "training 19.39%: 0.255. Loss: 2.860339879989624\n",
      "training 19.45%: 0.256. Loss: 2.8317298889160156\n",
      "training 19.51%: 0.256. Loss: 2.5754220485687256\n",
      "training 19.58%: 0.256. Loss: 2.9417126178741455\n",
      "training 19.64%: 0.257. Loss: 2.939929485321045\n",
      "training 19.71%: 0.257. Loss: 2.7521965503692627\n",
      "training 19.77%: 0.258. Loss: 2.6689095497131348\n",
      "training 19.83%: 0.259. Loss: 3.113590717315674\n",
      "training 19.90%: 0.259. Loss: 2.8678550720214844\n",
      "training 19.96%: 0.259. Loss: 2.8532705307006836\n",
      "training 20.03%: 0.260. Loss: 2.766599178314209\n",
      "training 20.09%: 0.260. Loss: 2.5480306148529053\n",
      "training 20.15%: 0.261. Loss: 2.4556548595428467\n",
      "training 20.22%: 0.261. Loss: 2.4402146339416504\n",
      "training 20.28%: 0.261. Loss: 2.8600223064422607\n",
      "training 20.35%: 0.262. Loss: 2.7022931575775146\n",
      "training 20.41%: 0.262. Loss: 2.8020827770233154\n",
      "training 20.47%: 0.263. Loss: 2.9359405040740967\n",
      "training 20.54%: 0.263. Loss: 2.8336751461029053\n",
      "training 20.60%: 0.263. Loss: 2.6792471408843994\n",
      "training 20.67%: 0.264. Loss: 2.3247649669647217\n",
      "training 20.73%: 0.265. Loss: 2.478639841079712\n",
      "training 20.79%: 0.266. Loss: 2.3788962364196777\n",
      "training 20.86%: 0.266. Loss: 2.7520053386688232\n",
      "training 20.92%: 0.267. Loss: 2.3984365463256836\n",
      "training 20.99%: 0.267. Loss: 2.904536724090576\n",
      "training 21.05%: 0.268. Loss: 2.414912223815918\n",
      "training 21.11%: 0.268. Loss: 2.610700845718384\n",
      "training 21.18%: 0.269. Loss: 2.2845349311828613\n",
      "training 21.24%: 0.270. Loss: 2.5618948936462402\n",
      "training 21.31%: 0.270. Loss: 2.5471513271331787\n",
      "training 21.37%: 0.271. Loss: 2.5024003982543945\n",
      "training 21.43%: 0.271. Loss: 3.001343250274658\n",
      "training 21.50%: 0.272. Loss: 2.64970064163208\n",
      "training 21.56%: 0.272. Loss: 2.9142353534698486\n",
      "training 21.63%: 0.272. Loss: 2.847238063812256\n",
      "training 21.69%: 0.273. Loss: 2.4945716857910156\n",
      "training 21.75%: 0.273. Loss: 2.864250421524048\n",
      "training 21.82%: 0.274. Loss: 2.6730892658233643\n",
      "training 21.88%: 0.274. Loss: 2.784426212310791\n",
      "training 21.94%: 0.275. Loss: 2.524702787399292\n",
      "training 22.01%: 0.275. Loss: 2.605320930480957\n",
      "training 22.07%: 0.276. Loss: 2.60715913772583\n",
      "training 22.14%: 0.276. Loss: 2.592481851577759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 22.20%: 0.277. Loss: 2.3828201293945312\n",
      "training 22.26%: 0.278. Loss: 2.430624008178711\n",
      "training 22.33%: 0.278. Loss: 2.5792582035064697\n",
      "training 22.39%: 0.279. Loss: 2.724910259246826\n",
      "training 22.46%: 0.279. Loss: 2.5450711250305176\n",
      "training 22.52%: 0.279. Loss: 3.0616822242736816\n",
      "training 22.58%: 0.280. Loss: 2.5092720985412598\n",
      "training 22.65%: 0.280. Loss: 2.624560594558716\n",
      "training 22.71%: 0.281. Loss: 2.614659547805786\n",
      "training 22.78%: 0.281. Loss: 2.631394147872925\n",
      "training 22.84%: 0.282. Loss: 2.4203567504882812\n",
      "training 22.90%: 0.282. Loss: 2.514209270477295\n",
      "training 22.97%: 0.282. Loss: 2.861593246459961\n",
      "training 23.03%: 0.283. Loss: 2.324143409729004\n",
      "training 23.10%: 0.283. Loss: 2.4298670291900635\n",
      "training 23.16%: 0.284. Loss: 2.2898452281951904\n",
      "training 23.22%: 0.285. Loss: 2.627523422241211\n",
      "training 23.29%: 0.285. Loss: 2.327603816986084\n",
      "training 23.35%: 0.285. Loss: 2.545067310333252\n",
      "training 23.42%: 0.286. Loss: 2.6459462642669678\n",
      "training 23.48%: 0.286. Loss: 2.7916994094848633\n",
      "training 23.54%: 0.287. Loss: 2.5159037113189697\n",
      "training 23.61%: 0.287. Loss: 2.2413196563720703\n",
      "training 23.67%: 0.288. Loss: 2.1986873149871826\n",
      "training 23.74%: 0.289. Loss: 2.604189872741699\n",
      "training 23.80%: 0.289. Loss: 2.6166939735412598\n",
      "training 23.86%: 0.290. Loss: 2.5094892978668213\n",
      "training 23.93%: 0.290. Loss: 2.392186403274536\n",
      "training 23.99%: 0.290. Loss: 2.688600540161133\n",
      "training 24.06%: 0.291. Loss: 2.3454551696777344\n",
      "training 24.12%: 0.291. Loss: 2.541471004486084\n",
      "training 24.18%: 0.292. Loss: 2.404999017715454\n",
      "training 24.25%: 0.293. Loss: 2.2881929874420166\n",
      "training 24.31%: 0.293. Loss: 2.593899965286255\n",
      "training 24.38%: 0.293. Loss: 2.4965155124664307\n",
      "training 24.44%: 0.294. Loss: 2.3254008293151855\n",
      "training 24.50%: 0.295. Loss: 2.415745258331299\n",
      "training 24.57%: 0.295. Loss: 2.852808713912964\n",
      "training 24.63%: 0.295. Loss: 2.9187145233154297\n",
      "training 24.70%: 0.295. Loss: 2.4572014808654785\n",
      "training 24.76%: 0.296. Loss: 2.6986522674560547\n",
      "training 24.82%: 0.296. Loss: 2.5018551349639893\n",
      "training 24.89%: 0.297. Loss: 2.5905871391296387\n",
      "training 24.95%: 0.297. Loss: 2.3521828651428223\n",
      "training 25.02%: 0.298. Loss: 2.2063090801239014\n",
      "training 25.08%: 0.298. Loss: 2.431142807006836\n",
      "training 25.14%: 0.298. Loss: 2.45320987701416\n",
      "training 25.21%: 0.299. Loss: 2.560823678970337\n",
      "training 25.27%: 0.299. Loss: 2.4597487449645996\n",
      "training 25.34%: 0.300. Loss: 2.208770513534546\n",
      "training 25.40%: 0.300. Loss: 2.6044960021972656\n",
      "training 25.46%: 0.301. Loss: 2.4625351428985596\n",
      "training 25.53%: 0.301. Loss: 2.4911701679229736\n",
      "training 25.59%: 0.301. Loss: 2.617225170135498\n",
      "training 25.66%: 0.302. Loss: 2.1623475551605225\n",
      "training 25.72%: 0.302. Loss: 2.292839288711548\n",
      "training 25.78%: 0.303. Loss: 2.6297860145568848\n",
      "training 25.85%: 0.303. Loss: 2.8325693607330322\n",
      "training 25.91%: 0.303. Loss: 2.4179623126983643\n",
      "training 25.98%: 0.304. Loss: 2.437194347381592\n",
      "training 26.04%: 0.304. Loss: 2.035534143447876\n",
      "training 26.10%: 0.304. Loss: 2.703653573989868\n",
      "training 26.17%: 0.305. Loss: 2.3657491207122803\n",
      "training 26.23%: 0.305. Loss: 2.611429214477539\n",
      "training 26.30%: 0.306. Loss: 2.4927806854248047\n",
      "training 26.36%: 0.306. Loss: 2.753772020339966\n",
      "training 26.42%: 0.306. Loss: 2.502230167388916\n",
      "training 26.49%: 0.306. Loss: 2.2325379848480225\n",
      "training 26.55%: 0.307. Loss: 2.420947551727295\n",
      "training 26.62%: 0.307. Loss: 2.525529146194458\n",
      "training 26.68%: 0.307. Loss: 2.319427728652954\n",
      "training 26.74%: 0.308. Loss: 2.550104856491089\n",
      "training 26.81%: 0.308. Loss: 2.6869115829467773\n",
      "training 26.87%: 0.308. Loss: 2.370706081390381\n",
      "training 26.94%: 0.308. Loss: 2.7044503688812256\n",
      "training 27.00%: 0.309. Loss: 2.126311779022217\n",
      "training 27.06%: 0.309. Loss: 2.7059359550476074\n",
      "training 27.13%: 0.309. Loss: 2.725046396255493\n",
      "training 27.19%: 0.310. Loss: 2.6000895500183105\n",
      "training 27.26%: 0.310. Loss: 2.442082643508911\n",
      "training 27.32%: 0.310. Loss: 2.73606276512146\n",
      "training 27.38%: 0.311. Loss: 2.3632898330688477\n",
      "training 27.45%: 0.311. Loss: 2.425537586212158\n",
      "training 27.51%: 0.311. Loss: 2.4145641326904297\n",
      "training 27.58%: 0.312. Loss: 2.2716004848480225\n",
      "training 27.64%: 0.312. Loss: 2.5737192630767822\n",
      "training 27.70%: 0.312. Loss: 2.3852944374084473\n",
      "training 27.77%: 0.312. Loss: 2.8286850452423096\n",
      "training 27.83%: 0.313. Loss: 2.293264389038086\n",
      "training 27.90%: 0.313. Loss: 2.576287269592285\n",
      "training 27.96%: 0.313. Loss: 2.357083797454834\n",
      "training 28.02%: 0.314. Loss: 2.295311212539673\n",
      "training 28.09%: 0.314. Loss: 2.4004273414611816\n",
      "training 28.15%: 0.314. Loss: 2.6023850440979004\n",
      "training 28.21%: 0.315. Loss: 2.6919169425964355\n",
      "training 28.28%: 0.315. Loss: 2.5447611808776855\n",
      "training 28.34%: 0.315. Loss: 2.76708984375\n",
      "training 28.41%: 0.315. Loss: 2.455291271209717\n",
      "training 28.47%: 0.316. Loss: 2.40036678314209\n",
      "training 28.53%: 0.316. Loss: 2.4515163898468018\n",
      "training 28.60%: 0.316. Loss: 2.3250129222869873\n",
      "training 28.66%: 0.317. Loss: 2.321928024291992\n",
      "training 28.73%: 0.317. Loss: 2.28611159324646\n",
      "training 28.79%: 0.318. Loss: 2.2763712406158447\n",
      "training 28.85%: 0.318. Loss: 2.516955614089966\n",
      "training 28.92%: 0.318. Loss: 2.1555256843566895\n",
      "training 28.98%: 0.319. Loss: 2.319920539855957\n",
      "training 29.05%: 0.319. Loss: 2.067868709564209\n",
      "training 29.11%: 0.320. Loss: 2.3499197959899902\n",
      "training 29.17%: 0.320. Loss: 2.47424578666687\n",
      "training 29.24%: 0.320. Loss: 2.6130263805389404\n",
      "training 29.30%: 0.320. Loss: 2.4779841899871826\n",
      "training 29.37%: 0.321. Loss: 2.6349103450775146\n",
      "training 29.43%: 0.321. Loss: 2.171827554702759\n",
      "training 29.49%: 0.321. Loss: 2.7771317958831787\n",
      "training 29.56%: 0.322. Loss: 2.654364824295044\n",
      "training 29.62%: 0.322. Loss: 2.238090753555298\n",
      "training 29.69%: 0.323. Loss: 2.265606164932251\n",
      "training 29.75%: 0.323. Loss: 2.055387258529663\n",
      "training 29.81%: 0.324. Loss: 2.041480541229248\n",
      "training 29.88%: 0.324. Loss: 2.521395444869995\n",
      "training 29.94%: 0.324. Loss: 2.396209716796875\n",
      "training 30.01%: 0.324. Loss: 2.555828809738159\n",
      "training 30.07%: 0.325. Loss: 2.5177414417266846\n",
      "training 30.13%: 0.325. Loss: 2.4376187324523926\n",
      "training 30.20%: 0.325. Loss: 2.2638349533081055\n",
      "training 30.26%: 0.326. Loss: 2.3083512783050537\n",
      "training 30.33%: 0.326. Loss: 2.2158942222595215\n",
      "training 30.39%: 0.326. Loss: 2.3022689819335938\n",
      "training 30.45%: 0.327. Loss: 2.3706085681915283\n",
      "training 30.52%: 0.327. Loss: 2.4868810176849365\n",
      "training 30.58%: 0.327. Loss: 2.195631980895996\n",
      "training 30.65%: 0.327. Loss: 2.332869291305542\n",
      "training 30.71%: 0.328. Loss: 2.1641571521759033\n",
      "training 30.77%: 0.328. Loss: 2.762141704559326\n",
      "training 30.84%: 0.328. Loss: 2.374305248260498\n",
      "training 30.90%: 0.329. Loss: 2.1870152950286865\n",
      "training 30.97%: 0.329. Loss: 2.124810218811035\n",
      "training 31.03%: 0.329. Loss: 2.667222023010254\n",
      "training 31.09%: 0.330. Loss: 2.416337490081787\n",
      "training 31.16%: 0.330. Loss: 2.227654457092285\n",
      "training 31.22%: 0.330. Loss: 2.050508499145508\n",
      "training 31.29%: 0.331. Loss: 2.2363576889038086\n",
      "training 31.35%: 0.331. Loss: 2.3645873069763184\n",
      "training 31.41%: 0.331. Loss: 2.396472215652466\n",
      "training 31.48%: 0.331. Loss: 2.431731939315796\n",
      "training 31.54%: 0.332. Loss: 2.2288732528686523\n",
      "training 31.61%: 0.332. Loss: 2.308335781097412\n",
      "training 31.67%: 0.332. Loss: 2.4847328662872314\n",
      "training 31.73%: 0.333. Loss: 2.120675802230835\n",
      "training 31.80%: 0.333. Loss: 2.0362002849578857\n",
      "training 31.86%: 0.334. Loss: 2.2898671627044678\n",
      "training 31.93%: 0.334. Loss: 2.3461520671844482\n",
      "training 31.99%: 0.334. Loss: 2.1733603477478027\n",
      "training 32.05%: 0.335. Loss: 2.2293295860290527\n",
      "training 32.12%: 0.335. Loss: 2.2717058658599854\n",
      "training 32.18%: 0.335. Loss: 2.2208166122436523\n",
      "training 32.25%: 0.336. Loss: 1.9053937196731567\n",
      "training 32.31%: 0.336. Loss: 2.0583672523498535\n",
      "training 32.37%: 0.336. Loss: 2.453087568283081\n",
      "training 32.44%: 0.336. Loss: 2.385951280593872\n",
      "training 32.50%: 0.337. Loss: 2.2503414154052734\n",
      "training 32.57%: 0.337. Loss: 2.400125503540039\n",
      "training 32.63%: 0.337. Loss: 2.479677438735962\n",
      "training 32.69%: 0.337. Loss: 2.350524425506592\n",
      "training 32.76%: 0.338. Loss: 2.323594808578491\n",
      "training 32.82%: 0.338. Loss: 2.058499336242676\n",
      "training 32.89%: 0.339. Loss: 1.811295509338379\n",
      "training 32.95%: 0.339. Loss: 2.106375217437744\n",
      "training 33.01%: 0.339. Loss: 2.3334150314331055\n",
      "training 33.08%: 0.340. Loss: 2.3054370880126953\n",
      "training 33.14%: 0.340. Loss: 2.5206806659698486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 33.21%: 0.340. Loss: 2.440225124359131\n",
      "training 33.27%: 0.340. Loss: 2.487548589706421\n",
      "training 33.33%: 0.340. Loss: 2.3967463970184326\n",
      "training 33.40%: 0.341. Loss: 2.337444305419922\n",
      "training 33.46%: 0.341. Loss: 2.155406951904297\n",
      "training 33.53%: 0.341. Loss: 2.7715353965759277\n",
      "training 33.59%: 0.342. Loss: 2.0795350074768066\n",
      "training 33.65%: 0.342. Loss: 2.5145039558410645\n",
      "training 33.72%: 0.342. Loss: 2.177722692489624\n",
      "training 33.78%: 0.342. Loss: 2.140016555786133\n",
      "training 33.85%: 0.343. Loss: 2.030989408493042\n",
      "training 33.91%: 0.343. Loss: 2.192903518676758\n",
      "training 33.97%: 0.343. Loss: 2.1791369915008545\n",
      "training 34.04%: 0.343. Loss: 2.341377019882202\n",
      "training 34.10%: 0.343. Loss: 2.6771397590637207\n",
      "training 34.17%: 0.343. Loss: 2.6214988231658936\n",
      "training 34.23%: 0.344. Loss: 1.9529409408569336\n",
      "training 34.29%: 0.344. Loss: 2.4332315921783447\n",
      "training 34.36%: 0.344. Loss: 2.3340516090393066\n",
      "training 34.42%: 0.345. Loss: 2.043891429901123\n",
      "training 34.48%: 0.345. Loss: 2.497781991958618\n",
      "training 34.55%: 0.345. Loss: 2.050114393234253\n",
      "training 34.61%: 0.346. Loss: 1.8842545747756958\n",
      "training 34.68%: 0.346. Loss: 2.5194411277770996\n",
      "training 34.74%: 0.346. Loss: 2.061903476715088\n",
      "training 34.80%: 0.347. Loss: 1.9502137899398804\n",
      "training 34.87%: 0.347. Loss: 2.2173585891723633\n",
      "training 34.93%: 0.348. Loss: 1.9200119972229004\n",
      "training 35.00%: 0.348. Loss: 2.3008642196655273\n",
      "training 35.06%: 0.348. Loss: 2.248872756958008\n",
      "training 35.12%: 0.348. Loss: 2.5518829822540283\n",
      "training 35.19%: 0.348. Loss: 2.5094478130340576\n",
      "training 35.25%: 0.348. Loss: 2.1963555812835693\n",
      "training 35.32%: 0.349. Loss: 2.2287232875823975\n",
      "training 35.38%: 0.349. Loss: 2.1349074840545654\n",
      "training 35.44%: 0.349. Loss: 2.640319585800171\n",
      "training 35.51%: 0.349. Loss: 2.3222169876098633\n",
      "training 35.57%: 0.350. Loss: 2.4371705055236816\n",
      "training 35.64%: 0.350. Loss: 2.2033753395080566\n",
      "training 35.70%: 0.350. Loss: 2.298877477645874\n",
      "training 35.76%: 0.351. Loss: 2.097109794616699\n",
      "training 35.83%: 0.351. Loss: 2.460340976715088\n",
      "training 35.89%: 0.351. Loss: 2.460010528564453\n",
      "training 35.96%: 0.351. Loss: 2.160871982574463\n",
      "training 36.02%: 0.351. Loss: 2.0512537956237793\n",
      "training 36.08%: 0.351. Loss: 1.9216500520706177\n",
      "training 36.15%: 0.352. Loss: 2.132481575012207\n",
      "training 36.21%: 0.352. Loss: 1.9440417289733887\n",
      "training 36.28%: 0.352. Loss: 2.1151816844940186\n",
      "training 36.34%: 0.353. Loss: 2.4160573482513428\n",
      "training 36.40%: 0.353. Loss: 2.093958854675293\n",
      "training 36.47%: 0.353. Loss: 1.9489836692810059\n",
      "training 36.53%: 0.353. Loss: 2.926158905029297\n",
      "training 36.60%: 0.353. Loss: 2.5785090923309326\n",
      "training 36.66%: 0.354. Loss: 2.029555559158325\n",
      "training 36.72%: 0.354. Loss: 2.1000313758850098\n",
      "training 36.79%: 0.354. Loss: 2.3198139667510986\n",
      "training 36.85%: 0.354. Loss: 2.5153019428253174\n",
      "training 36.92%: 0.355. Loss: 2.338358163833618\n",
      "training 36.98%: 0.355. Loss: 2.3744685649871826\n",
      "training 37.04%: 0.355. Loss: 2.6281206607818604\n",
      "training 37.11%: 0.355. Loss: 2.616673707962036\n",
      "training 37.17%: 0.355. Loss: 1.9805299043655396\n",
      "training 37.24%: 0.355. Loss: 2.1059999465942383\n",
      "training 37.30%: 0.356. Loss: 1.962659478187561\n",
      "training 37.36%: 0.356. Loss: 2.0683019161224365\n",
      "training 37.43%: 0.356. Loss: 2.4121837615966797\n",
      "training 37.49%: 0.356. Loss: 2.4481277465820312\n",
      "training 37.56%: 0.356. Loss: 2.350755214691162\n",
      "training 37.62%: 0.356. Loss: 2.3061444759368896\n",
      "training 37.68%: 0.357. Loss: 1.935935139656067\n",
      "training 37.75%: 0.357. Loss: 2.2958526611328125\n",
      "training 37.81%: 0.357. Loss: 2.427548408508301\n",
      "training 37.88%: 0.357. Loss: 2.6080172061920166\n",
      "training 37.94%: 0.357. Loss: 2.153254985809326\n",
      "training 38.00%: 0.358. Loss: 2.2924118041992188\n",
      "training 38.07%: 0.358. Loss: 2.4489529132843018\n",
      "training 38.13%: 0.358. Loss: 1.9870249032974243\n",
      "training 38.20%: 0.358. Loss: 2.0752010345458984\n",
      "training 38.26%: 0.359. Loss: 2.234626293182373\n",
      "training 38.32%: 0.359. Loss: 2.1469368934631348\n",
      "training 38.39%: 0.359. Loss: 2.454859972000122\n",
      "training 38.45%: 0.359. Loss: 1.9978573322296143\n",
      "training 38.52%: 0.359. Loss: 2.2424914836883545\n",
      "training 38.58%: 0.360. Loss: 2.052229881286621\n",
      "training 38.64%: 0.360. Loss: 1.9719496965408325\n",
      "training 38.71%: 0.360. Loss: 1.9805055856704712\n",
      "training 38.77%: 0.361. Loss: 1.9707168340682983\n",
      "training 38.84%: 0.361. Loss: 2.2025210857391357\n",
      "training 38.90%: 0.361. Loss: 2.2443344593048096\n",
      "training 38.96%: 0.361. Loss: 2.1775734424591064\n",
      "training 39.03%: 0.361. Loss: 2.0875532627105713\n",
      "training 39.09%: 0.361. Loss: 2.3639628887176514\n",
      "training 39.16%: 0.362. Loss: 2.267951250076294\n",
      "training 39.22%: 0.362. Loss: 2.4352285861968994\n",
      "training 39.28%: 0.362. Loss: 2.2014288902282715\n",
      "training 39.35%: 0.362. Loss: 2.0757076740264893\n",
      "training 39.41%: 0.362. Loss: 2.2356841564178467\n",
      "training 39.48%: 0.362. Loss: 2.411573648452759\n",
      "training 39.54%: 0.362. Loss: 2.3672006130218506\n",
      "training 39.60%: 0.363. Loss: 2.319538116455078\n",
      "training 39.67%: 0.363. Loss: 2.2567813396453857\n",
      "training 39.73%: 0.363. Loss: 2.1488161087036133\n",
      "training 39.80%: 0.363. Loss: 2.023892879486084\n",
      "training 39.86%: 0.363. Loss: 2.014162302017212\n",
      "training 39.92%: 0.364. Loss: 2.2475109100341797\n",
      "training 39.99%: 0.364. Loss: 2.4017179012298584\n",
      "training 40.05%: 0.364. Loss: 2.0527379512786865\n",
      "training 40.12%: 0.364. Loss: 2.092254877090454\n",
      "training 40.18%: 0.365. Loss: 2.4409162998199463\n",
      "training 40.24%: 0.365. Loss: 2.012641668319702\n",
      "training 40.31%: 0.365. Loss: 2.4767072200775146\n",
      "training 40.37%: 0.365. Loss: 2.3797390460968018\n",
      "training 40.44%: 0.365. Loss: 2.3429670333862305\n",
      "training 40.50%: 0.366. Loss: 2.384866714477539\n",
      "training 40.56%: 0.366. Loss: 2.7459843158721924\n",
      "training 40.63%: 0.366. Loss: 1.6451637744903564\n",
      "training 40.69%: 0.366. Loss: 2.0258915424346924\n",
      "training 40.75%: 0.366. Loss: 1.9706969261169434\n",
      "training 40.82%: 0.367. Loss: 2.396512031555176\n",
      "training 40.88%: 0.367. Loss: 2.0323808193206787\n",
      "training 40.95%: 0.367. Loss: 1.9985405206680298\n",
      "training 41.01%: 0.367. Loss: 2.2314624786376953\n",
      "training 41.07%: 0.368. Loss: 2.045712471008301\n",
      "training 41.14%: 0.368. Loss: 2.2153830528259277\n",
      "training 41.20%: 0.368. Loss: 2.250636100769043\n",
      "training 41.27%: 0.368. Loss: 2.2077748775482178\n",
      "training 41.33%: 0.368. Loss: 1.8222236633300781\n",
      "training 41.39%: 0.369. Loss: 2.085636854171753\n",
      "training 41.46%: 0.369. Loss: 2.2483432292938232\n",
      "training 41.52%: 0.369. Loss: 2.194930076599121\n",
      "training 41.59%: 0.369. Loss: 2.107530117034912\n",
      "training 41.65%: 0.370. Loss: 2.010408639907837\n",
      "training 41.71%: 0.370. Loss: 2.2312936782836914\n",
      "training 41.78%: 0.370. Loss: 2.4829208850860596\n",
      "training 41.84%: 0.370. Loss: 2.064487934112549\n",
      "training 41.91%: 0.370. Loss: 2.674062728881836\n",
      "training 41.97%: 0.370. Loss: 2.509934425354004\n",
      "training 42.03%: 0.370. Loss: 2.2553768157958984\n",
      "training 42.10%: 0.371. Loss: 1.7776490449905396\n",
      "training 42.16%: 0.371. Loss: 2.423032522201538\n",
      "training 42.23%: 0.372. Loss: 2.0108137130737305\n",
      "training 42.29%: 0.372. Loss: 2.2135753631591797\n",
      "training 42.35%: 0.372. Loss: 2.1220548152923584\n",
      "training 42.42%: 0.372. Loss: 1.847214698791504\n",
      "training 42.48%: 0.372. Loss: 2.229513645172119\n",
      "training 42.55%: 0.373. Loss: 2.1675212383270264\n",
      "training 42.61%: 0.373. Loss: 2.0279769897460938\n",
      "training 42.67%: 0.373. Loss: 2.5047709941864014\n",
      "training 42.74%: 0.373. Loss: 2.1422924995422363\n",
      "training 42.80%: 0.373. Loss: 2.3296267986297607\n",
      "training 42.87%: 0.373. Loss: 2.240842342376709\n",
      "training 42.93%: 0.374. Loss: 2.161817789077759\n",
      "training 42.99%: 0.374. Loss: 2.0470759868621826\n",
      "training 43.06%: 0.374. Loss: 2.1753926277160645\n",
      "training 43.12%: 0.374. Loss: 2.0138282775878906\n",
      "training 43.19%: 0.375. Loss: 2.319960832595825\n",
      "training 43.25%: 0.375. Loss: 2.0555520057678223\n",
      "training 43.31%: 0.375. Loss: 1.8549100160598755\n",
      "training 43.38%: 0.375. Loss: 1.812446117401123\n",
      "training 43.44%: 0.376. Loss: 2.0433497428894043\n",
      "training 43.51%: 0.376. Loss: 2.5047109127044678\n",
      "training 43.57%: 0.376. Loss: 2.1842293739318848\n",
      "training 43.63%: 0.376. Loss: 1.918662667274475\n",
      "training 43.70%: 0.376. Loss: 2.7471890449523926\n",
      "training 43.76%: 0.376. Loss: 1.8345463275909424\n",
      "training 43.83%: 0.377. Loss: 2.3688576221466064\n",
      "training 43.89%: 0.377. Loss: 2.1581485271453857\n",
      "training 43.95%: 0.377. Loss: 2.1927871704101562\n",
      "training 44.02%: 0.377. Loss: 2.2784061431884766\n",
      "training 44.08%: 0.377. Loss: 2.133786916732788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 44.15%: 0.377. Loss: 2.2033069133758545\n",
      "training 44.21%: 0.377. Loss: 1.9391274452209473\n",
      "training 44.27%: 0.378. Loss: 2.2993249893188477\n",
      "training 44.34%: 0.378. Loss: 2.054436683654785\n",
      "training 44.40%: 0.378. Loss: 1.9239674806594849\n",
      "training 44.47%: 0.378. Loss: 2.073704242706299\n",
      "training 44.53%: 0.378. Loss: 2.1342408657073975\n",
      "training 44.59%: 0.379. Loss: 2.135213613510132\n",
      "training 44.66%: 0.379. Loss: 1.866525411605835\n",
      "training 44.72%: 0.379. Loss: 2.3446781635284424\n",
      "training 44.79%: 0.379. Loss: 2.0499324798583984\n",
      "training 44.85%: 0.380. Loss: 2.1515767574310303\n",
      "training 44.91%: 0.380. Loss: 2.4752745628356934\n",
      "training 44.98%: 0.380. Loss: 2.5955443382263184\n",
      "training 45.04%: 0.380. Loss: 1.8752048015594482\n",
      "training 45.11%: 0.380. Loss: 2.070695161819458\n",
      "training 45.17%: 0.381. Loss: 2.165123701095581\n",
      "training 45.23%: 0.381. Loss: 2.2332093715667725\n",
      "training 45.30%: 0.381. Loss: 2.1433064937591553\n",
      "training 45.36%: 0.381. Loss: 1.8872909545898438\n",
      "training 45.43%: 0.381. Loss: 2.105919122695923\n",
      "training 45.49%: 0.381. Loss: 2.210023880004883\n",
      "training 45.55%: 0.382. Loss: 1.7149124145507812\n",
      "training 45.62%: 0.382. Loss: 2.38227915763855\n",
      "training 45.68%: 0.382. Loss: 2.364387035369873\n",
      "training 45.75%: 0.382. Loss: 2.1389756202697754\n",
      "training 45.81%: 0.382. Loss: 2.1631851196289062\n",
      "training 45.87%: 0.382. Loss: 2.1156094074249268\n",
      "training 45.94%: 0.382. Loss: 2.3494255542755127\n",
      "training 46.00%: 0.383. Loss: 2.116438627243042\n",
      "training 46.07%: 0.383. Loss: 2.2926793098449707\n",
      "training 46.13%: 0.383. Loss: 2.1245293617248535\n",
      "training 46.19%: 0.383. Loss: 1.8810611963272095\n",
      "training 46.26%: 0.383. Loss: 2.2900280952453613\n",
      "training 46.32%: 0.383. Loss: 2.2968645095825195\n",
      "training 46.39%: 0.384. Loss: 2.2097246646881104\n",
      "training 46.45%: 0.384. Loss: 2.2447381019592285\n",
      "training 46.51%: 0.384. Loss: 2.2760560512542725\n",
      "training 46.58%: 0.384. Loss: 2.20894718170166\n",
      "training 46.64%: 0.384. Loss: 2.388720989227295\n",
      "training 46.71%: 0.384. Loss: 1.9534283876419067\n",
      "training 46.77%: 0.385. Loss: 1.8924065828323364\n",
      "training 46.83%: 0.385. Loss: 2.1910626888275146\n",
      "training 46.90%: 0.385. Loss: 2.0203092098236084\n",
      "training 46.96%: 0.385. Loss: 2.157477617263794\n",
      "training 47.02%: 0.385. Loss: 1.8316271305084229\n",
      "training 47.09%: 0.385. Loss: 2.290560007095337\n",
      "training 47.15%: 0.386. Loss: 2.2065017223358154\n",
      "training 47.22%: 0.386. Loss: 2.0414648056030273\n",
      "training 47.28%: 0.386. Loss: 2.0694944858551025\n",
      "training 47.34%: 0.386. Loss: 2.489309310913086\n",
      "training 47.41%: 0.386. Loss: 2.174227237701416\n",
      "training 47.47%: 0.386. Loss: 2.025444507598877\n",
      "training 47.54%: 0.386. Loss: 2.5527331829071045\n",
      "training 47.60%: 0.386. Loss: 2.3841443061828613\n",
      "training 47.66%: 0.386. Loss: 1.8838664293289185\n",
      "training 47.73%: 0.387. Loss: 2.0113749504089355\n",
      "training 47.79%: 0.387. Loss: 1.779931664466858\n",
      "training 47.86%: 0.387. Loss: 1.9728387594223022\n",
      "training 47.92%: 0.387. Loss: 1.902270793914795\n",
      "training 47.98%: 0.388. Loss: 1.6643803119659424\n",
      "training 48.05%: 0.388. Loss: 2.443228244781494\n",
      "training 48.11%: 0.388. Loss: 1.8883743286132812\n",
      "training 48.18%: 0.388. Loss: 2.1055965423583984\n",
      "training 48.24%: 0.388. Loss: 1.8949917554855347\n",
      "training 48.30%: 0.389. Loss: 2.26697039604187\n",
      "training 48.37%: 0.389. Loss: 2.1805293560028076\n",
      "training 48.43%: 0.389. Loss: 2.419358968734741\n",
      "training 48.50%: 0.389. Loss: 1.942448616027832\n",
      "training 48.56%: 0.389. Loss: 1.9969511032104492\n",
      "training 48.62%: 0.389. Loss: 2.2479708194732666\n",
      "training 48.69%: 0.390. Loss: 1.863002896308899\n",
      "training 48.75%: 0.390. Loss: 2.265287160873413\n",
      "training 48.82%: 0.390. Loss: 1.9753267765045166\n",
      "training 48.88%: 0.390. Loss: 1.9624788761138916\n",
      "training 48.94%: 0.390. Loss: 2.4066905975341797\n",
      "training 49.01%: 0.390. Loss: 2.0066885948181152\n",
      "training 49.07%: 0.390. Loss: 2.077455997467041\n",
      "training 49.14%: 0.391. Loss: 2.149937391281128\n",
      "training 49.20%: 0.391. Loss: 1.7595654726028442\n",
      "training 49.26%: 0.391. Loss: 1.9210054874420166\n",
      "training 49.33%: 0.391. Loss: 1.9183452129364014\n",
      "training 49.39%: 0.391. Loss: 2.198549747467041\n",
      "training 49.46%: 0.391. Loss: 2.1174113750457764\n",
      "training 49.52%: 0.391. Loss: 2.1590957641601562\n",
      "training 49.58%: 0.391. Loss: 2.395554304122925\n",
      "training 49.65%: 0.392. Loss: 2.246427059173584\n",
      "training 49.71%: 0.392. Loss: 2.151012897491455\n",
      "training 49.78%: 0.392. Loss: 2.0090250968933105\n",
      "training 49.84%: 0.392. Loss: 2.039346218109131\n",
      "training 49.90%: 0.392. Loss: 2.4327545166015625\n",
      "training 49.97%: 0.392. Loss: 2.344503164291382\n",
      "training 50.03%: 0.392. Loss: 2.1490683555603027\n",
      "training 50.10%: 0.392. Loss: 2.271397113800049\n",
      "training 50.16%: 0.393. Loss: 2.1240365505218506\n",
      "training 50.22%: 0.393. Loss: 1.928629994392395\n",
      "training 50.29%: 0.393. Loss: 2.3176791667938232\n",
      "training 50.35%: 0.393. Loss: 1.813984751701355\n",
      "training 50.42%: 0.393. Loss: 2.3899736404418945\n",
      "training 50.48%: 0.393. Loss: 1.8548895120620728\n",
      "training 50.54%: 0.393. Loss: 2.037132978439331\n",
      "training 50.61%: 0.394. Loss: 1.8947434425354004\n",
      "training 50.67%: 0.394. Loss: 2.127505302429199\n",
      "training 50.74%: 0.394. Loss: 2.2702884674072266\n",
      "training 50.80%: 0.394. Loss: 2.053215503692627\n",
      "training 50.86%: 0.394. Loss: 2.4317026138305664\n",
      "training 50.93%: 0.394. Loss: 2.0510408878326416\n",
      "training 50.99%: 0.394. Loss: 2.5162644386291504\n",
      "training 51.06%: 0.394. Loss: 2.190953016281128\n",
      "training 51.12%: 0.395. Loss: 1.6658844947814941\n",
      "training 51.18%: 0.395. Loss: 1.9784055948257446\n",
      "training 51.25%: 0.395. Loss: 2.3973076343536377\n",
      "training 51.31%: 0.395. Loss: 2.0710065364837646\n",
      "training 51.38%: 0.395. Loss: 1.8472918272018433\n",
      "training 51.44%: 0.396. Loss: 2.293109893798828\n",
      "training 51.50%: 0.396. Loss: 2.113215208053589\n",
      "training 51.57%: 0.396. Loss: 1.964534878730774\n",
      "training 51.63%: 0.396. Loss: 2.201780080795288\n",
      "training 51.70%: 0.396. Loss: 2.1861774921417236\n",
      "training 51.76%: 0.396. Loss: 2.548017740249634\n",
      "training 51.82%: 0.396. Loss: 2.0821895599365234\n",
      "training 51.89%: 0.396. Loss: 1.835876226425171\n",
      "training 51.95%: 0.396. Loss: 2.317213296890259\n",
      "training 52.02%: 0.396. Loss: 2.3007733821868896\n",
      "training 52.08%: 0.397. Loss: 2.0415196418762207\n",
      "training 52.14%: 0.397. Loss: 1.9779505729675293\n",
      "training 52.21%: 0.397. Loss: 2.1512584686279297\n",
      "training 52.27%: 0.397. Loss: 1.833380937576294\n",
      "training 52.34%: 0.397. Loss: 2.0455386638641357\n",
      "training 52.40%: 0.397. Loss: 2.2493584156036377\n",
      "training 52.46%: 0.397. Loss: 1.940487027168274\n",
      "training 52.53%: 0.398. Loss: 1.9805850982666016\n",
      "training 52.59%: 0.398. Loss: 2.098848342895508\n",
      "training 52.66%: 0.398. Loss: 1.9765604734420776\n",
      "training 52.72%: 0.398. Loss: 2.191257953643799\n",
      "training 52.78%: 0.398. Loss: 1.8747726678848267\n",
      "training 52.85%: 0.399. Loss: 1.642737865447998\n",
      "training 52.91%: 0.399. Loss: 1.7854423522949219\n",
      "training 52.98%: 0.399. Loss: 2.1236441135406494\n",
      "training 53.04%: 0.399. Loss: 2.1023311614990234\n",
      "training 53.10%: 0.399. Loss: 2.0669803619384766\n",
      "training 53.17%: 0.399. Loss: 2.6000802516937256\n",
      "training 53.23%: 0.399. Loss: 2.071714162826538\n",
      "training 53.29%: 0.399. Loss: 2.117617130279541\n",
      "training 53.36%: 0.400. Loss: 2.0086374282836914\n",
      "training 53.42%: 0.400. Loss: 2.0034828186035156\n",
      "training 53.49%: 0.400. Loss: 2.0634264945983887\n",
      "training 53.55%: 0.400. Loss: 1.8127533197402954\n",
      "training 53.61%: 0.400. Loss: 1.9318031072616577\n",
      "training 53.68%: 0.400. Loss: 1.7970689535140991\n",
      "training 53.74%: 0.401. Loss: 1.9306952953338623\n",
      "training 53.81%: 0.401. Loss: 2.0581438541412354\n",
      "training 53.87%: 0.401. Loss: 1.8385393619537354\n",
      "training 53.93%: 0.401. Loss: 2.1688790321350098\n",
      "training 54.00%: 0.401. Loss: 1.9128360748291016\n",
      "training 54.06%: 0.401. Loss: 2.116917610168457\n",
      "training 54.13%: 0.401. Loss: 2.538011312484741\n",
      "training 54.19%: 0.402. Loss: 1.8570374250411987\n",
      "training 54.25%: 0.402. Loss: 1.6274397373199463\n",
      "training 54.32%: 0.402. Loss: 2.303478479385376\n",
      "training 54.38%: 0.402. Loss: 2.0361385345458984\n",
      "training 54.45%: 0.402. Loss: 2.0733916759490967\n",
      "training 54.51%: 0.402. Loss: 2.3491668701171875\n",
      "training 54.57%: 0.402. Loss: 2.2234277725219727\n",
      "training 54.64%: 0.402. Loss: 2.1388375759124756\n",
      "training 54.70%: 0.403. Loss: 1.905137300491333\n",
      "training 54.77%: 0.403. Loss: 2.0230143070220947\n",
      "training 54.83%: 0.403. Loss: 2.3114547729492188\n",
      "training 54.89%: 0.403. Loss: 1.9500147104263306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 54.96%: 0.403. Loss: 2.046377658843994\n",
      "training 55.02%: 0.403. Loss: 1.845283031463623\n",
      "training 55.09%: 0.403. Loss: 2.080965042114258\n",
      "training 55.15%: 0.403. Loss: 2.1358911991119385\n",
      "training 55.21%: 0.404. Loss: 1.8644680976867676\n",
      "training 55.28%: 0.404. Loss: 1.9925932884216309\n",
      "training 55.34%: 0.404. Loss: 1.7449240684509277\n",
      "training 55.41%: 0.404. Loss: 2.1084179878234863\n",
      "training 55.47%: 0.404. Loss: 2.2291266918182373\n",
      "training 55.53%: 0.404. Loss: 1.8631502389907837\n",
      "training 55.60%: 0.405. Loss: 2.1989338397979736\n",
      "training 55.66%: 0.405. Loss: 1.9126056432724\n",
      "training 55.73%: 0.405. Loss: 2.1895885467529297\n",
      "training 55.79%: 0.405. Loss: 1.4726091623306274\n",
      "training 55.85%: 0.405. Loss: 2.27022123336792\n",
      "training 55.92%: 0.405. Loss: 1.99045729637146\n",
      "training 55.98%: 0.405. Loss: 2.5376381874084473\n",
      "training 56.05%: 0.406. Loss: 1.7901687622070312\n",
      "training 56.11%: 0.406. Loss: 2.253131866455078\n",
      "training 56.17%: 0.406. Loss: 2.087592601776123\n",
      "training 56.24%: 0.406. Loss: 1.7098429203033447\n",
      "training 56.30%: 0.406. Loss: 2.108224868774414\n",
      "training 56.37%: 0.406. Loss: 2.103527307510376\n",
      "training 56.43%: 0.406. Loss: 2.319873332977295\n",
      "training 56.49%: 0.406. Loss: 2.2725281715393066\n",
      "training 56.56%: 0.406. Loss: 2.153353452682495\n",
      "training 56.62%: 0.406. Loss: 1.796068787574768\n",
      "training 56.69%: 0.407. Loss: 2.1336960792541504\n",
      "training 56.75%: 0.407. Loss: 1.6643400192260742\n",
      "training 56.81%: 0.407. Loss: 1.9958468675613403\n",
      "training 56.88%: 0.407. Loss: 1.9354240894317627\n",
      "training 56.94%: 0.407. Loss: 2.145012855529785\n",
      "training 57.01%: 0.407. Loss: 2.0603013038635254\n",
      "training 57.07%: 0.407. Loss: 2.0405936241149902\n",
      "training 57.13%: 0.407. Loss: 1.8237324953079224\n",
      "training 57.20%: 0.408. Loss: 1.8821580410003662\n",
      "training 57.26%: 0.408. Loss: 2.216804027557373\n",
      "training 57.33%: 0.408. Loss: 2.175943374633789\n",
      "training 57.39%: 0.408. Loss: 1.684069275856018\n",
      "training 57.45%: 0.408. Loss: 2.3513810634613037\n",
      "training 57.52%: 0.408. Loss: 1.6159764528274536\n",
      "training 57.58%: 0.409. Loss: 1.915274977684021\n",
      "training 57.65%: 0.409. Loss: 2.168877363204956\n",
      "training 57.71%: 0.409. Loss: 1.9498237371444702\n",
      "training 57.77%: 0.409. Loss: 1.8583003282546997\n",
      "training 57.84%: 0.409. Loss: 2.172823667526245\n",
      "training 57.90%: 0.409. Loss: 1.832719087600708\n",
      "training 57.97%: 0.409. Loss: 1.8420015573501587\n",
      "training 58.03%: 0.409. Loss: 2.109022855758667\n",
      "training 58.09%: 0.409. Loss: 2.059453248977661\n",
      "training 58.16%: 0.410. Loss: 1.9781655073165894\n",
      "training 58.22%: 0.410. Loss: 2.151007890701294\n",
      "training 58.29%: 0.410. Loss: 1.7682584524154663\n",
      "training 58.35%: 0.410. Loss: 1.8577345609664917\n",
      "training 58.41%: 0.410. Loss: 2.3063864707946777\n",
      "training 58.48%: 0.410. Loss: 2.082263708114624\n",
      "training 58.54%: 0.410. Loss: 1.838640809059143\n",
      "training 58.61%: 0.410. Loss: 2.274555206298828\n",
      "training 58.67%: 0.410. Loss: 2.0999255180358887\n",
      "training 58.73%: 0.411. Loss: 2.021911859512329\n",
      "training 58.80%: 0.411. Loss: 1.835345983505249\n",
      "training 58.86%: 0.411. Loss: 1.7028734683990479\n",
      "training 58.93%: 0.411. Loss: 2.0577383041381836\n",
      "training 58.99%: 0.411. Loss: 1.7791920900344849\n",
      "training 59.05%: 0.411. Loss: 2.1844873428344727\n",
      "training 59.12%: 0.411. Loss: 2.2029945850372314\n",
      "training 59.18%: 0.411. Loss: 2.2561349868774414\n",
      "training 59.25%: 0.411. Loss: 2.3192920684814453\n",
      "training 59.31%: 0.412. Loss: 2.2307240962982178\n",
      "training 59.37%: 0.412. Loss: 1.7072196006774902\n",
      "training 59.44%: 0.412. Loss: 2.3406968116760254\n",
      "training 59.50%: 0.412. Loss: 1.8195880651474\n",
      "training 59.56%: 0.412. Loss: 2.2864997386932373\n",
      "training 59.63%: 0.412. Loss: 2.0265583992004395\n",
      "training 59.69%: 0.412. Loss: 1.7428852319717407\n",
      "training 59.76%: 0.412. Loss: 1.8693844079971313\n",
      "training 59.82%: 0.412. Loss: 2.297366142272949\n",
      "training 59.88%: 0.413. Loss: 1.9828248023986816\n",
      "training 59.95%: 0.413. Loss: 1.9526174068450928\n",
      "training 60.01%: 0.413. Loss: 2.171217203140259\n",
      "training 60.08%: 0.413. Loss: 2.0985937118530273\n",
      "training 60.14%: 0.413. Loss: 1.805285930633545\n",
      "training 60.20%: 0.413. Loss: 2.085151433944702\n",
      "training 60.27%: 0.413. Loss: 1.9115971326828003\n",
      "training 60.33%: 0.413. Loss: 2.3764517307281494\n",
      "training 60.40%: 0.414. Loss: 1.7928457260131836\n",
      "training 60.46%: 0.414. Loss: 1.9102948904037476\n",
      "training 60.52%: 0.414. Loss: 2.1170761585235596\n",
      "training 60.59%: 0.414. Loss: 1.901625394821167\n",
      "training 60.65%: 0.414. Loss: 2.561110019683838\n",
      "training 60.72%: 0.414. Loss: 2.208183765411377\n",
      "training 60.78%: 0.414. Loss: 2.3912150859832764\n",
      "training 60.84%: 0.414. Loss: 1.866978645324707\n",
      "training 60.91%: 0.414. Loss: 2.0945310592651367\n",
      "training 60.97%: 0.414. Loss: 2.0671255588531494\n",
      "training 61.04%: 0.415. Loss: 1.7395464181900024\n",
      "training 61.10%: 0.415. Loss: 2.2075154781341553\n",
      "training 61.16%: 0.415. Loss: 1.9349637031555176\n",
      "training 61.23%: 0.415. Loss: 1.8015042543411255\n",
      "training 61.29%: 0.415. Loss: 2.104423999786377\n",
      "training 61.36%: 0.415. Loss: 1.8839045763015747\n",
      "training 61.42%: 0.415. Loss: 2.132730007171631\n",
      "training 61.48%: 0.416. Loss: 2.082655668258667\n",
      "training 61.55%: 0.416. Loss: 1.8426142930984497\n",
      "training 61.61%: 0.416. Loss: 1.8909235000610352\n",
      "training 61.68%: 0.416. Loss: 2.115398645401001\n",
      "training 61.74%: 0.416. Loss: 2.2106761932373047\n",
      "training 61.80%: 0.416. Loss: 1.9256905317306519\n",
      "training 61.87%: 0.416. Loss: 2.1042559146881104\n",
      "training 61.93%: 0.416. Loss: 2.053337812423706\n",
      "training 62.00%: 0.416. Loss: 1.8609713315963745\n",
      "training 62.06%: 0.417. Loss: 2.117755889892578\n",
      "training 62.12%: 0.417. Loss: 1.6569616794586182\n",
      "training 62.19%: 0.417. Loss: 1.6945407390594482\n",
      "training 62.25%: 0.417. Loss: 1.7291719913482666\n",
      "training 62.32%: 0.417. Loss: 1.7809628248214722\n",
      "training 62.38%: 0.417. Loss: 2.104811906814575\n",
      "training 62.44%: 0.417. Loss: 1.6649301052093506\n",
      "training 62.51%: 0.418. Loss: 1.782528281211853\n",
      "training 62.57%: 0.418. Loss: 1.7361159324645996\n",
      "training 62.64%: 0.418. Loss: 2.2189104557037354\n",
      "training 62.70%: 0.418. Loss: 1.3525092601776123\n",
      "training 62.76%: 0.418. Loss: 2.297985553741455\n",
      "training 62.83%: 0.418. Loss: 1.7407697439193726\n",
      "training 62.89%: 0.418. Loss: 2.059995412826538\n",
      "training 62.96%: 0.418. Loss: 1.9184471368789673\n",
      "training 63.02%: 0.418. Loss: 2.258188009262085\n",
      "training 63.08%: 0.418. Loss: 2.059281587600708\n",
      "training 63.15%: 0.419. Loss: 2.086268901824951\n",
      "training 63.21%: 0.419. Loss: 2.007986068725586\n",
      "training 63.28%: 0.419. Loss: 2.1192119121551514\n",
      "training 63.34%: 0.419. Loss: 2.000084638595581\n",
      "training 63.40%: 0.419. Loss: 1.9620158672332764\n",
      "training 63.47%: 0.419. Loss: 2.286973237991333\n",
      "training 63.53%: 0.419. Loss: 1.9380139112472534\n",
      "training 63.60%: 0.419. Loss: 2.0925796031951904\n",
      "training 63.66%: 0.419. Loss: 2.2240512371063232\n",
      "training 63.72%: 0.419. Loss: 2.6884307861328125\n",
      "training 63.79%: 0.419. Loss: 2.0144858360290527\n",
      "training 63.85%: 0.419. Loss: 1.949809193611145\n",
      "training 63.92%: 0.419. Loss: 2.002842664718628\n",
      "training 63.98%: 0.420. Loss: 2.143460988998413\n",
      "training 64.04%: 0.420. Loss: 2.1933844089508057\n",
      "training 64.11%: 0.420. Loss: 2.173210382461548\n",
      "training 64.17%: 0.420. Loss: 1.9905543327331543\n",
      "training 64.24%: 0.420. Loss: 1.6875841617584229\n",
      "training 64.30%: 0.420. Loss: 1.9337924718856812\n",
      "training 64.36%: 0.420. Loss: 1.8845562934875488\n",
      "training 64.43%: 0.420. Loss: 1.8877184391021729\n",
      "training 64.49%: 0.420. Loss: 2.2335422039031982\n",
      "training 64.56%: 0.420. Loss: 1.8923637866973877\n",
      "training 64.62%: 0.421. Loss: 1.8790863752365112\n",
      "training 64.68%: 0.421. Loss: 2.136442184448242\n",
      "training 64.75%: 0.421. Loss: 2.0384562015533447\n",
      "training 64.81%: 0.421. Loss: 1.8950154781341553\n",
      "training 64.88%: 0.421. Loss: 1.7164274454116821\n",
      "training 64.94%: 0.421. Loss: 2.0999388694763184\n",
      "training 65.00%: 0.421. Loss: 2.214740753173828\n",
      "training 65.07%: 0.421. Loss: 2.5963079929351807\n",
      "training 65.13%: 0.421. Loss: 1.712853193283081\n",
      "training 65.20%: 0.421. Loss: 1.6216425895690918\n",
      "training 65.26%: 0.422. Loss: 1.994735836982727\n",
      "training 65.32%: 0.422. Loss: 2.1915464401245117\n",
      "training 65.39%: 0.422. Loss: 1.7683323621749878\n",
      "training 65.45%: 0.422. Loss: 2.337327480316162\n",
      "training 65.52%: 0.422. Loss: 1.758028507232666\n",
      "training 65.58%: 0.422. Loss: 1.6639596223831177\n",
      "training 65.64%: 0.422. Loss: 1.9556738138198853\n",
      "training 65.71%: 0.422. Loss: 1.7785958051681519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 65.77%: 0.422. Loss: 1.9739564657211304\n",
      "training 65.83%: 0.423. Loss: 1.381090760231018\n",
      "training 65.90%: 0.423. Loss: 1.7755910158157349\n",
      "training 65.96%: 0.423. Loss: 1.9387993812561035\n",
      "training 66.03%: 0.423. Loss: 1.3539347648620605\n",
      "training 66.09%: 0.423. Loss: 2.363556385040283\n",
      "training 66.15%: 0.423. Loss: 1.9244452714920044\n",
      "training 66.22%: 0.423. Loss: 1.9457939863204956\n",
      "training 66.28%: 0.423. Loss: 2.0995500087738037\n",
      "training 66.35%: 0.424. Loss: 1.5708035230636597\n",
      "training 66.41%: 0.424. Loss: 1.9277740716934204\n",
      "training 66.47%: 0.424. Loss: 2.0888986587524414\n",
      "training 66.54%: 0.424. Loss: 1.9802005290985107\n",
      "training 66.60%: 0.424. Loss: 1.6224206686019897\n",
      "training 66.67%: 0.424. Loss: 2.23382306098938\n",
      "training 66.73%: 0.424. Loss: 2.024807929992676\n",
      "training 66.79%: 0.424. Loss: 2.1241347789764404\n",
      "training 66.86%: 0.424. Loss: 1.7699604034423828\n",
      "training 66.92%: 0.425. Loss: 2.0607457160949707\n",
      "training 66.99%: 0.425. Loss: 1.995613694190979\n",
      "training 67.05%: 0.425. Loss: 1.9331375360488892\n",
      "training 67.11%: 0.425. Loss: 2.050309419631958\n",
      "training 67.18%: 0.425. Loss: 1.6887747049331665\n",
      "training 67.24%: 0.425. Loss: 1.8420217037200928\n",
      "training 67.31%: 0.425. Loss: 2.115422010421753\n",
      "training 67.37%: 0.425. Loss: 1.8188962936401367\n",
      "training 67.43%: 0.426. Loss: 1.6099008321762085\n",
      "training 67.50%: 0.426. Loss: 1.7675409317016602\n",
      "training 67.56%: 0.426. Loss: 2.106386184692383\n",
      "training 67.63%: 0.426. Loss: 1.749910593032837\n",
      "training 67.69%: 0.426. Loss: 1.9247504472732544\n",
      "training 67.75%: 0.426. Loss: 2.178272008895874\n",
      "training 67.82%: 0.426. Loss: 1.969736933708191\n",
      "training 67.88%: 0.426. Loss: 2.289626359939575\n",
      "training 67.95%: 0.426. Loss: 2.3817405700683594\n",
      "training 68.01%: 0.426. Loss: 1.8197157382965088\n",
      "training 68.07%: 0.427. Loss: 1.7609575986862183\n",
      "training 68.14%: 0.427. Loss: 1.8439433574676514\n",
      "training 68.20%: 0.427. Loss: 1.6630057096481323\n",
      "training 68.27%: 0.427. Loss: 1.8665099143981934\n",
      "training 68.33%: 0.427. Loss: 1.6973978281021118\n",
      "training 68.39%: 0.427. Loss: 1.9544564485549927\n",
      "training 68.46%: 0.427. Loss: 1.7205421924591064\n",
      "training 68.52%: 0.427. Loss: 1.94472336769104\n",
      "training 68.59%: 0.427. Loss: 1.6362113952636719\n",
      "training 68.65%: 0.428. Loss: 1.8291864395141602\n",
      "training 68.71%: 0.428. Loss: 2.130511999130249\n",
      "training 68.78%: 0.428. Loss: 1.507360816001892\n",
      "training 68.84%: 0.428. Loss: 2.00406551361084\n",
      "training 68.91%: 0.428. Loss: 1.9730263948440552\n",
      "training 68.97%: 0.428. Loss: 2.4226746559143066\n",
      "training 69.03%: 0.428. Loss: 1.7904932498931885\n",
      "training 69.10%: 0.428. Loss: 1.9211351871490479\n",
      "training 69.16%: 0.428. Loss: 1.7859822511672974\n",
      "training 69.23%: 0.428. Loss: 1.9004961252212524\n",
      "training 69.29%: 0.428. Loss: 2.3194916248321533\n",
      "training 69.35%: 0.429. Loss: 1.6145128011703491\n",
      "training 69.42%: 0.429. Loss: 1.8287242650985718\n",
      "training 69.48%: 0.429. Loss: 1.418515920639038\n",
      "training 69.55%: 0.429. Loss: 1.7568447589874268\n",
      "training 69.61%: 0.429. Loss: 2.195962429046631\n",
      "training 69.67%: 0.429. Loss: 2.216163158416748\n",
      "training 69.74%: 0.429. Loss: 1.4029526710510254\n",
      "training 69.80%: 0.429. Loss: 2.3297693729400635\n",
      "training 69.87%: 0.429. Loss: 1.7975767850875854\n",
      "training 69.93%: 0.430. Loss: 1.632554292678833\n",
      "training 69.99%: 0.430. Loss: 2.000864267349243\n",
      "training 70.06%: 0.430. Loss: 2.093820095062256\n",
      "training 70.12%: 0.430. Loss: 1.6682486534118652\n",
      "training 70.19%: 0.430. Loss: 2.4001119136810303\n",
      "training 70.25%: 0.430. Loss: 1.9843157529830933\n",
      "training 70.31%: 0.430. Loss: 1.6955854892730713\n",
      "training 70.38%: 0.430. Loss: 2.007955551147461\n",
      "training 70.44%: 0.430. Loss: 2.1832151412963867\n",
      "training 70.51%: 0.430. Loss: 1.6424216032028198\n",
      "training 70.57%: 0.430. Loss: 2.258636474609375\n",
      "training 70.63%: 0.430. Loss: 2.0769083499908447\n",
      "training 70.70%: 0.431. Loss: 1.964590072631836\n",
      "training 70.76%: 0.431. Loss: 1.8103585243225098\n",
      "training 70.83%: 0.431. Loss: 1.7897809743881226\n",
      "training 70.89%: 0.431. Loss: 1.8388811349868774\n",
      "training 70.95%: 0.431. Loss: 1.9240071773529053\n",
      "training 71.02%: 0.431. Loss: 2.0402135848999023\n",
      "training 71.08%: 0.431. Loss: 1.9394844770431519\n",
      "training 71.15%: 0.431. Loss: 2.0326626300811768\n",
      "training 71.21%: 0.431. Loss: 1.7852153778076172\n",
      "training 71.27%: 0.431. Loss: 2.029137372970581\n",
      "training 71.34%: 0.431. Loss: 2.4972965717315674\n",
      "training 71.40%: 0.432. Loss: 1.9091285467147827\n",
      "training 71.47%: 0.432. Loss: 1.6247860193252563\n",
      "training 71.53%: 0.432. Loss: 2.1152448654174805\n",
      "training 71.59%: 0.432. Loss: 2.0114023685455322\n",
      "training 71.66%: 0.432. Loss: 1.6610348224639893\n",
      "training 71.72%: 0.432. Loss: 1.644352912902832\n",
      "training 71.79%: 0.432. Loss: 2.2611215114593506\n",
      "training 71.85%: 0.432. Loss: 2.066265821456909\n",
      "training 71.91%: 0.432. Loss: 1.691473126411438\n",
      "training 71.98%: 0.432. Loss: 2.0757853984832764\n",
      "training 72.04%: 0.432. Loss: 2.016530990600586\n",
      "training 72.10%: 0.432. Loss: 1.9179410934448242\n",
      "training 72.17%: 0.432. Loss: 1.609017252922058\n",
      "training 72.23%: 0.432. Loss: 2.188278913497925\n",
      "training 72.30%: 0.433. Loss: 2.2380242347717285\n",
      "training 72.36%: 0.433. Loss: 1.8787320852279663\n",
      "training 72.42%: 0.433. Loss: 2.0706634521484375\n",
      "training 72.49%: 0.433. Loss: 1.8016386032104492\n",
      "training 72.55%: 0.433. Loss: 1.8662686347961426\n",
      "training 72.62%: 0.433. Loss: 2.0826070308685303\n",
      "training 72.68%: 0.433. Loss: 1.781693458557129\n",
      "training 72.74%: 0.433. Loss: 2.1409528255462646\n",
      "training 72.81%: 0.433. Loss: 2.156494379043579\n",
      "training 72.87%: 0.433. Loss: 1.9772262573242188\n",
      "training 72.94%: 0.433. Loss: 1.9922455549240112\n",
      "training 73.00%: 0.433. Loss: 2.052567481994629\n",
      "training 73.06%: 0.433. Loss: 2.1770412921905518\n",
      "training 73.13%: 0.433. Loss: 2.0398974418640137\n",
      "training 73.19%: 0.434. Loss: 1.9271420240402222\n",
      "training 73.26%: 0.434. Loss: 2.189502000808716\n",
      "training 73.32%: 0.434. Loss: 1.9503707885742188\n",
      "training 73.38%: 0.434. Loss: 1.6982501745224\n",
      "training 73.45%: 0.434. Loss: 2.0108070373535156\n",
      "training 73.51%: 0.434. Loss: 2.0709266662597656\n",
      "training 73.58%: 0.434. Loss: 2.0273616313934326\n",
      "training 73.64%: 0.434. Loss: 1.88298499584198\n",
      "training 73.70%: 0.434. Loss: 1.9336460828781128\n",
      "training 73.77%: 0.434. Loss: 1.9568921327590942\n",
      "training 73.83%: 0.434. Loss: 1.8231499195098877\n",
      "training 73.90%: 0.434. Loss: 1.6309205293655396\n",
      "training 73.96%: 0.434. Loss: 1.9661571979522705\n",
      "training 74.02%: 0.434. Loss: 1.9455251693725586\n",
      "training 74.09%: 0.434. Loss: 2.2065694332122803\n",
      "training 74.15%: 0.434. Loss: 1.935052514076233\n",
      "training 74.22%: 0.435. Loss: 2.0962672233581543\n",
      "training 74.28%: 0.435. Loss: 1.7710847854614258\n",
      "training 74.34%: 0.435. Loss: 2.0721774101257324\n",
      "training 74.41%: 0.435. Loss: 1.5903750658035278\n",
      "training 74.47%: 0.435. Loss: 1.8000108003616333\n",
      "training 74.54%: 0.435. Loss: 1.9584014415740967\n",
      "training 74.60%: 0.435. Loss: 1.8197596073150635\n",
      "training 74.66%: 0.435. Loss: 1.6510745286941528\n",
      "training 74.73%: 0.435. Loss: 1.74960196018219\n",
      "training 74.79%: 0.435. Loss: 1.9828920364379883\n",
      "training 74.86%: 0.436. Loss: 1.989226222038269\n",
      "training 74.92%: 0.436. Loss: 1.789278507232666\n",
      "training 74.98%: 0.436. Loss: 1.6451168060302734\n",
      "training 75.05%: 0.436. Loss: 2.264954090118408\n",
      "training 75.11%: 0.436. Loss: 2.323598861694336\n",
      "training 75.18%: 0.436. Loss: 1.921655297279358\n",
      "training 75.24%: 0.436. Loss: 2.0884313583374023\n",
      "training 75.30%: 0.436. Loss: 1.7971888780593872\n",
      "training 75.37%: 0.436. Loss: 1.4909615516662598\n",
      "training 75.43%: 0.436. Loss: 2.0793819427490234\n",
      "training 75.50%: 0.436. Loss: 2.016125202178955\n",
      "training 75.56%: 0.436. Loss: 2.0720815658569336\n",
      "training 75.62%: 0.436. Loss: 2.083850145339966\n",
      "training 75.69%: 0.437. Loss: 1.7276026010513306\n",
      "training 75.75%: 0.437. Loss: 1.6652796268463135\n",
      "training 75.82%: 0.437. Loss: 2.2108747959136963\n",
      "training 75.88%: 0.437. Loss: 1.4610825777053833\n",
      "training 75.94%: 0.437. Loss: 2.279252052307129\n",
      "training 76.01%: 0.437. Loss: 1.8931814432144165\n",
      "training 76.07%: 0.437. Loss: 1.8039138317108154\n",
      "training 76.14%: 0.437. Loss: 1.6170278787612915\n",
      "training 76.20%: 0.437. Loss: 2.047774076461792\n",
      "training 76.26%: 0.437. Loss: 1.8827879428863525\n",
      "training 76.33%: 0.437. Loss: 1.8625850677490234\n",
      "training 76.39%: 0.438. Loss: 1.5371094942092896\n",
      "training 76.46%: 0.438. Loss: 2.0034677982330322\n",
      "training 76.52%: 0.438. Loss: 1.8160792589187622\n",
      "training 76.58%: 0.438. Loss: 2.029444932937622\n",
      "training 76.65%: 0.438. Loss: 1.9722912311553955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 76.71%: 0.438. Loss: 1.8546605110168457\n",
      "training 76.78%: 0.438. Loss: 1.5320018529891968\n",
      "training 76.84%: 0.438. Loss: 1.6969493627548218\n",
      "training 76.90%: 0.438. Loss: 1.788401484489441\n",
      "training 76.97%: 0.438. Loss: 1.6638386249542236\n",
      "training 77.03%: 0.438. Loss: 2.038438081741333\n",
      "training 77.10%: 0.439. Loss: 1.9765979051589966\n",
      "training 77.16%: 0.439. Loss: 2.1935672760009766\n",
      "training 77.22%: 0.439. Loss: 1.8690391778945923\n",
      "training 77.29%: 0.439. Loss: 2.1679155826568604\n",
      "training 77.35%: 0.439. Loss: 1.5343434810638428\n",
      "training 77.42%: 0.439. Loss: 1.500179648399353\n",
      "training 77.48%: 0.439. Loss: 1.6389936208724976\n",
      "training 77.54%: 0.439. Loss: 1.6368151903152466\n",
      "training 77.61%: 0.439. Loss: 2.072878122329712\n",
      "training 77.67%: 0.439. Loss: 1.9476534128189087\n",
      "training 77.74%: 0.439. Loss: 1.9009065628051758\n",
      "training 77.80%: 0.439. Loss: 1.889184832572937\n",
      "training 77.86%: 0.440. Loss: 1.921749234199524\n",
      "training 77.93%: 0.440. Loss: 1.881473183631897\n",
      "training 77.99%: 0.440. Loss: 2.2966842651367188\n",
      "training 78.06%: 0.440. Loss: 2.4596188068389893\n",
      "training 78.12%: 0.440. Loss: 1.8574376106262207\n",
      "training 78.18%: 0.440. Loss: 2.1726622581481934\n",
      "training 78.25%: 0.440. Loss: 2.0162129402160645\n",
      "training 78.31%: 0.440. Loss: 1.928438663482666\n",
      "training 78.37%: 0.440. Loss: 1.8182846307754517\n",
      "training 78.44%: 0.440. Loss: 1.7156611680984497\n",
      "training 78.50%: 0.440. Loss: 2.0719144344329834\n",
      "training 78.57%: 0.440. Loss: 1.8788427114486694\n",
      "training 78.63%: 0.440. Loss: 1.8213683366775513\n",
      "training 78.69%: 0.440. Loss: 1.7123128175735474\n",
      "training 78.76%: 0.440. Loss: 2.1548898220062256\n",
      "training 78.82%: 0.441. Loss: 2.1812760829925537\n",
      "training 78.89%: 0.441. Loss: 1.6490325927734375\n",
      "training 78.95%: 0.441. Loss: 2.37550687789917\n",
      "training 79.01%: 0.441. Loss: 2.06050968170166\n",
      "training 79.08%: 0.441. Loss: 1.7924261093139648\n",
      "training 79.14%: 0.441. Loss: 2.0043482780456543\n",
      "training 79.21%: 0.441. Loss: 2.077238082885742\n",
      "training 79.27%: 0.441. Loss: 1.718204379081726\n",
      "training 79.33%: 0.441. Loss: 2.0323050022125244\n",
      "training 79.40%: 0.441. Loss: 2.1682040691375732\n",
      "training 79.46%: 0.441. Loss: 1.8665810823440552\n",
      "training 79.53%: 0.441. Loss: 1.999890685081482\n",
      "training 79.59%: 0.441. Loss: 1.8087505102157593\n",
      "training 79.65%: 0.441. Loss: 1.926039457321167\n",
      "training 79.72%: 0.442. Loss: 1.8464524745941162\n",
      "training 79.78%: 0.442. Loss: 1.6160292625427246\n",
      "training 79.85%: 0.442. Loss: 1.9550005197525024\n",
      "training 79.91%: 0.442. Loss: 2.289924383163452\n",
      "training 79.97%: 0.442. Loss: 2.362267255783081\n",
      "training 80.04%: 0.442. Loss: 2.0914363861083984\n",
      "training 80.10%: 0.442. Loss: 2.091212749481201\n",
      "training 80.17%: 0.442. Loss: 1.478641152381897\n",
      "training 80.23%: 0.442. Loss: 2.1158032417297363\n",
      "training 80.29%: 0.442. Loss: 2.030273675918579\n",
      "training 80.36%: 0.442. Loss: 1.9977116584777832\n",
      "training 80.42%: 0.442. Loss: 2.264214038848877\n",
      "training 80.49%: 0.442. Loss: 1.7176456451416016\n",
      "training 80.55%: 0.442. Loss: 1.966550588607788\n",
      "training 80.61%: 0.442. Loss: 2.0606324672698975\n",
      "training 80.68%: 0.442. Loss: 2.0714712142944336\n",
      "training 80.74%: 0.442. Loss: 1.8030897378921509\n",
      "training 80.81%: 0.443. Loss: 1.786745309829712\n",
      "training 80.87%: 0.443. Loss: 1.9705106019973755\n",
      "training 80.93%: 0.443. Loss: 1.984541893005371\n",
      "training 81.00%: 0.443. Loss: 2.319955348968506\n",
      "training 81.06%: 0.443. Loss: 1.530588984489441\n",
      "training 81.13%: 0.443. Loss: 1.7377347946166992\n",
      "training 81.19%: 0.443. Loss: 1.998403787612915\n",
      "training 81.25%: 0.443. Loss: 1.9251725673675537\n",
      "training 81.32%: 0.443. Loss: 1.841068148612976\n",
      "training 81.38%: 0.443. Loss: 1.535928726196289\n",
      "training 81.45%: 0.443. Loss: 2.0795738697052\n",
      "training 81.51%: 0.443. Loss: 1.9677672386169434\n",
      "training 81.57%: 0.443. Loss: 1.9572728872299194\n",
      "training 81.64%: 0.443. Loss: 2.1419456005096436\n",
      "training 81.70%: 0.444. Loss: 1.8662474155426025\n",
      "training 81.77%: 0.444. Loss: 1.5915045738220215\n",
      "training 81.83%: 0.444. Loss: 2.12713623046875\n",
      "training 81.89%: 0.444. Loss: 1.7997686862945557\n",
      "training 81.96%: 0.444. Loss: 2.112766981124878\n",
      "training 82.02%: 0.444. Loss: 1.7138599157333374\n",
      "training 82.09%: 0.444. Loss: 1.8895370960235596\n",
      "training 82.15%: 0.444. Loss: 2.0764145851135254\n",
      "training 82.21%: 0.444. Loss: 1.8269461393356323\n",
      "training 82.28%: 0.444. Loss: 1.4515349864959717\n",
      "training 82.34%: 0.444. Loss: 2.0513267517089844\n",
      "training 82.41%: 0.444. Loss: 2.2162747383117676\n",
      "training 82.47%: 0.444. Loss: 1.7253996133804321\n",
      "training 82.53%: 0.444. Loss: 2.3830084800720215\n",
      "training 82.60%: 0.444. Loss: 1.824732780456543\n",
      "training 82.66%: 0.444. Loss: 2.019014835357666\n",
      "training 82.73%: 0.445. Loss: 1.73649263381958\n",
      "training 82.79%: 0.445. Loss: 1.6377311944961548\n",
      "training 82.85%: 0.445. Loss: 2.1207315921783447\n",
      "training 82.92%: 0.445. Loss: 1.8535587787628174\n",
      "training 82.98%: 0.445. Loss: 1.9303187131881714\n",
      "training 83.05%: 0.445. Loss: 1.6562438011169434\n",
      "training 83.11%: 0.445. Loss: 1.597935676574707\n",
      "training 83.17%: 0.445. Loss: 1.7195520401000977\n",
      "training 83.24%: 0.445. Loss: 1.9501234292984009\n",
      "training 83.30%: 0.445. Loss: 1.6172176599502563\n",
      "training 83.37%: 0.445. Loss: 2.7251970767974854\n",
      "training 83.43%: 0.445. Loss: 1.6519485712051392\n",
      "training 83.49%: 0.446. Loss: 1.8383206129074097\n",
      "training 83.56%: 0.446. Loss: 2.1610193252563477\n",
      "training 83.62%: 0.446. Loss: 1.8350633382797241\n",
      "training 83.69%: 0.446. Loss: 1.5274676084518433\n",
      "training 83.75%: 0.446. Loss: 2.1253111362457275\n",
      "training 83.81%: 0.446. Loss: 1.9358530044555664\n",
      "training 83.88%: 0.446. Loss: 2.1556739807128906\n",
      "training 83.94%: 0.446. Loss: 1.6352487802505493\n",
      "training 84.01%: 0.446. Loss: 1.7313443422317505\n",
      "training 84.07%: 0.446. Loss: 1.9486801624298096\n",
      "training 84.13%: 0.446. Loss: 1.5783029794692993\n",
      "training 84.20%: 0.446. Loss: 1.657583236694336\n",
      "training 84.26%: 0.446. Loss: 1.970902919769287\n",
      "training 84.33%: 0.447. Loss: 1.6721338033676147\n",
      "training 84.39%: 0.447. Loss: 2.102536678314209\n",
      "training 84.45%: 0.447. Loss: 1.5772109031677246\n",
      "training 84.52%: 0.447. Loss: 1.755353569984436\n",
      "training 84.58%: 0.447. Loss: 1.8156980276107788\n",
      "training 84.64%: 0.447. Loss: 1.7090747356414795\n",
      "training 84.71%: 0.447. Loss: 2.5286777019500732\n",
      "training 84.77%: 0.447. Loss: 1.7282862663269043\n",
      "training 84.84%: 0.447. Loss: 2.0331509113311768\n",
      "training 84.90%: 0.447. Loss: 1.6234114170074463\n",
      "training 84.96%: 0.447. Loss: 2.3738629817962646\n",
      "training 85.03%: 0.447. Loss: 2.251870632171631\n",
      "training 85.09%: 0.447. Loss: 1.7954075336456299\n",
      "training 85.16%: 0.447. Loss: 2.3366189002990723\n",
      "training 85.22%: 0.447. Loss: 1.6112595796585083\n",
      "training 85.28%: 0.447. Loss: 2.3755955696105957\n",
      "training 85.35%: 0.447. Loss: 1.4016361236572266\n",
      "training 85.41%: 0.448. Loss: 2.0227131843566895\n",
      "training 85.48%: 0.448. Loss: 1.6365582942962646\n",
      "training 85.54%: 0.448. Loss: 1.825566291809082\n",
      "training 85.60%: 0.448. Loss: 1.3130375146865845\n",
      "training 85.67%: 0.448. Loss: 1.6796599626541138\n",
      "training 85.73%: 0.448. Loss: 2.0000224113464355\n",
      "training 85.80%: 0.448. Loss: 1.9437203407287598\n",
      "training 85.86%: 0.448. Loss: 1.5893876552581787\n",
      "training 85.92%: 0.448. Loss: 1.8909337520599365\n",
      "training 85.99%: 0.448. Loss: 1.927268385887146\n",
      "training 86.05%: 0.449. Loss: 1.9573432207107544\n",
      "training 86.12%: 0.449. Loss: 1.9637492895126343\n",
      "training 86.18%: 0.449. Loss: 1.5295844078063965\n",
      "training 86.24%: 0.449. Loss: 1.5243797302246094\n",
      "training 86.31%: 0.449. Loss: 2.0605897903442383\n",
      "training 86.37%: 0.449. Loss: 1.8424755334854126\n",
      "training 86.44%: 0.449. Loss: 2.010867118835449\n",
      "training 86.50%: 0.449. Loss: 2.010261297225952\n",
      "training 86.56%: 0.449. Loss: 1.4018633365631104\n",
      "training 86.63%: 0.449. Loss: 1.6118335723876953\n",
      "training 86.69%: 0.449. Loss: 2.2338480949401855\n",
      "training 86.76%: 0.449. Loss: 2.269375801086426\n",
      "training 86.82%: 0.449. Loss: 1.9409047365188599\n",
      "training 86.88%: 0.449. Loss: 1.7390172481536865\n",
      "training 86.95%: 0.449. Loss: 2.3930366039276123\n",
      "training 87.01%: 0.449. Loss: 2.011662721633911\n",
      "training 87.08%: 0.450. Loss: 1.7894593477249146\n",
      "training 87.14%: 0.450. Loss: 1.9124647378921509\n",
      "training 87.20%: 0.450. Loss: 1.6868505477905273\n",
      "training 87.27%: 0.450. Loss: 1.915518045425415\n",
      "training 87.33%: 0.450. Loss: 1.7566955089569092\n",
      "training 87.40%: 0.450. Loss: 1.8455981016159058\n",
      "training 87.46%: 0.450. Loss: 2.320636510848999\n",
      "training 87.52%: 0.450. Loss: 1.7736848592758179\n",
      "training 87.59%: 0.450. Loss: 2.48684024810791\n",
      "training 87.65%: 0.450. Loss: 1.7641069889068604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 87.72%: 0.450. Loss: 2.3935301303863525\n",
      "training 87.78%: 0.450. Loss: 1.8849172592163086\n",
      "training 87.84%: 0.450. Loss: 1.5495203733444214\n",
      "training 87.91%: 0.450. Loss: 1.774786353111267\n",
      "training 87.97%: 0.450. Loss: 1.6951918601989746\n",
      "training 88.04%: 0.451. Loss: 1.4178000688552856\n",
      "training 88.10%: 0.451. Loss: 1.7381258010864258\n",
      "training 88.16%: 0.451. Loss: 2.2604379653930664\n",
      "training 88.23%: 0.451. Loss: 1.8573390245437622\n",
      "training 88.29%: 0.451. Loss: 1.969932198524475\n",
      "training 88.36%: 0.451. Loss: 2.0646395683288574\n",
      "training 88.42%: 0.451. Loss: 2.083961248397827\n",
      "training 88.48%: 0.451. Loss: 1.7657427787780762\n",
      "training 88.55%: 0.451. Loss: 1.661298394203186\n",
      "training 88.61%: 0.451. Loss: 1.9067137241363525\n",
      "training 88.68%: 0.451. Loss: 2.0902187824249268\n",
      "training 88.74%: 0.451. Loss: 2.1485273838043213\n",
      "training 88.80%: 0.451. Loss: 2.453106641769409\n",
      "training 88.87%: 0.451. Loss: 2.324742078781128\n",
      "training 88.93%: 0.451. Loss: 1.6465091705322266\n",
      "training 89.00%: 0.451. Loss: 1.8280314207077026\n",
      "training 89.06%: 0.451. Loss: 2.1574840545654297\n",
      "training 89.12%: 0.451. Loss: 1.735700011253357\n",
      "training 89.19%: 0.452. Loss: 1.5971314907073975\n",
      "training 89.25%: 0.452. Loss: 1.6992790699005127\n",
      "training 89.32%: 0.452. Loss: 2.135592222213745\n",
      "training 89.38%: 0.452. Loss: 1.8877596855163574\n",
      "training 89.44%: 0.452. Loss: 2.1316099166870117\n",
      "training 89.51%: 0.452. Loss: 1.811086654663086\n",
      "training 89.57%: 0.452. Loss: 2.1642837524414062\n",
      "training 89.64%: 0.452. Loss: 1.8678689002990723\n",
      "training 89.70%: 0.452. Loss: 2.0228288173675537\n",
      "training 89.76%: 0.452. Loss: 1.8577579259872437\n",
      "training 89.83%: 0.452. Loss: 1.8876019716262817\n",
      "training 89.89%: 0.452. Loss: 1.80204176902771\n",
      "training 89.96%: 0.452. Loss: 2.0605804920196533\n",
      "training 90.02%: 0.452. Loss: 2.02673077583313\n",
      "training 90.08%: 0.452. Loss: 1.8606281280517578\n",
      "training 90.15%: 0.452. Loss: 1.857848882675171\n",
      "training 90.21%: 0.453. Loss: 1.5050382614135742\n",
      "training 90.28%: 0.453. Loss: 1.5365979671478271\n",
      "training 90.34%: 0.453. Loss: 2.3026206493377686\n",
      "training 90.40%: 0.453. Loss: 1.7976276874542236\n",
      "training 90.47%: 0.453. Loss: 1.3312797546386719\n",
      "training 90.53%: 0.453. Loss: 1.7139856815338135\n",
      "training 90.60%: 0.453. Loss: 1.8859928846359253\n",
      "training 90.66%: 0.453. Loss: 1.7366414070129395\n",
      "training 90.72%: 0.453. Loss: 1.6682502031326294\n",
      "training 90.79%: 0.453. Loss: 1.816040277481079\n",
      "training 90.85%: 0.453. Loss: 1.6991304159164429\n",
      "training 90.91%: 0.453. Loss: 1.8194547891616821\n",
      "training 90.98%: 0.453. Loss: 2.1800386905670166\n",
      "training 91.04%: 0.454. Loss: 1.6445387601852417\n",
      "training 91.11%: 0.454. Loss: 1.978132963180542\n",
      "training 91.17%: 0.454. Loss: 2.4205033779144287\n",
      "training 91.23%: 0.454. Loss: 2.2447617053985596\n",
      "training 91.30%: 0.454. Loss: 1.927985668182373\n",
      "training 91.36%: 0.454. Loss: 1.964798927307129\n",
      "training 91.43%: 0.454. Loss: 1.647168517112732\n",
      "training 91.49%: 0.454. Loss: 1.696400761604309\n",
      "training 91.55%: 0.454. Loss: 2.0534050464630127\n",
      "training 91.62%: 0.454. Loss: 2.056018352508545\n",
      "training 91.68%: 0.454. Loss: 1.8542572259902954\n",
      "training 91.75%: 0.454. Loss: 1.914005160331726\n",
      "training 91.81%: 0.454. Loss: 2.063199996948242\n",
      "training 91.87%: 0.454. Loss: 1.7676459550857544\n",
      "training 91.94%: 0.454. Loss: 2.1549336910247803\n",
      "training 92.00%: 0.454. Loss: 2.0439634323120117\n",
      "training 92.07%: 0.454. Loss: 2.0623714923858643\n",
      "training 92.13%: 0.454. Loss: 1.9403150081634521\n",
      "training 92.19%: 0.454. Loss: 1.589021921157837\n",
      "training 92.26%: 0.454. Loss: 1.8303070068359375\n",
      "training 92.32%: 0.454. Loss: 1.8243361711502075\n",
      "training 92.39%: 0.455. Loss: 1.431088924407959\n",
      "training 92.45%: 0.455. Loss: 1.8984861373901367\n",
      "training 92.51%: 0.455. Loss: 1.755727767944336\n",
      "training 92.58%: 0.455. Loss: 1.4641618728637695\n",
      "training 92.64%: 0.455. Loss: 2.188477039337158\n",
      "training 92.71%: 0.455. Loss: 1.5875924825668335\n",
      "training 92.77%: 0.455. Loss: 1.851776361465454\n",
      "training 92.83%: 0.455. Loss: 2.7543466091156006\n",
      "training 92.90%: 0.455. Loss: 2.048839807510376\n",
      "training 92.96%: 0.455. Loss: 2.015707015991211\n",
      "training 93.03%: 0.455. Loss: 1.8313180208206177\n",
      "training 93.09%: 0.455. Loss: 1.8534436225891113\n",
      "training 93.15%: 0.455. Loss: 2.45458722114563\n",
      "training 93.22%: 0.455. Loss: 1.8067376613616943\n",
      "training 93.28%: 0.456. Loss: 1.8193118572235107\n",
      "training 93.35%: 0.456. Loss: 1.816732406616211\n",
      "training 93.41%: 0.456. Loss: 1.7993360757827759\n",
      "training 93.47%: 0.456. Loss: 1.4210001230239868\n",
      "training 93.54%: 0.456. Loss: 1.9772262573242188\n",
      "training 93.60%: 0.456. Loss: 1.6967365741729736\n",
      "training 93.67%: 0.456. Loss: 1.8858574628829956\n",
      "training 93.73%: 0.456. Loss: 1.2933006286621094\n",
      "training 93.79%: 0.456. Loss: 2.232483386993408\n",
      "training 93.86%: 0.456. Loss: 2.139010429382324\n",
      "training 93.92%: 0.456. Loss: 1.945397973060608\n",
      "training 93.99%: 0.456. Loss: 1.9306702613830566\n",
      "training 94.05%: 0.456. Loss: 2.003453016281128\n",
      "training 94.11%: 0.457. Loss: 2.0914347171783447\n",
      "training 94.18%: 0.457. Loss: 2.4239470958709717\n",
      "training 94.24%: 0.457. Loss: 1.7180429697036743\n",
      "training 94.31%: 0.457. Loss: 1.599188208580017\n",
      "training 94.37%: 0.457. Loss: 1.8048980236053467\n",
      "training 94.43%: 0.457. Loss: 1.5676019191741943\n",
      "training 94.50%: 0.457. Loss: 1.7321341037750244\n",
      "training 94.56%: 0.457. Loss: 1.6030482053756714\n",
      "training 94.63%: 0.457. Loss: 1.5678211450576782\n",
      "training 94.69%: 0.457. Loss: 1.7586745023727417\n",
      "training 94.75%: 0.457. Loss: 2.1433961391448975\n",
      "training 94.82%: 0.457. Loss: 1.7800503969192505\n",
      "training 94.88%: 0.457. Loss: 2.352783679962158\n",
      "training 94.95%: 0.457. Loss: 1.949281096458435\n",
      "training 95.01%: 0.457. Loss: 1.9009122848510742\n",
      "training 95.07%: 0.457. Loss: 1.7942044734954834\n",
      "training 95.14%: 0.457. Loss: 1.7066264152526855\n",
      "training 95.20%: 0.457. Loss: 1.3104108572006226\n",
      "training 95.27%: 0.457. Loss: 2.4072377681732178\n",
      "training 95.33%: 0.457. Loss: 1.9926270246505737\n",
      "training 95.39%: 0.457. Loss: 1.606584072113037\n",
      "training 95.46%: 0.458. Loss: 1.8469215631484985\n",
      "training 95.52%: 0.458. Loss: 2.097052812576294\n",
      "training 95.59%: 0.458. Loss: 2.20109224319458\n",
      "training 95.65%: 0.458. Loss: 1.9631199836730957\n",
      "training 95.71%: 0.458. Loss: 1.9134091138839722\n",
      "training 95.78%: 0.458. Loss: 2.1114237308502197\n",
      "training 95.84%: 0.458. Loss: 1.7561649084091187\n",
      "training 95.91%: 0.458. Loss: 1.7161492109298706\n",
      "training 95.97%: 0.458. Loss: 1.8639806509017944\n",
      "training 96.03%: 0.458. Loss: 1.9485589265823364\n",
      "training 96.10%: 0.458. Loss: 1.9336825609207153\n",
      "training 96.16%: 0.458. Loss: 2.029899835586548\n",
      "training 96.23%: 0.458. Loss: 1.8125848770141602\n",
      "training 96.29%: 0.458. Loss: 1.7355501651763916\n",
      "training 96.35%: 0.458. Loss: 1.6152093410491943\n",
      "training 96.42%: 0.458. Loss: 1.6186578273773193\n",
      "training 96.48%: 0.458. Loss: 1.8106417655944824\n",
      "training 96.55%: 0.459. Loss: 1.4616891145706177\n",
      "training 96.61%: 0.459. Loss: 1.838225245475769\n",
      "training 96.67%: 0.459. Loss: 1.7691044807434082\n",
      "training 96.74%: 0.459. Loss: 2.2715556621551514\n",
      "training 96.80%: 0.459. Loss: 1.9420214891433716\n",
      "training 96.87%: 0.459. Loss: 1.8235682249069214\n",
      "training 96.93%: 0.459. Loss: 1.8839092254638672\n",
      "training 96.99%: 0.459. Loss: 2.0138986110687256\n",
      "training 97.06%: 0.459. Loss: 1.6626096963882446\n",
      "training 97.12%: 0.459. Loss: 1.771294355392456\n",
      "training 97.18%: 0.459. Loss: 1.5221439599990845\n",
      "training 97.25%: 0.459. Loss: 2.3118362426757812\n",
      "training 97.31%: 0.459. Loss: 2.3173327445983887\n",
      "training 97.38%: 0.459. Loss: 1.552239179611206\n",
      "training 97.44%: 0.459. Loss: 1.765620470046997\n",
      "training 97.50%: 0.459. Loss: 2.0414836406707764\n",
      "training 97.57%: 0.459. Loss: 1.879902958869934\n",
      "training 97.63%: 0.459. Loss: 2.005849838256836\n",
      "training 97.70%: 0.459. Loss: 1.9208160638809204\n",
      "training 97.76%: 0.459. Loss: 1.7960543632507324\n",
      "training 97.82%: 0.460. Loss: 1.7679121494293213\n",
      "training 97.89%: 0.460. Loss: 1.4934793710708618\n",
      "training 97.95%: 0.460. Loss: 1.7671877145767212\n",
      "training 98.02%: 0.460. Loss: 1.581318974494934\n",
      "training 98.08%: 0.460. Loss: 1.7000048160552979\n",
      "training 98.14%: 0.460. Loss: 2.0226330757141113\n",
      "training 98.21%: 0.460. Loss: 1.856793761253357\n",
      "training 98.27%: 0.460. Loss: 2.170332908630371\n",
      "training 98.34%: 0.460. Loss: 2.0051615238189697\n",
      "training 98.40%: 0.460. Loss: 1.9044755697250366\n",
      "training 98.46%: 0.460. Loss: 1.7515296936035156\n",
      "training 98.53%: 0.460. Loss: 2.0732667446136475\n",
      "training 98.59%: 0.460. Loss: 1.7591407299041748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 98.66%: 0.460. Loss: 1.791692852973938\n",
      "training 98.72%: 0.460. Loss: 1.7567312717437744\n",
      "training 98.78%: 0.460. Loss: 1.6418428421020508\n",
      "training 98.85%: 0.460. Loss: 1.9651962518692017\n",
      "training 98.91%: 0.460. Loss: 2.01298451423645\n",
      "training 98.98%: 0.461. Loss: 1.8639616966247559\n",
      "training 99.04%: 0.461. Loss: 1.8421889543533325\n",
      "training 99.10%: 0.461. Loss: 1.480391502380371\n",
      "training 99.17%: 0.461. Loss: 1.553377389907837\n",
      "training 99.23%: 0.461. Loss: 1.7033357620239258\n",
      "training 99.30%: 0.461. Loss: 1.9888150691986084\n",
      "training 99.36%: 0.461. Loss: 1.8872214555740356\n",
      "training 99.42%: 0.461. Loss: 2.0243453979492188\n",
      "training 99.49%: 0.461. Loss: 1.4541165828704834\n",
      "training 99.55%: 0.461. Loss: 1.9480522871017456\n",
      "training 99.62%: 0.461. Loss: 1.8222932815551758\n",
      "training 99.68%: 0.461. Loss: 2.039240837097168\n",
      "training 99.74%: 0.461. Loss: 1.6301279067993164\n",
      "training 99.81%: 0.461. Loss: 1.8701231479644775\n",
      "training 99.87%: 0.461. Loss: 2.1719167232513428\n",
      "training 99.94%: 0.462. Loss: 1.9107404947280884\n",
      "val 0.00%: 0.453. Loss: 2.080535650253296\n",
      "val 0.64%: 0.547. Loss: 1.6096097230911255\n",
      "val 1.27%: 0.536. Loss: 1.919214129447937\n",
      "val 1.91%: 0.543. Loss: 1.7182563543319702\n",
      "val 2.55%: 0.544. Loss: 1.906182885169983\n",
      "val 3.18%: 0.536. Loss: 1.9604631662368774\n",
      "val 3.82%: 0.542. Loss: 1.7471529245376587\n",
      "val 4.46%: 0.537. Loss: 2.212768316268921\n",
      "val 5.10%: 0.547. Loss: 1.6594775915145874\n",
      "val 5.73%: 0.547. Loss: 1.6378965377807617\n",
      "val 6.37%: 0.538. Loss: 2.1278772354125977\n",
      "val 7.01%: 0.546. Loss: 1.5831489562988281\n",
      "val 7.64%: 0.540. Loss: 2.099207878112793\n",
      "val 8.28%: 0.542. Loss: 1.616513967514038\n",
      "val 8.92%: 0.534. Loss: 2.1731648445129395\n",
      "val 9.55%: 0.540. Loss: 1.6199880838394165\n",
      "val 10.19%: 0.542. Loss: 1.6003605127334595\n",
      "val 10.83%: 0.543. Loss: 1.8364166021347046\n",
      "val 11.46%: 0.546. Loss: 1.8517261743545532\n",
      "val 12.10%: 0.542. Loss: 1.930952787399292\n",
      "val 12.74%: 0.547. Loss: 1.740084171295166\n",
      "val 13.38%: 0.544. Loss: 1.9395639896392822\n",
      "val 14.01%: 0.542. Loss: 1.545605182647705\n",
      "val 14.65%: 0.547. Loss: 1.6074894666671753\n",
      "val 15.29%: 0.551. Loss: 1.59418523311615\n",
      "val 15.92%: 0.548. Loss: 1.9497227668762207\n",
      "val 16.56%: 0.550. Loss: 1.7226382493972778\n",
      "val 17.20%: 0.549. Loss: 1.851766586303711\n",
      "val 17.83%: 0.549. Loss: 1.7361611127853394\n",
      "val 18.47%: 0.547. Loss: 2.1193764209747314\n",
      "val 19.11%: 0.545. Loss: 2.1918981075286865\n",
      "val 19.75%: 0.546. Loss: 1.654164433479309\n",
      "val 20.38%: 0.549. Loss: 1.6249783039093018\n",
      "val 21.02%: 0.550. Loss: 1.7206672430038452\n",
      "val 21.66%: 0.552. Loss: 1.6755831241607666\n",
      "val 22.29%: 0.551. Loss: 2.219789981842041\n",
      "val 22.93%: 0.552. Loss: 1.7580957412719727\n",
      "val 23.57%: 0.553. Loss: 1.668232798576355\n",
      "val 24.20%: 0.551. Loss: 1.9486773014068604\n",
      "val 24.84%: 0.554. Loss: 1.4337384700775146\n",
      "val 25.48%: 0.552. Loss: 1.7725375890731812\n",
      "val 26.11%: 0.553. Loss: 1.5586320161819458\n",
      "val 26.75%: 0.554. Loss: 1.9782657623291016\n",
      "val 27.39%: 0.553. Loss: 1.9226239919662476\n",
      "val 28.03%: 0.552. Loss: 1.9236077070236206\n",
      "val 28.66%: 0.553. Loss: 1.815164566040039\n",
      "val 29.30%: 0.553. Loss: 1.8505009412765503\n",
      "val 29.94%: 0.552. Loss: 1.742446780204773\n",
      "val 30.57%: 0.553. Loss: 1.6824103593826294\n",
      "val 31.21%: 0.553. Loss: 1.8567914962768555\n",
      "val 31.85%: 0.552. Loss: 1.8947198390960693\n",
      "val 32.48%: 0.551. Loss: 1.6605117321014404\n",
      "val 33.12%: 0.550. Loss: 2.0197463035583496\n",
      "val 33.76%: 0.549. Loss: 1.9379656314849854\n",
      "val 34.39%: 0.548. Loss: 1.8330802917480469\n",
      "val 35.03%: 0.548. Loss: 1.7980307340621948\n",
      "val 35.67%: 0.549. Loss: 1.5411428213119507\n",
      "val 36.31%: 0.547. Loss: 2.166142225265503\n",
      "val 36.94%: 0.548. Loss: 2.026735544204712\n",
      "val 37.58%: 0.549. Loss: 1.5068950653076172\n",
      "val 38.22%: 0.548. Loss: 1.8492401838302612\n",
      "val 38.85%: 0.548. Loss: 2.1466434001922607\n",
      "val 39.49%: 0.550. Loss: 1.6344008445739746\n",
      "val 40.13%: 0.549. Loss: 2.0882656574249268\n",
      "val 40.76%: 0.549. Loss: 1.9100152254104614\n",
      "val 41.40%: 0.548. Loss: 2.00211763381958\n",
      "val 42.04%: 0.547. Loss: 2.1392743587493896\n",
      "val 42.68%: 0.548. Loss: 2.0112862586975098\n",
      "val 43.31%: 0.548. Loss: 1.665700912475586\n",
      "val 43.95%: 0.550. Loss: 1.3853892087936401\n",
      "val 44.59%: 0.550. Loss: 1.9588619470596313\n",
      "val 45.22%: 0.549. Loss: 2.1401209831237793\n",
      "val 45.86%: 0.551. Loss: 1.3205249309539795\n",
      "val 46.50%: 0.550. Loss: 2.1478676795959473\n",
      "val 47.13%: 0.550. Loss: 1.5675278902053833\n",
      "val 47.77%: 0.550. Loss: 2.062222719192505\n",
      "val 48.41%: 0.551. Loss: 1.608100414276123\n",
      "val 49.04%: 0.550. Loss: 1.8939393758773804\n",
      "val 49.68%: 0.551. Loss: 1.978395700454712\n",
      "val 50.32%: 0.551. Loss: 1.8298230171203613\n",
      "val 50.96%: 0.551. Loss: 1.5892921686172485\n",
      "val 51.59%: 0.553. Loss: 1.562786340713501\n",
      "val 52.23%: 0.553. Loss: 2.1029818058013916\n",
      "val 52.87%: 0.553. Loss: 1.9605456590652466\n",
      "val 53.50%: 0.553. Loss: 1.6160304546356201\n",
      "val 54.14%: 0.555. Loss: 1.2665393352508545\n",
      "val 54.78%: 0.554. Loss: 1.8801724910736084\n",
      "val 55.41%: 0.555. Loss: 1.6676850318908691\n",
      "val 56.05%: 0.554. Loss: 1.995364785194397\n",
      "val 56.69%: 0.554. Loss: 1.8357511758804321\n",
      "val 57.32%: 0.554. Loss: 1.6438655853271484\n",
      "val 57.96%: 0.554. Loss: 1.917557954788208\n",
      "val 58.60%: 0.555. Loss: 1.704466462135315\n",
      "val 59.24%: 0.555. Loss: 1.893330454826355\n",
      "val 59.87%: 0.556. Loss: 1.4070243835449219\n",
      "val 60.51%: 0.556. Loss: 1.6445342302322388\n",
      "val 61.15%: 0.556. Loss: 1.9769494533538818\n",
      "val 61.78%: 0.556. Loss: 1.964363694190979\n",
      "val 62.42%: 0.556. Loss: 1.7802757024765015\n",
      "val 63.06%: 0.556. Loss: 1.7376841306686401\n",
      "val 63.69%: 0.555. Loss: 2.151327610015869\n",
      "val 64.33%: 0.555. Loss: 1.668134331703186\n",
      "val 64.97%: 0.553. Loss: 2.227126121520996\n",
      "val 65.61%: 0.554. Loss: 1.6915181875228882\n",
      "val 66.24%: 0.554. Loss: 1.6039910316467285\n",
      "val 66.88%: 0.555. Loss: 1.5947130918502808\n",
      "val 67.52%: 0.555. Loss: 1.7787822484970093\n",
      "val 68.15%: 0.554. Loss: 2.4265615940093994\n",
      "val 68.79%: 0.554. Loss: 1.8187460899353027\n",
      "val 69.43%: 0.553. Loss: 2.327035665512085\n",
      "val 70.06%: 0.552. Loss: 1.772815465927124\n",
      "val 70.70%: 0.553. Loss: 1.9205397367477417\n",
      "val 71.34%: 0.553. Loss: 1.3677417039871216\n",
      "val 71.97%: 0.553. Loss: 2.079939842224121\n",
      "val 72.61%: 0.554. Loss: 1.2999277114868164\n",
      "val 73.25%: 0.554. Loss: 2.0971479415893555\n",
      "val 73.89%: 0.553. Loss: 1.874287724494934\n",
      "val 74.52%: 0.553. Loss: 1.839756965637207\n",
      "val 75.16%: 0.554. Loss: 1.6050165891647339\n",
      "val 75.80%: 0.554. Loss: 1.6758828163146973\n",
      "val 76.43%: 0.555. Loss: 1.3952161073684692\n",
      "val 77.07%: 0.556. Loss: 1.3926434516906738\n",
      "val 77.71%: 0.555. Loss: 1.9548368453979492\n",
      "val 78.34%: 0.555. Loss: 1.6367071866989136\n",
      "val 78.98%: 0.555. Loss: 1.8804757595062256\n",
      "val 79.62%: 0.556. Loss: 1.6739705801010132\n",
      "val 80.25%: 0.556. Loss: 1.7842060327529907\n",
      "val 80.89%: 0.555. Loss: 2.0484869480133057\n",
      "val 81.53%: 0.555. Loss: 1.8847172260284424\n",
      "val 82.17%: 0.556. Loss: 1.42611563205719\n",
      "val 82.80%: 0.556. Loss: 1.9172859191894531\n",
      "val 83.44%: 0.556. Loss: 1.8536819219589233\n",
      "val 84.08%: 0.556. Loss: 1.6663432121276855\n",
      "val 84.71%: 0.556. Loss: 1.7209094762802124\n",
      "val 85.35%: 0.556. Loss: 1.9898799657821655\n",
      "val 85.99%: 0.556. Loss: 1.6093134880065918\n",
      "val 86.62%: 0.556. Loss: 1.766819715499878\n",
      "val 87.26%: 0.556. Loss: 1.9857697486877441\n",
      "val 87.90%: 0.556. Loss: 1.5081865787506104\n",
      "val 88.54%: 0.556. Loss: 1.7484134435653687\n",
      "val 89.17%: 0.556. Loss: 1.9044989347457886\n",
      "val 89.81%: 0.557. Loss: 1.234641671180725\n",
      "val 90.45%: 0.557. Loss: 1.4969042539596558\n",
      "val 91.08%: 0.557. Loss: 1.7379920482635498\n",
      "val 91.72%: 0.558. Loss: 1.7805582284927368\n",
      "val 92.36%: 0.557. Loss: 1.9207398891448975\n",
      "val 92.99%: 0.558. Loss: 1.3954979181289673\n",
      "val 93.63%: 0.558. Loss: 1.742327332496643\n",
      "val 94.27%: 0.558. Loss: 1.390632152557373\n",
      "val 94.90%: 0.557. Loss: 1.8926538228988647\n",
      "val 95.54%: 0.558. Loss: 1.3897533416748047\n",
      "val 96.18%: 0.558. Loss: 1.5839763879776\n",
      "val 96.82%: 0.559. Loss: 1.6137492656707764\n",
      "val 97.45%: 0.558. Loss: 1.906761884689331\n",
      "val 98.09%: 0.558. Loss: 2.2059528827667236\n",
      "val 98.73%: 0.558. Loss: 1.8995686769485474\n",
      "val 99.36%: 0.558. Loss: 1.8666996955871582\n",
      "training 0.00%: 0.562. Loss: 1.7713919878005981\n",
      "training 0.06%: 0.555. Loss: 1.6738392114639282\n",
      "training 0.13%: 0.557. Loss: 2.06571364402771\n",
      "training 0.19%: 0.543. Loss: 1.9756065607070923\n",
      "training 0.26%: 0.572. Loss: 1.460619568824768\n",
      "training 0.32%: 0.589. Loss: 1.2428778409957886\n",
      "training 0.38%: 0.598. Loss: 1.4473416805267334\n",
      "training 0.45%: 0.604. Loss: 1.3382271528244019\n",
      "training 0.51%: 0.602. Loss: 1.6853878498077393\n",
      "training 0.58%: 0.602. Loss: 1.7661675214767456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 0.64%: 0.599. Loss: 1.2813440561294556\n",
      "training 0.70%: 0.598. Loss: 1.8137145042419434\n",
      "training 0.77%: 0.596. Loss: 1.9106839895248413\n",
      "training 0.83%: 0.590. Loss: 2.0050625801086426\n",
      "training 0.90%: 0.589. Loss: 2.028669595718384\n",
      "training 0.96%: 0.590. Loss: 1.7567466497421265\n",
      "training 1.02%: 0.588. Loss: 1.7246710062026978\n",
      "training 1.09%: 0.582. Loss: 1.897411823272705\n",
      "training 1.15%: 0.586. Loss: 1.3960033655166626\n",
      "training 1.22%: 0.584. Loss: 1.6461031436920166\n",
      "training 1.28%: 0.581. Loss: 1.7312006950378418\n",
      "training 1.34%: 0.581. Loss: 1.8368231058120728\n",
      "training 1.41%: 0.584. Loss: 1.506923794746399\n",
      "training 1.47%: 0.587. Loss: 1.423479437828064\n",
      "training 1.54%: 0.588. Loss: 1.7620495557785034\n",
      "training 1.60%: 0.594. Loss: 1.2846795320510864\n",
      "training 1.66%: 0.590. Loss: 1.9682427644729614\n",
      "training 1.73%: 0.588. Loss: 2.0473318099975586\n",
      "training 1.79%: 0.588. Loss: 1.581168293952942\n",
      "training 1.86%: 0.590. Loss: 1.404020071029663\n",
      "training 1.92%: 0.588. Loss: 1.8438665866851807\n",
      "training 1.98%: 0.588. Loss: 1.7691764831542969\n",
      "training 2.05%: 0.586. Loss: 1.731239676475525\n",
      "training 2.11%: 0.588. Loss: 1.4194681644439697\n",
      "training 2.18%: 0.587. Loss: 1.7238028049468994\n",
      "training 2.24%: 0.586. Loss: 1.469769835472107\n",
      "training 2.30%: 0.585. Loss: 1.774640440940857\n",
      "training 2.37%: 0.583. Loss: 1.3994231224060059\n",
      "training 2.43%: 0.582. Loss: 1.7389893531799316\n",
      "training 2.50%: 0.583. Loss: 1.5112571716308594\n",
      "training 2.56%: 0.582. Loss: 1.9605300426483154\n",
      "training 2.62%: 0.580. Loss: 2.084989547729492\n",
      "training 2.69%: 0.582. Loss: 1.528145670890808\n",
      "training 2.75%: 0.582. Loss: 1.5539766550064087\n",
      "training 2.82%: 0.577. Loss: 2.575690746307373\n",
      "training 2.88%: 0.578. Loss: 1.4970548152923584\n",
      "training 2.94%: 0.580. Loss: 1.4541760683059692\n",
      "training 3.01%: 0.579. Loss: 1.991632342338562\n",
      "training 3.07%: 0.579. Loss: 1.685330867767334\n",
      "training 3.13%: 0.580. Loss: 1.598828911781311\n",
      "training 3.20%: 0.581. Loss: 1.6004996299743652\n",
      "training 3.26%: 0.582. Loss: 1.5555438995361328\n",
      "training 3.33%: 0.585. Loss: 1.103776454925537\n",
      "training 3.39%: 0.584. Loss: 1.819624662399292\n",
      "training 3.45%: 0.583. Loss: 1.7239691019058228\n",
      "training 3.52%: 0.584. Loss: 1.7295846939086914\n",
      "training 3.58%: 0.584. Loss: 1.8097779750823975\n",
      "training 3.65%: 0.584. Loss: 1.558095932006836\n",
      "training 3.71%: 0.583. Loss: 2.0140109062194824\n",
      "training 3.77%: 0.584. Loss: 1.5876508951187134\n",
      "training 3.84%: 0.585. Loss: 1.659787893295288\n",
      "training 3.90%: 0.583. Loss: 1.7094234228134155\n",
      "training 3.97%: 0.584. Loss: 1.5499359369277954\n",
      "training 4.03%: 0.583. Loss: 2.08705997467041\n",
      "training 4.09%: 0.584. Loss: 1.6405441761016846\n",
      "training 4.16%: 0.583. Loss: 1.5375322103500366\n",
      "training 4.22%: 0.583. Loss: 1.4445059299468994\n",
      "training 4.29%: 0.583. Loss: 1.8252092599868774\n",
      "training 4.35%: 0.582. Loss: 1.9752575159072876\n",
      "training 4.41%: 0.582. Loss: 1.6142826080322266\n",
      "training 4.48%: 0.582. Loss: 1.5869566202163696\n",
      "training 4.54%: 0.582. Loss: 1.5469890832901\n",
      "training 4.61%: 0.582. Loss: 1.5357908010482788\n",
      "training 4.67%: 0.582. Loss: 1.7726171016693115\n",
      "training 4.73%: 0.583. Loss: 1.5450984239578247\n",
      "training 4.80%: 0.583. Loss: 1.6205579042434692\n",
      "training 4.86%: 0.583. Loss: 1.9488660097122192\n",
      "training 4.93%: 0.583. Loss: 1.8827208280563354\n",
      "training 4.99%: 0.582. Loss: 1.7379815578460693\n",
      "training 5.05%: 0.583. Loss: 1.8003753423690796\n",
      "training 5.12%: 0.583. Loss: 1.5678383111953735\n",
      "training 5.18%: 0.583. Loss: 1.7046542167663574\n",
      "training 5.25%: 0.583. Loss: 1.8380217552185059\n",
      "training 5.31%: 0.584. Loss: 1.491252064704895\n",
      "training 5.37%: 0.582. Loss: 1.9584264755249023\n",
      "training 5.44%: 0.582. Loss: 1.8120625019073486\n",
      "training 5.50%: 0.581. Loss: 1.7865010499954224\n",
      "training 5.57%: 0.581. Loss: 1.4547061920166016\n",
      "training 5.63%: 0.581. Loss: 2.1441447734832764\n",
      "training 5.69%: 0.581. Loss: 1.8792144060134888\n",
      "training 5.76%: 0.582. Loss: 1.4097986221313477\n",
      "training 5.82%: 0.583. Loss: 1.576882004737854\n",
      "training 5.89%: 0.583. Loss: 1.9319521188735962\n",
      "training 5.95%: 0.582. Loss: 1.5993165969848633\n",
      "training 6.01%: 0.582. Loss: 1.512241244316101\n",
      "training 6.08%: 0.583. Loss: 1.964394450187683\n",
      "training 6.14%: 0.583. Loss: 1.4557297229766846\n",
      "training 6.21%: 0.583. Loss: 1.2669281959533691\n",
      "training 6.27%: 0.583. Loss: 1.6962586641311646\n",
      "training 6.33%: 0.584. Loss: 1.4071567058563232\n",
      "training 6.40%: 0.584. Loss: 1.646288275718689\n",
      "training 6.46%: 0.583. Loss: 1.561191439628601\n",
      "training 6.53%: 0.582. Loss: 2.1697819232940674\n",
      "training 6.59%: 0.581. Loss: 1.8253297805786133\n",
      "training 6.65%: 0.582. Loss: 1.2434532642364502\n",
      "training 6.72%: 0.582. Loss: 2.0167794227600098\n",
      "training 6.78%: 0.581. Loss: 1.9484530687332153\n",
      "training 6.85%: 0.581. Loss: 1.7408275604248047\n",
      "training 6.91%: 0.582. Loss: 1.5175853967666626\n",
      "training 6.97%: 0.581. Loss: 1.7323853969573975\n",
      "training 7.04%: 0.581. Loss: 1.9908121824264526\n",
      "training 7.10%: 0.581. Loss: 1.6915597915649414\n",
      "training 7.17%: 0.581. Loss: 1.4860321283340454\n",
      "training 7.23%: 0.580. Loss: 2.134061098098755\n",
      "training 7.29%: 0.580. Loss: 1.8218903541564941\n",
      "training 7.36%: 0.579. Loss: 1.9983755350112915\n",
      "training 7.42%: 0.580. Loss: 1.5200539827346802\n",
      "training 7.49%: 0.579. Loss: 1.8171584606170654\n",
      "training 7.55%: 0.579. Loss: 1.9521703720092773\n",
      "training 7.61%: 0.578. Loss: 1.9620976448059082\n",
      "training 7.68%: 0.577. Loss: 2.180734634399414\n",
      "training 7.74%: 0.578. Loss: 1.4681124687194824\n",
      "training 7.81%: 0.577. Loss: 1.6175116300582886\n",
      "training 7.87%: 0.577. Loss: 1.7052910327911377\n",
      "training 7.93%: 0.577. Loss: 1.832801342010498\n",
      "training 8.00%: 0.577. Loss: 1.2657796144485474\n",
      "training 8.06%: 0.577. Loss: 1.9832179546356201\n",
      "training 8.13%: 0.577. Loss: 1.5840541124343872\n",
      "training 8.19%: 0.578. Loss: 1.4718281030654907\n",
      "training 8.25%: 0.578. Loss: 2.159449815750122\n",
      "training 8.32%: 0.578. Loss: 1.87076735496521\n",
      "training 8.38%: 0.578. Loss: 1.7367147207260132\n",
      "training 8.45%: 0.578. Loss: 1.7700995206832886\n",
      "training 8.51%: 0.578. Loss: 1.7614598274230957\n",
      "training 8.57%: 0.579. Loss: 1.8640563488006592\n",
      "training 8.64%: 0.578. Loss: 1.9584126472473145\n",
      "training 8.70%: 0.579. Loss: 1.518896460533142\n",
      "training 8.77%: 0.578. Loss: 1.8783797025680542\n",
      "training 8.83%: 0.578. Loss: 1.9760960340499878\n",
      "training 8.89%: 0.579. Loss: 1.523030161857605\n",
      "training 8.96%: 0.579. Loss: 1.802954912185669\n",
      "training 9.02%: 0.580. Loss: 1.3699867725372314\n",
      "training 9.09%: 0.579. Loss: 2.0902554988861084\n",
      "training 9.15%: 0.579. Loss: 1.7405232191085815\n",
      "training 9.21%: 0.580. Loss: 1.6718153953552246\n",
      "training 9.28%: 0.580. Loss: 1.6373037099838257\n",
      "training 9.34%: 0.579. Loss: 1.7660974264144897\n",
      "training 9.40%: 0.579. Loss: 1.7839807271957397\n",
      "training 9.47%: 0.579. Loss: 1.595170021057129\n",
      "training 9.53%: 0.579. Loss: 2.0790958404541016\n",
      "training 9.60%: 0.579. Loss: 1.5479704141616821\n",
      "training 9.66%: 0.579. Loss: 1.8328608274459839\n",
      "training 9.72%: 0.579. Loss: 1.6866934299468994\n",
      "training 9.79%: 0.579. Loss: 1.4596986770629883\n",
      "training 9.85%: 0.579. Loss: 1.5379014015197754\n",
      "training 9.92%: 0.579. Loss: 1.6579365730285645\n",
      "training 9.98%: 0.579. Loss: 1.8423086404800415\n",
      "training 10.04%: 0.578. Loss: 2.212503433227539\n",
      "training 10.11%: 0.578. Loss: 1.7786943912506104\n",
      "training 10.17%: 0.578. Loss: 1.7106921672821045\n",
      "training 10.24%: 0.578. Loss: 1.7327466011047363\n",
      "training 10.30%: 0.578. Loss: 1.7463233470916748\n",
      "training 10.36%: 0.578. Loss: 1.7883164882659912\n",
      "training 10.43%: 0.579. Loss: 1.5885083675384521\n",
      "training 10.49%: 0.579. Loss: 1.6981242895126343\n",
      "training 10.56%: 0.578. Loss: 2.1972949504852295\n",
      "training 10.62%: 0.578. Loss: 1.4985302686691284\n",
      "training 10.68%: 0.578. Loss: 1.3087217807769775\n",
      "training 10.75%: 0.578. Loss: 1.5695379972457886\n",
      "training 10.81%: 0.578. Loss: 1.85805344581604\n",
      "training 10.88%: 0.578. Loss: 1.7033966779708862\n",
      "training 10.94%: 0.578. Loss: 1.8430873155593872\n",
      "training 11.00%: 0.578. Loss: 2.152590036392212\n",
      "training 11.07%: 0.578. Loss: 1.687628984451294\n",
      "training 11.13%: 0.578. Loss: 1.5483957529067993\n",
      "training 11.20%: 0.578. Loss: 1.8715773820877075\n",
      "training 11.26%: 0.578. Loss: 1.7832227945327759\n",
      "training 11.32%: 0.577. Loss: 1.802035927772522\n",
      "training 11.39%: 0.577. Loss: 1.874272108078003\n",
      "training 11.45%: 0.577. Loss: 1.4356260299682617\n",
      "training 11.52%: 0.577. Loss: 1.394214391708374\n",
      "training 11.58%: 0.578. Loss: 1.4982117414474487\n",
      "training 11.64%: 0.578. Loss: 1.8773770332336426\n",
      "training 11.71%: 0.578. Loss: 1.5635921955108643\n",
      "training 11.77%: 0.577. Loss: 1.8560148477554321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 11.84%: 0.577. Loss: 1.8244884014129639\n",
      "training 11.90%: 0.577. Loss: 1.818624496459961\n",
      "training 11.96%: 0.577. Loss: 1.7886536121368408\n",
      "training 12.03%: 0.578. Loss: 1.5640437602996826\n",
      "training 12.09%: 0.578. Loss: 1.4610785245895386\n",
      "training 12.16%: 0.578. Loss: 1.7623475790023804\n",
      "training 12.22%: 0.578. Loss: 1.3905839920043945\n",
      "training 12.28%: 0.579. Loss: 1.6102218627929688\n",
      "training 12.35%: 0.579. Loss: 1.5812227725982666\n",
      "training 12.41%: 0.579. Loss: 1.6936376094818115\n",
      "training 12.48%: 0.578. Loss: 1.5543442964553833\n",
      "training 12.54%: 0.578. Loss: 2.2574374675750732\n",
      "training 12.60%: 0.578. Loss: 1.5035645961761475\n",
      "training 12.67%: 0.578. Loss: 1.956023097038269\n",
      "training 12.73%: 0.578. Loss: 1.556827187538147\n",
      "training 12.80%: 0.578. Loss: 2.3885655403137207\n",
      "training 12.86%: 0.579. Loss: 1.1424384117126465\n",
      "training 12.92%: 0.578. Loss: 1.6134212017059326\n",
      "training 12.99%: 0.578. Loss: 1.9587831497192383\n",
      "training 13.05%: 0.578. Loss: 1.9888325929641724\n",
      "training 13.12%: 0.578. Loss: 1.9655206203460693\n",
      "training 13.18%: 0.577. Loss: 1.6878559589385986\n",
      "training 13.24%: 0.577. Loss: 1.9484410285949707\n",
      "training 13.31%: 0.577. Loss: 1.6566892862319946\n",
      "training 13.37%: 0.577. Loss: 1.8390108346939087\n",
      "training 13.44%: 0.577. Loss: 1.9232640266418457\n",
      "training 13.50%: 0.577. Loss: 1.8015943765640259\n",
      "training 13.56%: 0.577. Loss: 1.8599849939346313\n",
      "training 13.63%: 0.576. Loss: 2.156463861465454\n",
      "training 13.69%: 0.576. Loss: 1.5305976867675781\n",
      "training 13.76%: 0.576. Loss: 1.7491328716278076\n",
      "training 13.82%: 0.577. Loss: 1.6124401092529297\n",
      "training 13.88%: 0.576. Loss: 1.929823875427246\n",
      "training 13.95%: 0.577. Loss: 1.4591611623764038\n",
      "training 14.01%: 0.577. Loss: 1.44235098361969\n",
      "training 14.08%: 0.577. Loss: 1.5866584777832031\n",
      "training 14.14%: 0.577. Loss: 1.2944252490997314\n",
      "training 14.20%: 0.577. Loss: 1.9470759630203247\n",
      "training 14.27%: 0.576. Loss: 1.880879282951355\n",
      "training 14.33%: 0.576. Loss: 1.92770516872406\n",
      "training 14.40%: 0.576. Loss: 1.6798022985458374\n",
      "training 14.46%: 0.575. Loss: 2.486768960952759\n",
      "training 14.52%: 0.575. Loss: 1.602255940437317\n",
      "training 14.59%: 0.576. Loss: 1.27373206615448\n",
      "training 14.65%: 0.576. Loss: 1.0946532487869263\n",
      "training 14.72%: 0.576. Loss: 1.7358874082565308\n",
      "training 14.78%: 0.576. Loss: 1.5433058738708496\n",
      "training 14.84%: 0.576. Loss: 1.7338392734527588\n",
      "training 14.91%: 0.577. Loss: 1.5105613470077515\n",
      "training 14.97%: 0.576. Loss: 1.8980536460876465\n",
      "training 15.04%: 0.577. Loss: 1.393763780593872\n",
      "training 15.10%: 0.577. Loss: 1.8096232414245605\n",
      "training 15.16%: 0.576. Loss: 2.007122278213501\n",
      "training 15.23%: 0.576. Loss: 1.8726935386657715\n",
      "training 15.29%: 0.576. Loss: 2.1141934394836426\n",
      "training 15.36%: 0.576. Loss: 1.5206518173217773\n",
      "training 15.42%: 0.576. Loss: 1.73712158203125\n",
      "training 15.48%: 0.575. Loss: 2.1715261936187744\n",
      "training 15.55%: 0.575. Loss: 1.9315848350524902\n",
      "training 15.61%: 0.575. Loss: 1.6609463691711426\n",
      "training 15.67%: 0.575. Loss: 1.7029377222061157\n",
      "training 15.74%: 0.575. Loss: 1.4988510608673096\n",
      "training 15.80%: 0.576. Loss: 1.2628685235977173\n",
      "training 15.87%: 0.576. Loss: 1.5752652883529663\n",
      "training 15.93%: 0.576. Loss: 1.6905511617660522\n",
      "training 15.99%: 0.576. Loss: 1.405419111251831\n",
      "training 16.06%: 0.576. Loss: 1.8946315050125122\n",
      "training 16.12%: 0.576. Loss: 1.505773901939392\n",
      "training 16.19%: 0.576. Loss: 1.4335166215896606\n",
      "training 16.25%: 0.576. Loss: 1.6664282083511353\n",
      "training 16.31%: 0.576. Loss: 1.6414462327957153\n",
      "training 16.38%: 0.576. Loss: 1.5994285345077515\n",
      "training 16.44%: 0.576. Loss: 1.6851202249526978\n",
      "training 16.51%: 0.576. Loss: 1.8586100339889526\n",
      "training 16.57%: 0.576. Loss: 1.638023018836975\n",
      "training 16.63%: 0.577. Loss: 1.5149750709533691\n",
      "training 16.70%: 0.577. Loss: 1.6163212060928345\n",
      "training 16.76%: 0.577. Loss: 1.6806302070617676\n",
      "training 16.83%: 0.577. Loss: 2.146488904953003\n",
      "training 16.89%: 0.577. Loss: 1.8413361310958862\n",
      "training 16.95%: 0.577. Loss: 1.6058229207992554\n",
      "training 17.02%: 0.577. Loss: 1.892528772354126\n",
      "training 17.08%: 0.577. Loss: 1.6031155586242676\n",
      "training 17.15%: 0.577. Loss: 1.6942509412765503\n",
      "training 17.21%: 0.577. Loss: 1.979775071144104\n",
      "training 17.27%: 0.577. Loss: 1.7706224918365479\n",
      "training 17.34%: 0.577. Loss: 1.6267261505126953\n",
      "training 17.40%: 0.577. Loss: 1.6753320693969727\n",
      "training 17.47%: 0.577. Loss: 1.704681634902954\n",
      "training 17.53%: 0.577. Loss: 1.7282655239105225\n",
      "training 17.59%: 0.577. Loss: 1.964568853378296\n",
      "training 17.66%: 0.577. Loss: 1.5244256258010864\n",
      "training 17.72%: 0.577. Loss: 1.8263081312179565\n",
      "training 17.79%: 0.577. Loss: 1.621712327003479\n",
      "training 17.85%: 0.577. Loss: 1.8219059705734253\n",
      "training 17.91%: 0.577. Loss: 1.468709945678711\n",
      "training 17.98%: 0.577. Loss: 1.4670066833496094\n",
      "training 18.04%: 0.577. Loss: 1.6484979391098022\n",
      "training 18.11%: 0.577. Loss: 1.749894380569458\n",
      "training 18.17%: 0.577. Loss: 1.6519380807876587\n",
      "training 18.23%: 0.577. Loss: 2.158170461654663\n",
      "training 18.30%: 0.577. Loss: 1.437769889831543\n",
      "training 18.36%: 0.578. Loss: 1.1373145580291748\n",
      "training 18.43%: 0.578. Loss: 1.7530531883239746\n",
      "training 18.49%: 0.578. Loss: 1.5418860912322998\n",
      "training 18.55%: 0.578. Loss: 1.8070710897445679\n",
      "training 18.62%: 0.578. Loss: 1.8862199783325195\n",
      "training 18.68%: 0.578. Loss: 1.7709252834320068\n",
      "training 18.75%: 0.577. Loss: 2.012479066848755\n",
      "training 18.81%: 0.578. Loss: 1.4047898054122925\n",
      "training 18.87%: 0.578. Loss: 1.9463634490966797\n",
      "training 18.94%: 0.578. Loss: 1.6063933372497559\n",
      "training 19.00%: 0.578. Loss: 1.6184351444244385\n",
      "training 19.07%: 0.578. Loss: 1.8352091312408447\n",
      "training 19.13%: 0.577. Loss: 2.1124227046966553\n",
      "training 19.19%: 0.577. Loss: 1.7800681591033936\n",
      "training 19.26%: 0.577. Loss: 2.262133836746216\n",
      "training 19.32%: 0.577. Loss: 1.9189999103546143\n",
      "training 19.39%: 0.577. Loss: 1.7947806119918823\n",
      "training 19.45%: 0.577. Loss: 1.7065733671188354\n",
      "training 19.51%: 0.577. Loss: 1.8831241130828857\n",
      "training 19.58%: 0.577. Loss: 1.6184600591659546\n",
      "training 19.64%: 0.577. Loss: 1.3768310546875\n",
      "training 19.71%: 0.577. Loss: 1.4967594146728516\n",
      "training 19.77%: 0.577. Loss: 1.8499454259872437\n",
      "training 19.83%: 0.577. Loss: 1.918751835823059\n",
      "training 19.90%: 0.577. Loss: 1.7248395681381226\n",
      "training 19.96%: 0.577. Loss: 1.9463576078414917\n",
      "training 20.03%: 0.577. Loss: 1.773266077041626\n",
      "training 20.09%: 0.576. Loss: 2.0815765857696533\n",
      "training 20.15%: 0.576. Loss: 1.362333059310913\n",
      "training 20.22%: 0.576. Loss: 1.6961599588394165\n",
      "training 20.28%: 0.577. Loss: 1.4922900199890137\n",
      "training 20.35%: 0.577. Loss: 1.6561369895935059\n",
      "training 20.41%: 0.577. Loss: 1.7231903076171875\n",
      "training 20.47%: 0.577. Loss: 1.630116581916809\n",
      "training 20.54%: 0.577. Loss: 1.9492754936218262\n",
      "training 20.60%: 0.576. Loss: 2.0479190349578857\n",
      "training 20.67%: 0.576. Loss: 1.418854832649231\n",
      "training 20.73%: 0.576. Loss: 2.1787939071655273\n",
      "training 20.79%: 0.576. Loss: 1.95450758934021\n",
      "training 20.86%: 0.576. Loss: 1.8863266706466675\n",
      "training 20.92%: 0.576. Loss: 1.9074629545211792\n",
      "training 20.99%: 0.576. Loss: 1.2989567518234253\n",
      "training 21.05%: 0.576. Loss: 2.073259115219116\n",
      "training 21.11%: 0.576. Loss: 1.6177223920822144\n",
      "training 21.18%: 0.575. Loss: 1.7816306352615356\n",
      "training 21.24%: 0.576. Loss: 1.7048169374465942\n",
      "training 21.31%: 0.576. Loss: 1.7209750413894653\n",
      "training 21.37%: 0.575. Loss: 2.077538251876831\n",
      "training 21.43%: 0.575. Loss: 1.9951038360595703\n",
      "training 21.50%: 0.575. Loss: 1.520147442817688\n",
      "training 21.56%: 0.575. Loss: 1.8519303798675537\n",
      "training 21.63%: 0.576. Loss: 1.353813648223877\n",
      "training 21.69%: 0.576. Loss: 1.9368031024932861\n",
      "training 21.75%: 0.576. Loss: 1.8310656547546387\n",
      "training 21.82%: 0.576. Loss: 1.7295697927474976\n",
      "training 21.88%: 0.575. Loss: 1.9232691526412964\n",
      "training 21.94%: 0.575. Loss: 1.6179578304290771\n",
      "training 22.01%: 0.575. Loss: 1.4955987930297852\n",
      "training 22.07%: 0.575. Loss: 2.17248797416687\n",
      "training 22.14%: 0.575. Loss: 1.4739172458648682\n",
      "training 22.20%: 0.575. Loss: 1.9588396549224854\n",
      "training 22.26%: 0.575. Loss: 1.8638644218444824\n",
      "training 22.33%: 0.575. Loss: 1.414428472518921\n",
      "training 22.39%: 0.575. Loss: 2.1162986755371094\n",
      "training 22.46%: 0.575. Loss: 1.5269116163253784\n",
      "training 22.52%: 0.575. Loss: 1.3497358560562134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 22.58%: 0.576. Loss: 1.3236536979675293\n",
      "training 22.65%: 0.575. Loss: 1.7670742273330688\n",
      "training 22.71%: 0.575. Loss: 1.9988794326782227\n",
      "training 22.78%: 0.576. Loss: 1.2744200229644775\n",
      "training 22.84%: 0.576. Loss: 1.7904244661331177\n",
      "training 22.90%: 0.576. Loss: 1.6432230472564697\n",
      "training 22.97%: 0.576. Loss: 1.7878539562225342\n",
      "training 23.03%: 0.576. Loss: 1.486027479171753\n",
      "training 23.10%: 0.576. Loss: 1.8689569234848022\n",
      "training 23.16%: 0.575. Loss: 2.102902412414551\n",
      "training 23.22%: 0.576. Loss: 1.9606465101242065\n",
      "training 23.29%: 0.575. Loss: 1.820703148841858\n",
      "training 23.35%: 0.575. Loss: 2.047516107559204\n",
      "training 23.42%: 0.575. Loss: 1.5305367708206177\n",
      "training 23.48%: 0.575. Loss: 2.0008914470672607\n",
      "training 23.54%: 0.575. Loss: 1.7755547761917114\n",
      "training 23.61%: 0.575. Loss: 1.9309113025665283\n",
      "training 23.67%: 0.574. Loss: 2.245112180709839\n",
      "training 23.74%: 0.574. Loss: 1.8677055835723877\n",
      "training 23.80%: 0.575. Loss: 1.5952683687210083\n",
      "training 23.86%: 0.575. Loss: 1.772725224494934\n",
      "training 23.93%: 0.575. Loss: 1.565407633781433\n",
      "training 23.99%: 0.575. Loss: 1.5443717241287231\n",
      "training 24.06%: 0.575. Loss: 1.8831980228424072\n",
      "training 24.12%: 0.575. Loss: 2.249549388885498\n",
      "training 24.18%: 0.574. Loss: 2.1188759803771973\n",
      "training 24.25%: 0.574. Loss: 1.9195383787155151\n",
      "training 24.31%: 0.575. Loss: 1.5150259733200073\n",
      "training 24.38%: 0.575. Loss: 1.3372598886489868\n",
      "training 24.44%: 0.575. Loss: 1.7056032419204712\n",
      "training 24.50%: 0.575. Loss: 1.8596432209014893\n",
      "training 24.57%: 0.575. Loss: 1.6804953813552856\n",
      "training 24.63%: 0.575. Loss: 1.6853325366973877\n",
      "training 24.70%: 0.575. Loss: 1.6447347402572632\n",
      "training 24.76%: 0.574. Loss: 1.9840497970581055\n",
      "training 24.82%: 0.574. Loss: 1.6810102462768555\n",
      "training 24.89%: 0.574. Loss: 2.2417078018188477\n",
      "training 24.95%: 0.574. Loss: 1.5074827671051025\n",
      "training 25.02%: 0.574. Loss: 1.9634402990341187\n",
      "training 25.08%: 0.574. Loss: 1.6889821290969849\n",
      "training 25.14%: 0.574. Loss: 2.007392168045044\n",
      "training 25.21%: 0.574. Loss: 1.285749912261963\n",
      "training 25.27%: 0.574. Loss: 1.8158278465270996\n",
      "training 25.34%: 0.574. Loss: 1.4579936265945435\n",
      "training 25.40%: 0.574. Loss: 1.6891868114471436\n",
      "training 25.46%: 0.574. Loss: 1.6781071424484253\n",
      "training 25.53%: 0.574. Loss: 1.9908843040466309\n",
      "training 25.59%: 0.574. Loss: 1.485824465751648\n",
      "training 25.66%: 0.574. Loss: 1.669252634048462\n",
      "training 25.72%: 0.574. Loss: 1.7409369945526123\n",
      "training 25.78%: 0.574. Loss: 1.4237492084503174\n",
      "training 25.85%: 0.574. Loss: 1.8908628225326538\n",
      "training 25.91%: 0.575. Loss: 1.738329291343689\n",
      "training 25.98%: 0.575. Loss: 2.2204463481903076\n",
      "training 26.04%: 0.575. Loss: 1.5570071935653687\n",
      "training 26.10%: 0.575. Loss: 1.6609219312667847\n",
      "training 26.17%: 0.574. Loss: 2.1393675804138184\n",
      "training 26.23%: 0.574. Loss: 1.5304335355758667\n",
      "training 26.30%: 0.574. Loss: 1.7129884958267212\n",
      "training 26.36%: 0.574. Loss: 2.145657539367676\n",
      "training 26.42%: 0.574. Loss: 1.5914573669433594\n",
      "training 26.49%: 0.575. Loss: 1.271779179573059\n",
      "training 26.55%: 0.574. Loss: 1.9902114868164062\n",
      "training 26.62%: 0.575. Loss: 1.71718430519104\n",
      "training 26.68%: 0.574. Loss: 1.6276443004608154\n",
      "training 26.74%: 0.575. Loss: 1.7356619834899902\n",
      "training 26.81%: 0.574. Loss: 1.6316063404083252\n",
      "training 26.87%: 0.575. Loss: 1.7952362298965454\n",
      "training 26.94%: 0.575. Loss: 1.7282918691635132\n",
      "training 27.00%: 0.575. Loss: 1.6903023719787598\n",
      "training 27.06%: 0.575. Loss: 1.656294584274292\n",
      "training 27.13%: 0.575. Loss: 1.8434265851974487\n",
      "training 27.19%: 0.575. Loss: 1.22211754322052\n",
      "training 27.26%: 0.575. Loss: 1.5090346336364746\n",
      "training 27.32%: 0.575. Loss: 1.639765739440918\n",
      "training 27.38%: 0.575. Loss: 1.6371194124221802\n",
      "training 27.45%: 0.575. Loss: 1.370373249053955\n",
      "training 27.51%: 0.575. Loss: 2.065305471420288\n",
      "training 27.58%: 0.575. Loss: 1.585896611213684\n",
      "training 27.64%: 0.575. Loss: 1.9332023859024048\n",
      "training 27.70%: 0.575. Loss: 1.7245088815689087\n",
      "training 27.77%: 0.575. Loss: 1.6095807552337646\n",
      "training 27.83%: 0.575. Loss: 1.710302710533142\n",
      "training 27.90%: 0.575. Loss: 1.602193832397461\n",
      "training 27.96%: 0.575. Loss: 1.5992324352264404\n",
      "training 28.02%: 0.575. Loss: 1.8164710998535156\n",
      "training 28.09%: 0.575. Loss: 1.6190801858901978\n",
      "training 28.15%: 0.575. Loss: 2.0696611404418945\n",
      "training 28.21%: 0.575. Loss: 1.7073317766189575\n",
      "training 28.28%: 0.575. Loss: 1.7874280214309692\n",
      "training 28.34%: 0.575. Loss: 1.2963780164718628\n",
      "training 28.41%: 0.576. Loss: 1.5423592329025269\n",
      "training 28.47%: 0.576. Loss: 1.3434878587722778\n",
      "training 28.53%: 0.576. Loss: 1.8766798973083496\n",
      "training 28.60%: 0.576. Loss: 1.2486060857772827\n",
      "training 28.66%: 0.576. Loss: 1.6996467113494873\n",
      "training 28.73%: 0.576. Loss: 1.7293275594711304\n",
      "training 28.79%: 0.576. Loss: 1.6028218269348145\n",
      "training 28.85%: 0.576. Loss: 1.8609509468078613\n",
      "training 28.92%: 0.576. Loss: 2.077315092086792\n",
      "training 28.98%: 0.576. Loss: 1.6347801685333252\n",
      "training 29.05%: 0.576. Loss: 1.6157417297363281\n",
      "training 29.11%: 0.576. Loss: 1.437412977218628\n",
      "training 29.17%: 0.577. Loss: 1.4490680694580078\n",
      "training 29.24%: 0.577. Loss: 1.2344520092010498\n",
      "training 29.30%: 0.577. Loss: 1.4780620336532593\n",
      "training 29.37%: 0.577. Loss: 1.9789133071899414\n",
      "training 29.43%: 0.577. Loss: 1.3538589477539062\n",
      "training 29.49%: 0.577. Loss: 1.8136310577392578\n",
      "training 29.56%: 0.577. Loss: 1.8254574537277222\n",
      "training 29.62%: 0.577. Loss: 1.7347229719161987\n",
      "training 29.69%: 0.577. Loss: 1.6616493463516235\n",
      "training 29.75%: 0.577. Loss: 1.6222634315490723\n",
      "training 29.81%: 0.577. Loss: 2.1471307277679443\n",
      "training 29.88%: 0.577. Loss: 1.6187714338302612\n",
      "training 29.94%: 0.577. Loss: 2.023853302001953\n",
      "training 30.01%: 0.576. Loss: 1.9264495372772217\n",
      "training 30.07%: 0.576. Loss: 1.8267827033996582\n",
      "training 30.13%: 0.576. Loss: 1.5721516609191895\n",
      "training 30.20%: 0.577. Loss: 1.678728699684143\n",
      "training 30.26%: 0.577. Loss: 1.403054118156433\n",
      "training 30.33%: 0.577. Loss: 1.3788268566131592\n",
      "training 30.39%: 0.577. Loss: 1.906908392906189\n",
      "training 30.45%: 0.577. Loss: 1.535628080368042\n",
      "training 30.52%: 0.577. Loss: 1.7810115814208984\n",
      "training 30.58%: 0.577. Loss: 1.8706450462341309\n",
      "training 30.65%: 0.577. Loss: 1.797111988067627\n",
      "training 30.71%: 0.576. Loss: 2.1220927238464355\n",
      "training 30.77%: 0.576. Loss: 1.5796116590499878\n",
      "training 30.84%: 0.576. Loss: 1.9932438135147095\n",
      "training 30.90%: 0.576. Loss: 1.4289346933364868\n",
      "training 30.97%: 0.576. Loss: 1.5275864601135254\n",
      "training 31.03%: 0.577. Loss: 1.298865556716919\n",
      "training 31.09%: 0.577. Loss: 1.9325135946273804\n",
      "training 31.16%: 0.577. Loss: 1.8006335496902466\n",
      "training 31.22%: 0.577. Loss: 1.7108968496322632\n",
      "training 31.29%: 0.576. Loss: 2.0513274669647217\n",
      "training 31.35%: 0.577. Loss: 1.9655158519744873\n",
      "training 31.41%: 0.576. Loss: 1.8400546312332153\n",
      "training 31.48%: 0.576. Loss: 1.4300355911254883\n",
      "training 31.54%: 0.576. Loss: 1.9829601049423218\n",
      "training 31.61%: 0.576. Loss: 2.1474783420562744\n",
      "training 31.67%: 0.576. Loss: 1.5770422220230103\n",
      "training 31.73%: 0.576. Loss: 1.7192200422286987\n",
      "training 31.80%: 0.577. Loss: 1.5315643548965454\n",
      "training 31.86%: 0.577. Loss: 1.5956697463989258\n",
      "training 31.93%: 0.577. Loss: 1.446016788482666\n",
      "training 31.99%: 0.576. Loss: 1.9623228311538696\n",
      "training 32.05%: 0.576. Loss: 1.8193390369415283\n",
      "training 32.12%: 0.576. Loss: 1.7252206802368164\n",
      "training 32.18%: 0.576. Loss: 1.9442405700683594\n",
      "training 32.25%: 0.576. Loss: 2.0765089988708496\n",
      "training 32.31%: 0.576. Loss: 1.9259026050567627\n",
      "training 32.37%: 0.576. Loss: 1.539745569229126\n",
      "training 32.44%: 0.576. Loss: 1.7775681018829346\n",
      "training 32.50%: 0.576. Loss: 2.2657885551452637\n",
      "training 32.57%: 0.576. Loss: 1.7887142896652222\n",
      "training 32.63%: 0.575. Loss: 2.012077808380127\n",
      "training 32.69%: 0.575. Loss: 2.0792641639709473\n",
      "training 32.76%: 0.575. Loss: 2.150409698486328\n",
      "training 32.82%: 0.575. Loss: 1.9008833169937134\n",
      "training 32.89%: 0.575. Loss: 1.5427486896514893\n",
      "training 32.95%: 0.575. Loss: 1.7506425380706787\n",
      "training 33.01%: 0.575. Loss: 1.7353084087371826\n",
      "training 33.08%: 0.575. Loss: 1.8882735967636108\n",
      "training 33.14%: 0.575. Loss: 1.7863050699234009\n",
      "training 33.21%: 0.575. Loss: 1.6892216205596924\n",
      "training 33.27%: 0.575. Loss: 1.8976064920425415\n",
      "training 33.33%: 0.575. Loss: 1.602781057357788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 33.40%: 0.575. Loss: 2.032561779022217\n",
      "training 33.46%: 0.575. Loss: 2.1792805194854736\n",
      "training 33.53%: 0.575. Loss: 1.804581642150879\n",
      "training 33.59%: 0.575. Loss: 1.6004865169525146\n",
      "training 33.65%: 0.575. Loss: 1.4116655588150024\n",
      "training 33.72%: 0.574. Loss: 1.826412320137024\n",
      "training 33.78%: 0.574. Loss: 2.07913875579834\n",
      "training 33.85%: 0.574. Loss: 1.8935877084732056\n",
      "training 33.91%: 0.574. Loss: 1.496541142463684\n",
      "training 33.97%: 0.574. Loss: 1.6804792881011963\n",
      "training 34.04%: 0.574. Loss: 1.9674921035766602\n",
      "training 34.10%: 0.574. Loss: 1.4693557024002075\n",
      "training 34.17%: 0.574. Loss: 2.0286896228790283\n",
      "training 34.23%: 0.574. Loss: 1.7950141429901123\n",
      "training 34.29%: 0.574. Loss: 1.564889669418335\n",
      "training 34.36%: 0.574. Loss: 1.64219069480896\n",
      "training 34.42%: 0.574. Loss: 1.6504521369934082\n",
      "training 34.48%: 0.574. Loss: 1.3944324254989624\n",
      "training 34.55%: 0.574. Loss: 1.9681488275527954\n",
      "training 34.61%: 0.574. Loss: 1.8638545274734497\n",
      "training 34.68%: 0.574. Loss: 1.6597813367843628\n",
      "training 34.74%: 0.575. Loss: 1.3941798210144043\n",
      "training 34.80%: 0.575. Loss: 1.836161494255066\n",
      "training 34.87%: 0.574. Loss: 1.7445179224014282\n",
      "training 34.93%: 0.574. Loss: 1.7399383783340454\n",
      "training 35.00%: 0.575. Loss: 1.81058931350708\n",
      "training 35.06%: 0.575. Loss: 1.6685069799423218\n",
      "training 35.12%: 0.575. Loss: 1.7323009967803955\n",
      "training 35.19%: 0.575. Loss: 1.5034223794937134\n",
      "training 35.25%: 0.575. Loss: 1.8877211809158325\n",
      "training 35.32%: 0.575. Loss: 1.5700852870941162\n",
      "training 35.38%: 0.574. Loss: 1.931287407875061\n",
      "training 35.44%: 0.574. Loss: 1.7925634384155273\n",
      "training 35.51%: 0.574. Loss: 1.962385654449463\n",
      "training 35.57%: 0.574. Loss: 1.4536858797073364\n",
      "training 35.64%: 0.574. Loss: 1.7910175323486328\n",
      "training 35.70%: 0.574. Loss: 1.8440312147140503\n",
      "training 35.76%: 0.574. Loss: 1.7494670152664185\n",
      "training 35.83%: 0.574. Loss: 1.686259388923645\n",
      "training 35.89%: 0.574. Loss: 2.1113944053649902\n",
      "training 35.96%: 0.574. Loss: 1.4856563806533813\n",
      "training 36.02%: 0.574. Loss: 1.7321516275405884\n",
      "training 36.08%: 0.574. Loss: 1.4724889993667603\n",
      "training 36.15%: 0.574. Loss: 1.6471140384674072\n",
      "training 36.21%: 0.574. Loss: 1.5893317461013794\n",
      "training 36.28%: 0.574. Loss: 1.680612564086914\n",
      "training 36.34%: 0.574. Loss: 2.019298791885376\n",
      "training 36.40%: 0.574. Loss: 2.182431936264038\n",
      "training 36.47%: 0.574. Loss: 1.2844312191009521\n",
      "training 36.53%: 0.574. Loss: 1.4766384363174438\n",
      "training 36.60%: 0.575. Loss: 1.592170000076294\n",
      "training 36.66%: 0.574. Loss: 1.9790394306182861\n",
      "training 36.72%: 0.574. Loss: 1.8812085390090942\n",
      "training 36.79%: 0.574. Loss: 1.579433798789978\n",
      "training 36.85%: 0.575. Loss: 1.5312288999557495\n",
      "training 36.92%: 0.575. Loss: 1.8407061100006104\n",
      "training 36.98%: 0.574. Loss: 1.7270779609680176\n",
      "training 37.04%: 0.574. Loss: 1.6219525337219238\n",
      "training 37.11%: 0.574. Loss: 1.9332765340805054\n",
      "training 37.17%: 0.574. Loss: 1.8740675449371338\n",
      "training 37.24%: 0.574. Loss: 1.6282843351364136\n",
      "training 37.30%: 0.574. Loss: 1.704180359840393\n",
      "training 37.36%: 0.574. Loss: 1.7946584224700928\n",
      "training 37.43%: 0.574. Loss: 1.7834579944610596\n",
      "training 37.49%: 0.574. Loss: 2.112666606903076\n",
      "training 37.56%: 0.574. Loss: 1.4173204898834229\n",
      "training 37.62%: 0.574. Loss: 1.5261977910995483\n",
      "training 37.68%: 0.574. Loss: 1.719185709953308\n",
      "training 37.75%: 0.575. Loss: 1.443833589553833\n",
      "training 37.81%: 0.575. Loss: 1.6090888977050781\n",
      "training 37.88%: 0.575. Loss: 1.18784761428833\n",
      "training 37.94%: 0.575. Loss: 1.8214589357376099\n",
      "training 38.00%: 0.575. Loss: 1.8415123224258423\n",
      "training 38.07%: 0.575. Loss: 1.6220850944519043\n",
      "training 38.13%: 0.575. Loss: 1.5768002271652222\n",
      "training 38.20%: 0.575. Loss: 1.323984980583191\n",
      "training 38.26%: 0.575. Loss: 1.4466946125030518\n",
      "training 38.32%: 0.575. Loss: 1.6300655603408813\n",
      "training 38.39%: 0.575. Loss: 2.038177013397217\n",
      "training 38.45%: 0.574. Loss: 2.0244219303131104\n",
      "training 38.52%: 0.574. Loss: 1.816418170928955\n",
      "training 38.58%: 0.574. Loss: 1.5339267253875732\n",
      "training 38.64%: 0.574. Loss: 1.589234709739685\n",
      "training 38.71%: 0.574. Loss: 1.579927921295166\n",
      "training 38.77%: 0.574. Loss: 1.814346194267273\n",
      "training 38.84%: 0.574. Loss: 1.3512461185455322\n",
      "training 38.90%: 0.574. Loss: 1.962855577468872\n",
      "training 38.96%: 0.574. Loss: 1.691084384918213\n",
      "training 39.03%: 0.574. Loss: 1.6979426145553589\n",
      "training 39.09%: 0.574. Loss: 2.0157551765441895\n",
      "training 39.16%: 0.574. Loss: 1.7099469900131226\n",
      "training 39.22%: 0.574. Loss: 1.9678497314453125\n",
      "training 39.28%: 0.574. Loss: 1.4767669439315796\n",
      "training 39.35%: 0.574. Loss: 1.6843205690383911\n",
      "training 39.41%: 0.574. Loss: 1.5263622999191284\n",
      "training 39.48%: 0.575. Loss: 1.4025144577026367\n",
      "training 39.54%: 0.575. Loss: 1.3428174257278442\n",
      "training 39.60%: 0.575. Loss: 1.7868146896362305\n",
      "training 39.67%: 0.575. Loss: 1.7854973077774048\n",
      "training 39.73%: 0.574. Loss: 1.851141095161438\n",
      "training 39.80%: 0.575. Loss: 1.5026421546936035\n",
      "training 39.86%: 0.575. Loss: 1.6981959342956543\n",
      "training 39.92%: 0.575. Loss: 1.9617763757705688\n",
      "training 39.99%: 0.575. Loss: 1.4970053434371948\n",
      "training 40.05%: 0.575. Loss: 1.3525944948196411\n",
      "training 40.12%: 0.575. Loss: 1.9140033721923828\n",
      "training 40.18%: 0.575. Loss: 1.8025997877120972\n",
      "training 40.24%: 0.575. Loss: 1.9835124015808105\n",
      "training 40.31%: 0.575. Loss: 1.559125542640686\n",
      "training 40.37%: 0.575. Loss: 1.568833589553833\n",
      "training 40.44%: 0.575. Loss: 1.8764303922653198\n",
      "training 40.50%: 0.575. Loss: 1.4185593128204346\n",
      "training 40.56%: 0.575. Loss: 1.432073950767517\n",
      "training 40.63%: 0.575. Loss: 2.1196675300598145\n",
      "training 40.69%: 0.575. Loss: 1.9667433500289917\n",
      "training 40.75%: 0.575. Loss: 1.8016782999038696\n",
      "training 40.82%: 0.575. Loss: 1.455024242401123\n",
      "training 40.88%: 0.575. Loss: 1.667678952217102\n",
      "training 40.95%: 0.575. Loss: 1.8666185140609741\n",
      "training 41.01%: 0.575. Loss: 1.2313131093978882\n",
      "training 41.07%: 0.575. Loss: 1.7050385475158691\n",
      "training 41.14%: 0.575. Loss: 2.1793153285980225\n",
      "training 41.20%: 0.575. Loss: 1.7930988073349\n",
      "training 41.27%: 0.575. Loss: 1.436774730682373\n",
      "training 41.33%: 0.575. Loss: 1.5380921363830566\n",
      "training 41.39%: 0.575. Loss: 1.649351716041565\n",
      "training 41.46%: 0.575. Loss: 1.5308105945587158\n",
      "training 41.52%: 0.574. Loss: 2.1924004554748535\n",
      "training 41.59%: 0.575. Loss: 1.9413317441940308\n",
      "training 41.65%: 0.575. Loss: 1.770866870880127\n",
      "training 41.71%: 0.575. Loss: 1.7862873077392578\n",
      "training 41.78%: 0.575. Loss: 1.7805850505828857\n",
      "training 41.84%: 0.574. Loss: 1.914096474647522\n",
      "training 41.91%: 0.574. Loss: 1.9899581670761108\n",
      "training 41.97%: 0.574. Loss: 1.4913676977157593\n",
      "training 42.03%: 0.574. Loss: 1.3629488945007324\n",
      "training 42.10%: 0.575. Loss: 1.8158878087997437\n",
      "training 42.16%: 0.575. Loss: 1.5302999019622803\n",
      "training 42.23%: 0.575. Loss: 1.436098575592041\n",
      "training 42.29%: 0.575. Loss: 1.5758486986160278\n",
      "training 42.35%: 0.575. Loss: 1.3825194835662842\n",
      "training 42.42%: 0.575. Loss: 1.7454019784927368\n",
      "training 42.48%: 0.575. Loss: 1.5744189023971558\n",
      "training 42.55%: 0.575. Loss: 2.0857813358306885\n",
      "training 42.61%: 0.575. Loss: 1.4007139205932617\n",
      "training 42.67%: 0.575. Loss: 2.1264801025390625\n",
      "training 42.74%: 0.575. Loss: 1.644952416419983\n",
      "training 42.80%: 0.574. Loss: 1.9785455465316772\n",
      "training 42.87%: 0.574. Loss: 2.2374982833862305\n",
      "training 42.93%: 0.575. Loss: 1.4008818864822388\n",
      "training 42.99%: 0.575. Loss: 1.815349817276001\n",
      "training 43.06%: 0.575. Loss: 1.6959971189498901\n",
      "training 43.12%: 0.574. Loss: 2.118112564086914\n",
      "training 43.19%: 0.574. Loss: 1.5267990827560425\n",
      "training 43.25%: 0.574. Loss: 1.7652738094329834\n",
      "training 43.31%: 0.574. Loss: 1.5801771879196167\n",
      "training 43.38%: 0.574. Loss: 2.0190043449401855\n",
      "training 43.44%: 0.574. Loss: 1.8824383020401\n",
      "training 43.51%: 0.574. Loss: 2.10255765914917\n",
      "training 43.57%: 0.574. Loss: 1.9548349380493164\n",
      "training 43.63%: 0.574. Loss: 2.102809429168701\n",
      "training 43.70%: 0.574. Loss: 2.2891600131988525\n",
      "training 43.76%: 0.574. Loss: 1.5526950359344482\n",
      "training 43.83%: 0.574. Loss: 1.5506725311279297\n",
      "training 43.89%: 0.574. Loss: 2.034485101699829\n",
      "training 43.95%: 0.574. Loss: 1.6139657497406006\n",
      "training 44.02%: 0.574. Loss: 2.171156167984009\n",
      "training 44.08%: 0.574. Loss: 1.6446799039840698\n",
      "training 44.15%: 0.574. Loss: 1.8517135381698608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 44.21%: 0.574. Loss: 1.649247646331787\n",
      "training 44.27%: 0.574. Loss: 1.3985739946365356\n",
      "training 44.34%: 0.574. Loss: 1.3356921672821045\n",
      "training 44.40%: 0.574. Loss: 2.3224751949310303\n",
      "training 44.47%: 0.574. Loss: 1.5256314277648926\n",
      "training 44.53%: 0.574. Loss: 1.4569597244262695\n",
      "training 44.59%: 0.574. Loss: 2.3366785049438477\n",
      "training 44.66%: 0.574. Loss: 1.5894240140914917\n",
      "training 44.72%: 0.574. Loss: 1.558829665184021\n",
      "training 44.79%: 0.574. Loss: 1.8346277475357056\n",
      "training 44.85%: 0.574. Loss: 2.2832093238830566\n",
      "training 44.91%: 0.574. Loss: 1.6625072956085205\n",
      "training 44.98%: 0.574. Loss: 1.5424755811691284\n",
      "training 45.04%: 0.574. Loss: 1.752536416053772\n",
      "training 45.11%: 0.574. Loss: 1.732192039489746\n",
      "training 45.17%: 0.574. Loss: 1.7444664239883423\n",
      "training 45.23%: 0.574. Loss: 1.5768404006958008\n",
      "training 45.30%: 0.574. Loss: 1.9235531091690063\n",
      "training 45.36%: 0.574. Loss: 1.656158208847046\n",
      "training 45.43%: 0.574. Loss: 1.4549603462219238\n",
      "training 45.49%: 0.574. Loss: 1.9118472337722778\n",
      "training 45.55%: 0.574. Loss: 2.158656120300293\n",
      "training 45.62%: 0.574. Loss: 1.3538399934768677\n",
      "training 45.68%: 0.574. Loss: 1.6674939393997192\n",
      "training 45.75%: 0.574. Loss: 1.681183099746704\n",
      "training 45.81%: 0.574. Loss: 1.7499144077301025\n",
      "training 45.87%: 0.574. Loss: 2.4316978454589844\n",
      "training 45.94%: 0.574. Loss: 1.8664970397949219\n",
      "training 46.00%: 0.574. Loss: 1.6898711919784546\n",
      "training 46.07%: 0.574. Loss: 1.7674667835235596\n",
      "training 46.13%: 0.574. Loss: 1.586041808128357\n",
      "training 46.19%: 0.574. Loss: 1.823512077331543\n",
      "training 46.26%: 0.574. Loss: 1.7142305374145508\n",
      "training 46.32%: 0.574. Loss: 1.698512077331543\n",
      "training 46.39%: 0.574. Loss: 1.0801066160202026\n",
      "training 46.45%: 0.574. Loss: 1.7111313343048096\n",
      "training 46.51%: 0.574. Loss: 1.8389942646026611\n",
      "training 46.58%: 0.574. Loss: 1.8553752899169922\n",
      "training 46.64%: 0.575. Loss: 1.2381898164749146\n",
      "training 46.71%: 0.574. Loss: 1.89482843875885\n",
      "training 46.77%: 0.575. Loss: 1.4710392951965332\n",
      "training 46.83%: 0.575. Loss: 1.7496328353881836\n",
      "training 46.90%: 0.575. Loss: 1.7694873809814453\n",
      "training 46.96%: 0.575. Loss: 1.450482964515686\n",
      "training 47.02%: 0.575. Loss: 1.550188422203064\n",
      "training 47.09%: 0.575. Loss: 1.6691813468933105\n",
      "training 47.15%: 0.575. Loss: 1.6336015462875366\n",
      "training 47.22%: 0.575. Loss: 1.6426891088485718\n",
      "training 47.28%: 0.575. Loss: 1.6666358709335327\n",
      "training 47.34%: 0.575. Loss: 1.715113639831543\n",
      "training 47.41%: 0.575. Loss: 1.6687581539154053\n",
      "training 47.47%: 0.575. Loss: 1.941543698310852\n",
      "training 47.54%: 0.575. Loss: 1.5615315437316895\n",
      "training 47.60%: 0.575. Loss: 1.3944027423858643\n",
      "training 47.66%: 0.575. Loss: 1.9475657939910889\n",
      "training 47.73%: 0.575. Loss: 1.6938825845718384\n",
      "training 47.79%: 0.575. Loss: 2.008985996246338\n",
      "training 47.86%: 0.575. Loss: 1.5876126289367676\n",
      "training 47.92%: 0.575. Loss: 1.7370762825012207\n",
      "training 47.98%: 0.575. Loss: 1.7449055910110474\n",
      "training 48.05%: 0.575. Loss: 1.3228724002838135\n",
      "training 48.11%: 0.575. Loss: 1.6717417240142822\n",
      "training 48.18%: 0.575. Loss: 1.5160706043243408\n",
      "training 48.24%: 0.575. Loss: 1.3882935047149658\n",
      "training 48.30%: 0.575. Loss: 1.7022122144699097\n",
      "training 48.37%: 0.575. Loss: 1.3550630807876587\n",
      "training 48.43%: 0.575. Loss: 1.6905765533447266\n",
      "training 48.50%: 0.575. Loss: 1.4615671634674072\n",
      "training 48.56%: 0.575. Loss: 1.9816851615905762\n",
      "training 48.62%: 0.576. Loss: 1.5286927223205566\n",
      "training 48.69%: 0.575. Loss: 2.1071953773498535\n",
      "training 48.75%: 0.575. Loss: 1.776080846786499\n",
      "training 48.82%: 0.576. Loss: 1.1067088842391968\n",
      "training 48.88%: 0.576. Loss: 1.9415925741195679\n",
      "training 48.94%: 0.575. Loss: 1.6872848272323608\n",
      "training 49.01%: 0.575. Loss: 1.801419973373413\n",
      "training 49.07%: 0.575. Loss: 1.705543875694275\n",
      "training 49.14%: 0.575. Loss: 1.506803274154663\n",
      "training 49.20%: 0.575. Loss: 1.8374916315078735\n",
      "training 49.26%: 0.575. Loss: 1.740065336227417\n",
      "training 49.33%: 0.576. Loss: 1.3462142944335938\n",
      "training 49.39%: 0.576. Loss: 1.5465083122253418\n",
      "training 49.46%: 0.576. Loss: 1.8874634504318237\n",
      "training 49.52%: 0.575. Loss: 1.9075291156768799\n",
      "training 49.58%: 0.575. Loss: 1.6918946504592896\n",
      "training 49.65%: 0.575. Loss: 1.9349756240844727\n",
      "training 49.71%: 0.575. Loss: 1.8327538967132568\n",
      "training 49.78%: 0.575. Loss: 1.6578271389007568\n",
      "training 49.84%: 0.575. Loss: 1.8432716131210327\n",
      "training 49.90%: 0.575. Loss: 1.2884031534194946\n",
      "training 49.97%: 0.575. Loss: 1.503959059715271\n",
      "training 50.03%: 0.575. Loss: 1.74556565284729\n",
      "training 50.10%: 0.575. Loss: 1.6214439868927002\n",
      "training 50.16%: 0.575. Loss: 1.8360542058944702\n",
      "training 50.22%: 0.575. Loss: 1.3756632804870605\n",
      "training 50.29%: 0.576. Loss: 1.4931913614273071\n",
      "training 50.35%: 0.576. Loss: 1.7441949844360352\n",
      "training 50.42%: 0.576. Loss: 1.6845264434814453\n",
      "training 50.48%: 0.576. Loss: 1.5614898204803467\n",
      "training 50.54%: 0.576. Loss: 1.7229293584823608\n",
      "training 50.61%: 0.576. Loss: 1.8055464029312134\n",
      "training 50.67%: 0.576. Loss: 1.7678948640823364\n",
      "training 50.74%: 0.576. Loss: 1.6446819305419922\n",
      "training 50.80%: 0.576. Loss: 1.7195959091186523\n",
      "training 50.86%: 0.576. Loss: 1.902146339416504\n",
      "training 50.93%: 0.576. Loss: 1.6760942935943604\n",
      "training 50.99%: 0.576. Loss: 1.7847647666931152\n",
      "training 51.06%: 0.576. Loss: 1.6182832717895508\n",
      "training 51.12%: 0.576. Loss: 1.5069888830184937\n",
      "training 51.18%: 0.576. Loss: 1.2720531225204468\n",
      "training 51.25%: 0.576. Loss: 1.7146121263504028\n",
      "training 51.31%: 0.576. Loss: 1.7598826885223389\n",
      "training 51.38%: 0.576. Loss: 1.4783190488815308\n",
      "training 51.44%: 0.576. Loss: 1.5145524740219116\n",
      "training 51.50%: 0.576. Loss: 1.8096104860305786\n",
      "training 51.57%: 0.576. Loss: 1.417966604232788\n",
      "training 51.63%: 0.576. Loss: 1.7158371210098267\n",
      "training 51.70%: 0.576. Loss: 1.89279043674469\n",
      "training 51.76%: 0.576. Loss: 1.3491792678833008\n",
      "training 51.82%: 0.576. Loss: 1.5892637968063354\n",
      "training 51.89%: 0.576. Loss: 1.8588322401046753\n",
      "training 51.95%: 0.576. Loss: 1.7934291362762451\n",
      "training 52.02%: 0.576. Loss: 1.8799430131912231\n",
      "training 52.08%: 0.576. Loss: 1.5956406593322754\n",
      "training 52.14%: 0.576. Loss: 1.717841386795044\n",
      "training 52.21%: 0.576. Loss: 2.3220276832580566\n",
      "training 52.27%: 0.576. Loss: 1.9705004692077637\n",
      "training 52.34%: 0.576. Loss: 1.887048363685608\n",
      "training 52.40%: 0.576. Loss: 1.772742509841919\n",
      "training 52.46%: 0.576. Loss: 1.7866716384887695\n",
      "training 52.53%: 0.576. Loss: 1.5810829401016235\n",
      "training 52.59%: 0.576. Loss: 1.6763324737548828\n",
      "training 52.66%: 0.576. Loss: 1.7185055017471313\n",
      "training 52.72%: 0.576. Loss: 1.6767349243164062\n",
      "training 52.78%: 0.576. Loss: 2.1194615364074707\n",
      "training 52.85%: 0.576. Loss: 1.3736214637756348\n",
      "training 52.91%: 0.576. Loss: 1.4285497665405273\n",
      "training 52.98%: 0.576. Loss: 1.5568410158157349\n",
      "training 53.04%: 0.576. Loss: 1.5553219318389893\n",
      "training 53.10%: 0.576. Loss: 1.2505143880844116\n",
      "training 53.17%: 0.576. Loss: 1.6873263120651245\n",
      "training 53.23%: 0.576. Loss: 1.8311983346939087\n",
      "training 53.29%: 0.576. Loss: 2.3571391105651855\n",
      "training 53.36%: 0.576. Loss: 2.279815435409546\n",
      "training 53.42%: 0.576. Loss: 1.831130027770996\n",
      "training 53.49%: 0.576. Loss: 1.5317277908325195\n",
      "training 53.55%: 0.576. Loss: 1.5747708082199097\n",
      "training 53.61%: 0.576. Loss: 1.5855920314788818\n",
      "training 53.68%: 0.576. Loss: 1.7572448253631592\n",
      "training 53.74%: 0.576. Loss: 1.690984845161438\n",
      "training 53.81%: 0.576. Loss: 1.7377216815948486\n",
      "training 53.87%: 0.576. Loss: 1.5335984230041504\n",
      "training 53.93%: 0.576. Loss: 1.8329086303710938\n",
      "training 54.00%: 0.576. Loss: 1.478761076927185\n",
      "training 54.06%: 0.576. Loss: 1.5971546173095703\n",
      "training 54.13%: 0.576. Loss: 1.4647860527038574\n",
      "training 54.19%: 0.576. Loss: 1.55521559715271\n",
      "training 54.25%: 0.577. Loss: 1.6696802377700806\n",
      "training 54.32%: 0.576. Loss: 1.902489423751831\n",
      "training 54.38%: 0.576. Loss: 1.8829765319824219\n",
      "training 54.45%: 0.577. Loss: 1.4098507165908813\n",
      "training 54.51%: 0.577. Loss: 1.8551043272018433\n",
      "training 54.57%: 0.577. Loss: 1.826133131980896\n",
      "training 54.64%: 0.577. Loss: 1.1911026239395142\n",
      "training 54.70%: 0.577. Loss: 1.6010361909866333\n",
      "training 54.77%: 0.577. Loss: 1.5520474910736084\n",
      "training 54.83%: 0.577. Loss: 1.6668121814727783\n",
      "training 54.89%: 0.577. Loss: 1.8291161060333252\n",
      "training 54.96%: 0.576. Loss: 2.1656432151794434\n",
      "training 55.02%: 0.576. Loss: 1.999330997467041\n",
      "training 55.09%: 0.576. Loss: 1.644750714302063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 55.15%: 0.576. Loss: 2.22564435005188\n",
      "training 55.21%: 0.576. Loss: 1.5153210163116455\n",
      "training 55.28%: 0.576. Loss: 1.8697997331619263\n",
      "training 55.34%: 0.576. Loss: 2.054603099822998\n",
      "training 55.41%: 0.576. Loss: 2.4063539505004883\n",
      "training 55.47%: 0.576. Loss: 1.5330842733383179\n",
      "training 55.53%: 0.576. Loss: 1.885904312133789\n",
      "training 55.60%: 0.576. Loss: 1.718678593635559\n",
      "training 55.66%: 0.576. Loss: 1.532302737236023\n",
      "training 55.73%: 0.576. Loss: 1.5223629474639893\n",
      "training 55.79%: 0.576. Loss: 1.5227771997451782\n",
      "training 55.85%: 0.576. Loss: 1.7840626239776611\n",
      "training 55.92%: 0.576. Loss: 2.0331509113311768\n",
      "training 55.98%: 0.576. Loss: 1.2992610931396484\n",
      "training 56.05%: 0.576. Loss: 1.44133722782135\n",
      "training 56.11%: 0.576. Loss: 1.5330199003219604\n",
      "training 56.17%: 0.576. Loss: 1.8437631130218506\n",
      "training 56.24%: 0.576. Loss: 1.7949931621551514\n",
      "training 56.30%: 0.576. Loss: 1.8556709289550781\n",
      "training 56.37%: 0.576. Loss: 1.4997667074203491\n",
      "training 56.43%: 0.576. Loss: 1.5214293003082275\n",
      "training 56.49%: 0.577. Loss: 1.540034294128418\n",
      "training 56.56%: 0.577. Loss: 1.53616201877594\n",
      "training 56.62%: 0.577. Loss: 1.7147846221923828\n",
      "training 56.69%: 0.576. Loss: 1.5455513000488281\n",
      "training 56.75%: 0.576. Loss: 1.9000059366226196\n",
      "training 56.81%: 0.577. Loss: 1.4790738821029663\n",
      "training 56.88%: 0.576. Loss: 1.770499348640442\n",
      "training 56.94%: 0.576. Loss: 1.8540427684783936\n",
      "training 57.01%: 0.577. Loss: 1.520373821258545\n",
      "training 57.07%: 0.577. Loss: 1.546888828277588\n",
      "training 57.13%: 0.577. Loss: 1.683728814125061\n",
      "training 57.20%: 0.577. Loss: 1.7779371738433838\n",
      "training 57.26%: 0.577. Loss: 1.6059457063674927\n",
      "training 57.33%: 0.577. Loss: 1.8135334253311157\n",
      "training 57.39%: 0.577. Loss: 1.5381032228469849\n",
      "training 57.45%: 0.577. Loss: 2.0888588428497314\n",
      "training 57.52%: 0.577. Loss: 1.766513705253601\n",
      "training 57.58%: 0.576. Loss: 2.1276614665985107\n",
      "training 57.65%: 0.576. Loss: 1.9022822380065918\n",
      "training 57.71%: 0.576. Loss: 1.4681910276412964\n",
      "training 57.77%: 0.576. Loss: 1.7150932550430298\n",
      "training 57.84%: 0.576. Loss: 2.115217447280884\n",
      "training 57.90%: 0.576. Loss: 1.2602944374084473\n",
      "training 57.97%: 0.576. Loss: 1.9879570007324219\n",
      "training 58.03%: 0.577. Loss: 1.557648777961731\n",
      "training 58.09%: 0.577. Loss: 1.4695097208023071\n",
      "training 58.16%: 0.577. Loss: 1.9588696956634521\n",
      "training 58.22%: 0.577. Loss: 1.7648135423660278\n",
      "training 58.29%: 0.577. Loss: 1.653666615486145\n",
      "training 58.35%: 0.577. Loss: 1.524048924446106\n",
      "training 58.41%: 0.576. Loss: 1.6769294738769531\n",
      "training 58.48%: 0.576. Loss: 1.6443778276443481\n",
      "training 58.54%: 0.576. Loss: 1.7537751197814941\n",
      "training 58.61%: 0.576. Loss: 2.012716770172119\n",
      "training 58.67%: 0.576. Loss: 1.8664648532867432\n",
      "training 58.73%: 0.576. Loss: 1.9260034561157227\n",
      "training 58.80%: 0.576. Loss: 2.1723625659942627\n",
      "training 58.86%: 0.576. Loss: 1.6662704944610596\n",
      "training 58.93%: 0.576. Loss: 1.70006263256073\n",
      "training 58.99%: 0.576. Loss: 1.6261368989944458\n",
      "training 59.05%: 0.576. Loss: 1.8953261375427246\n",
      "training 59.12%: 0.576. Loss: 1.6750104427337646\n",
      "training 59.18%: 0.576. Loss: 2.041041612625122\n",
      "training 59.25%: 0.576. Loss: 1.5749093294143677\n",
      "training 59.31%: 0.576. Loss: 2.1189589500427246\n",
      "training 59.37%: 0.576. Loss: 1.8376333713531494\n",
      "training 59.44%: 0.576. Loss: 1.2903705835342407\n",
      "training 59.50%: 0.576. Loss: 1.8212075233459473\n",
      "training 59.56%: 0.576. Loss: 1.598013162612915\n",
      "training 59.63%: 0.576. Loss: 1.9875953197479248\n",
      "training 59.69%: 0.576. Loss: 2.0682644844055176\n",
      "training 59.76%: 0.576. Loss: 1.6286914348602295\n",
      "training 59.82%: 0.576. Loss: 1.5563716888427734\n",
      "training 59.88%: 0.576. Loss: 1.7023298740386963\n",
      "training 59.95%: 0.576. Loss: 1.771323323249817\n",
      "training 60.01%: 0.576. Loss: 1.8415117263793945\n",
      "training 60.08%: 0.576. Loss: 1.8435896635055542\n",
      "training 60.14%: 0.576. Loss: 2.005253314971924\n",
      "training 60.20%: 0.576. Loss: 1.912957787513733\n",
      "training 60.27%: 0.576. Loss: 2.0055792331695557\n",
      "training 60.33%: 0.576. Loss: 1.8179168701171875\n",
      "training 60.40%: 0.576. Loss: 2.1168885231018066\n",
      "training 60.46%: 0.576. Loss: 1.5392251014709473\n",
      "training 60.52%: 0.576. Loss: 1.483337640762329\n",
      "training 60.59%: 0.576. Loss: 2.0843513011932373\n",
      "training 60.65%: 0.576. Loss: 1.826390027999878\n",
      "training 60.72%: 0.576. Loss: 1.7761130332946777\n",
      "training 60.78%: 0.576. Loss: 1.4286127090454102\n",
      "training 60.84%: 0.576. Loss: 2.2907803058624268\n",
      "training 60.91%: 0.576. Loss: 1.6320456266403198\n",
      "training 60.97%: 0.576. Loss: 2.083156108856201\n",
      "training 61.04%: 0.576. Loss: 1.4221853017807007\n",
      "training 61.10%: 0.576. Loss: 1.8860455751419067\n",
      "training 61.16%: 0.576. Loss: 1.6138710975646973\n",
      "training 61.23%: 0.576. Loss: 1.9850608110427856\n",
      "training 61.29%: 0.576. Loss: 1.7557896375656128\n",
      "training 61.36%: 0.576. Loss: 1.524628758430481\n",
      "training 61.42%: 0.576. Loss: 1.9622106552124023\n",
      "training 61.48%: 0.576. Loss: 1.4861359596252441\n",
      "training 61.55%: 0.576. Loss: 1.8099569082260132\n",
      "training 61.61%: 0.576. Loss: 1.6241190433502197\n",
      "training 61.68%: 0.575. Loss: 2.0371127128601074\n",
      "training 61.74%: 0.575. Loss: 1.82666015625\n",
      "training 61.80%: 0.575. Loss: 1.480201244354248\n",
      "training 61.87%: 0.575. Loss: 1.6364288330078125\n",
      "training 61.93%: 0.575. Loss: 1.612275242805481\n",
      "training 62.00%: 0.575. Loss: 1.630281925201416\n",
      "training 62.06%: 0.576. Loss: 1.6665867567062378\n",
      "training 62.12%: 0.576. Loss: 1.697474479675293\n",
      "training 62.19%: 0.576. Loss: 1.74212646484375\n",
      "training 62.25%: 0.576. Loss: 1.6329408884048462\n",
      "training 62.32%: 0.575. Loss: 1.71035897731781\n",
      "training 62.38%: 0.576. Loss: 1.5592796802520752\n",
      "training 62.44%: 0.576. Loss: 1.4160140752792358\n",
      "training 62.51%: 0.576. Loss: 1.4468077421188354\n",
      "training 62.57%: 0.576. Loss: 1.4998979568481445\n",
      "training 62.64%: 0.576. Loss: 1.8128513097763062\n",
      "training 62.70%: 0.576. Loss: 1.9915316104888916\n",
      "training 62.76%: 0.576. Loss: 2.1943023204803467\n",
      "training 62.83%: 0.576. Loss: 1.500410795211792\n",
      "training 62.89%: 0.576. Loss: 1.9794094562530518\n",
      "training 62.96%: 0.576. Loss: 1.9108039140701294\n",
      "training 63.02%: 0.576. Loss: 1.6145071983337402\n",
      "training 63.08%: 0.576. Loss: 1.505480170249939\n",
      "training 63.15%: 0.576. Loss: 1.8908616304397583\n",
      "training 63.21%: 0.576. Loss: 1.504806637763977\n",
      "training 63.28%: 0.576. Loss: 1.9875991344451904\n",
      "training 63.34%: 0.576. Loss: 1.5870200395584106\n",
      "training 63.40%: 0.576. Loss: 1.6315410137176514\n",
      "training 63.47%: 0.576. Loss: 1.95870041847229\n",
      "training 63.53%: 0.576. Loss: 1.6525652408599854\n",
      "training 63.60%: 0.576. Loss: 1.8003809452056885\n",
      "training 63.66%: 0.576. Loss: 1.8354105949401855\n",
      "training 63.72%: 0.576. Loss: 1.4509797096252441\n",
      "training 63.79%: 0.576. Loss: 1.6876178979873657\n",
      "training 63.85%: 0.576. Loss: 1.8693476915359497\n",
      "training 63.92%: 0.576. Loss: 1.3733446598052979\n",
      "training 63.98%: 0.576. Loss: 2.0302228927612305\n",
      "training 64.04%: 0.576. Loss: 1.9061906337738037\n",
      "training 64.11%: 0.576. Loss: 1.8046938180923462\n",
      "training 64.17%: 0.576. Loss: 2.175092935562134\n",
      "training 64.24%: 0.576. Loss: 1.5378283262252808\n",
      "training 64.30%: 0.576. Loss: 1.6480721235275269\n",
      "training 64.36%: 0.576. Loss: 1.7746306657791138\n",
      "training 64.43%: 0.576. Loss: 2.0520505905151367\n",
      "training 64.49%: 0.575. Loss: 2.183598041534424\n",
      "training 64.56%: 0.576. Loss: 1.4821476936340332\n",
      "training 64.62%: 0.576. Loss: 2.0752017498016357\n",
      "training 64.68%: 0.575. Loss: 1.926779866218567\n",
      "training 64.75%: 0.576. Loss: 1.575109839439392\n",
      "training 64.81%: 0.575. Loss: 1.8469358682632446\n",
      "training 64.88%: 0.575. Loss: 1.9205902814865112\n",
      "training 64.94%: 0.575. Loss: 1.6929962635040283\n",
      "training 65.00%: 0.575. Loss: 1.6418514251708984\n",
      "training 65.07%: 0.575. Loss: 1.9466356039047241\n",
      "training 65.13%: 0.575. Loss: 1.7590967416763306\n",
      "training 65.20%: 0.575. Loss: 1.5552940368652344\n",
      "training 65.26%: 0.575. Loss: 1.9037771224975586\n",
      "training 65.32%: 0.575. Loss: 1.7230335474014282\n",
      "training 65.39%: 0.575. Loss: 1.6613887548446655\n",
      "training 65.45%: 0.575. Loss: 1.43447744846344\n",
      "training 65.52%: 0.575. Loss: 1.9615750312805176\n",
      "training 65.58%: 0.575. Loss: 1.6782894134521484\n",
      "training 65.64%: 0.575. Loss: 1.4850149154663086\n",
      "training 65.71%: 0.575. Loss: 2.0144641399383545\n",
      "training 65.77%: 0.575. Loss: 1.3645864725112915\n",
      "training 65.83%: 0.575. Loss: 1.8779231309890747\n",
      "training 65.90%: 0.575. Loss: 1.6394777297973633\n",
      "training 65.96%: 0.575. Loss: 1.6743007898330688\n",
      "training 66.03%: 0.575. Loss: 1.6081037521362305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 66.09%: 0.575. Loss: 1.5710631608963013\n",
      "training 66.15%: 0.575. Loss: 1.5232014656066895\n",
      "training 66.22%: 0.575. Loss: 1.9284358024597168\n",
      "training 66.28%: 0.575. Loss: 1.8991930484771729\n",
      "training 66.35%: 0.575. Loss: 1.8079416751861572\n",
      "training 66.41%: 0.575. Loss: 1.9321945905685425\n",
      "training 66.47%: 0.575. Loss: 1.8665019273757935\n",
      "training 66.54%: 0.575. Loss: 1.619236707687378\n",
      "training 66.60%: 0.575. Loss: 1.914528727531433\n",
      "training 66.67%: 0.575. Loss: 1.4803485870361328\n",
      "training 66.73%: 0.575. Loss: 1.5873632431030273\n",
      "training 66.79%: 0.575. Loss: 1.6976155042648315\n",
      "training 66.86%: 0.575. Loss: 1.8983912467956543\n",
      "training 66.92%: 0.575. Loss: 1.8351311683654785\n",
      "training 66.99%: 0.575. Loss: 1.7613383531570435\n",
      "training 67.05%: 0.575. Loss: 1.5299389362335205\n",
      "training 67.11%: 0.575. Loss: 1.8914647102355957\n",
      "training 67.18%: 0.575. Loss: 1.4791656732559204\n",
      "training 67.24%: 0.575. Loss: 1.3561779260635376\n",
      "training 67.31%: 0.575. Loss: 1.8082464933395386\n",
      "training 67.37%: 0.576. Loss: 1.5162534713745117\n",
      "training 67.43%: 0.576. Loss: 1.7838176488876343\n",
      "training 67.50%: 0.576. Loss: 1.5353879928588867\n",
      "training 67.56%: 0.576. Loss: 1.8439202308654785\n",
      "training 67.63%: 0.576. Loss: 1.5409034490585327\n",
      "training 67.69%: 0.576. Loss: 1.497245192527771\n",
      "training 67.75%: 0.576. Loss: 1.859320878982544\n",
      "training 67.82%: 0.576. Loss: 2.0266504287719727\n",
      "training 67.88%: 0.576. Loss: 1.8597074747085571\n",
      "training 67.95%: 0.576. Loss: 1.7106834650039673\n",
      "training 68.01%: 0.576. Loss: 1.8910938501358032\n",
      "training 68.07%: 0.576. Loss: 1.5349260568618774\n",
      "training 68.14%: 0.576. Loss: 1.8143092393875122\n",
      "training 68.20%: 0.576. Loss: 1.8279929161071777\n",
      "training 68.27%: 0.576. Loss: 1.6449120044708252\n",
      "training 68.33%: 0.576. Loss: 1.4465829133987427\n",
      "training 68.39%: 0.576. Loss: 1.8897130489349365\n",
      "training 68.46%: 0.576. Loss: 1.697613000869751\n",
      "training 68.52%: 0.576. Loss: 1.7450066804885864\n",
      "training 68.59%: 0.576. Loss: 1.7653764486312866\n",
      "training 68.65%: 0.576. Loss: 2.10783314704895\n",
      "training 68.71%: 0.576. Loss: 1.432769536972046\n",
      "training 68.78%: 0.576. Loss: 1.6992087364196777\n",
      "training 68.84%: 0.576. Loss: 1.832733154296875\n",
      "training 68.91%: 0.576. Loss: 1.7265615463256836\n",
      "training 68.97%: 0.576. Loss: 1.7755768299102783\n",
      "training 69.03%: 0.576. Loss: 1.7914667129516602\n",
      "training 69.10%: 0.576. Loss: 1.6560535430908203\n",
      "training 69.16%: 0.576. Loss: 1.312880516052246\n",
      "training 69.23%: 0.576. Loss: 1.4854323863983154\n",
      "training 69.29%: 0.576. Loss: 1.669679880142212\n",
      "training 69.35%: 0.576. Loss: 1.9701340198516846\n",
      "training 69.42%: 0.576. Loss: 1.7222391366958618\n",
      "training 69.48%: 0.576. Loss: 1.5316493511199951\n",
      "training 69.55%: 0.576. Loss: 1.2971993684768677\n",
      "training 69.61%: 0.576. Loss: 2.061415672302246\n",
      "training 69.67%: 0.576. Loss: 1.6260583400726318\n",
      "training 69.74%: 0.576. Loss: 1.8444557189941406\n",
      "training 69.80%: 0.576. Loss: 1.6309362649917603\n",
      "training 69.87%: 0.576. Loss: 1.7056164741516113\n",
      "training 69.93%: 0.575. Loss: 1.9555644989013672\n",
      "training 69.99%: 0.575. Loss: 1.8502817153930664\n",
      "training 70.06%: 0.575. Loss: 1.7122091054916382\n",
      "training 70.12%: 0.575. Loss: 1.5998133420944214\n",
      "training 70.19%: 0.575. Loss: 2.3482751846313477\n",
      "training 70.25%: 0.575. Loss: 1.7418179512023926\n",
      "training 70.31%: 0.575. Loss: 1.5906703472137451\n",
      "training 70.38%: 0.575. Loss: 2.164119005203247\n",
      "training 70.44%: 0.575. Loss: 1.6743525266647339\n",
      "training 70.51%: 0.575. Loss: 1.8128970861434937\n",
      "training 70.57%: 0.575. Loss: 1.4874663352966309\n",
      "training 70.63%: 0.575. Loss: 2.253166913986206\n",
      "training 70.70%: 0.575. Loss: 1.6675996780395508\n",
      "training 70.76%: 0.575. Loss: 1.8205571174621582\n",
      "training 70.83%: 0.575. Loss: 1.5019136667251587\n",
      "training 70.89%: 0.575. Loss: 1.6070802211761475\n",
      "training 70.95%: 0.575. Loss: 1.5233049392700195\n",
      "training 71.02%: 0.575. Loss: 1.552173376083374\n",
      "training 71.08%: 0.576. Loss: 1.8654335737228394\n",
      "training 71.15%: 0.576. Loss: 1.2949708700180054\n",
      "training 71.21%: 0.576. Loss: 1.5162380933761597\n",
      "training 71.27%: 0.576. Loss: 2.251997709274292\n",
      "training 71.34%: 0.576. Loss: 1.4469594955444336\n",
      "training 71.40%: 0.576. Loss: 1.9972537755966187\n",
      "training 71.47%: 0.575. Loss: 2.144650936126709\n",
      "training 71.53%: 0.576. Loss: 1.6804929971694946\n",
      "training 71.59%: 0.576. Loss: 1.4685494899749756\n",
      "training 71.66%: 0.576. Loss: 1.4372254610061646\n",
      "training 71.72%: 0.576. Loss: 1.7821764945983887\n",
      "training 71.79%: 0.576. Loss: 1.6498383283615112\n",
      "training 71.85%: 0.576. Loss: 1.7447649240493774\n",
      "training 71.91%: 0.576. Loss: 1.6012498140335083\n",
      "training 71.98%: 0.576. Loss: 1.5718212127685547\n",
      "training 72.04%: 0.576. Loss: 1.5825713872909546\n",
      "training 72.10%: 0.576. Loss: 1.6591793298721313\n",
      "training 72.17%: 0.576. Loss: 1.4699620008468628\n",
      "training 72.23%: 0.576. Loss: 1.6050599813461304\n",
      "training 72.30%: 0.576. Loss: 1.6337612867355347\n",
      "training 72.36%: 0.576. Loss: 1.5314818620681763\n",
      "training 72.42%: 0.576. Loss: 1.8210848569869995\n",
      "training 72.49%: 0.576. Loss: 1.8554147481918335\n",
      "training 72.55%: 0.576. Loss: 2.0016286373138428\n",
      "training 72.62%: 0.576. Loss: 1.751916766166687\n",
      "training 72.68%: 0.576. Loss: 1.5921295881271362\n",
      "training 72.74%: 0.576. Loss: 2.0632851123809814\n",
      "training 72.81%: 0.576. Loss: 1.396652102470398\n",
      "training 72.87%: 0.576. Loss: 1.7823457717895508\n",
      "training 72.94%: 0.576. Loss: 1.6434928178787231\n",
      "training 73.00%: 0.576. Loss: 1.7029129266738892\n",
      "training 73.06%: 0.576. Loss: 2.3416666984558105\n",
      "training 73.13%: 0.576. Loss: 1.9148313999176025\n",
      "training 73.19%: 0.576. Loss: 1.545458436012268\n",
      "training 73.26%: 0.576. Loss: 1.8796610832214355\n",
      "training 73.32%: 0.575. Loss: 2.0938878059387207\n",
      "training 73.38%: 0.575. Loss: 1.6883926391601562\n",
      "training 73.45%: 0.575. Loss: 1.7583143711090088\n",
      "training 73.51%: 0.575. Loss: 1.5078331232070923\n",
      "training 73.58%: 0.576. Loss: 1.7025758028030396\n",
      "training 73.64%: 0.576. Loss: 1.420716404914856\n",
      "training 73.70%: 0.576. Loss: 1.6890572309494019\n",
      "training 73.77%: 0.576. Loss: 1.6330633163452148\n",
      "training 73.83%: 0.576. Loss: 1.8936400413513184\n",
      "training 73.90%: 0.576. Loss: 1.7713085412979126\n",
      "training 73.96%: 0.576. Loss: 1.6199785470962524\n",
      "training 74.02%: 0.576. Loss: 1.7789772748947144\n",
      "training 74.09%: 0.576. Loss: 1.488407015800476\n",
      "training 74.15%: 0.576. Loss: 1.4850454330444336\n",
      "training 74.22%: 0.576. Loss: 1.765835165977478\n",
      "training 74.28%: 0.576. Loss: 1.9370287656784058\n",
      "training 74.34%: 0.576. Loss: 1.6985282897949219\n",
      "training 74.41%: 0.576. Loss: 1.7463725805282593\n",
      "training 74.47%: 0.576. Loss: 1.7820873260498047\n",
      "training 74.54%: 0.575. Loss: 1.9250046014785767\n",
      "training 74.60%: 0.576. Loss: 1.4133929014205933\n",
      "training 74.66%: 0.576. Loss: 1.5548160076141357\n",
      "training 74.73%: 0.576. Loss: 1.4238395690917969\n",
      "training 74.79%: 0.576. Loss: 1.7541205883026123\n",
      "training 74.86%: 0.576. Loss: 2.0519955158233643\n",
      "training 74.92%: 0.576. Loss: 1.7269376516342163\n",
      "training 74.98%: 0.576. Loss: 1.9493883848190308\n",
      "training 75.05%: 0.576. Loss: 1.642251968383789\n",
      "training 75.11%: 0.576. Loss: 1.6132845878601074\n",
      "training 75.18%: 0.576. Loss: 1.4654922485351562\n",
      "training 75.24%: 0.576. Loss: 1.8420038223266602\n",
      "training 75.30%: 0.576. Loss: 1.759515404701233\n",
      "training 75.37%: 0.576. Loss: 1.4474953413009644\n",
      "training 75.43%: 0.576. Loss: 1.6963233947753906\n",
      "training 75.50%: 0.576. Loss: 1.7077492475509644\n",
      "training 75.56%: 0.576. Loss: 1.9477044343948364\n",
      "training 75.62%: 0.575. Loss: 1.9158035516738892\n",
      "training 75.69%: 0.575. Loss: 1.8544713258743286\n",
      "training 75.75%: 0.575. Loss: 1.5876249074935913\n",
      "training 75.82%: 0.576. Loss: 1.3645820617675781\n",
      "training 75.88%: 0.575. Loss: 2.1957454681396484\n",
      "training 75.94%: 0.575. Loss: 1.8420648574829102\n",
      "training 76.01%: 0.575. Loss: 1.9442787170410156\n",
      "training 76.07%: 0.575. Loss: 1.7440311908721924\n",
      "training 76.14%: 0.575. Loss: 2.0234265327453613\n",
      "training 76.20%: 0.575. Loss: 1.7509084939956665\n",
      "training 76.26%: 0.575. Loss: 1.42527437210083\n",
      "training 76.33%: 0.575. Loss: 2.0012521743774414\n",
      "training 76.39%: 0.575. Loss: 2.0334558486938477\n",
      "training 76.46%: 0.575. Loss: 1.4277353286743164\n",
      "training 76.52%: 0.575. Loss: 1.5594546794891357\n",
      "training 76.58%: 0.575. Loss: 2.121936798095703\n",
      "training 76.65%: 0.575. Loss: 1.3905158042907715\n",
      "training 76.71%: 0.575. Loss: 1.7452551126480103\n",
      "training 76.78%: 0.575. Loss: 1.5233604907989502\n",
      "training 76.84%: 0.575. Loss: 1.8641880750656128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 76.90%: 0.575. Loss: 2.2287814617156982\n",
      "training 76.97%: 0.575. Loss: 1.4203802347183228\n",
      "training 77.03%: 0.575. Loss: 1.9195969104766846\n",
      "training 77.10%: 0.575. Loss: 2.284029006958008\n",
      "training 77.16%: 0.575. Loss: 2.2050976753234863\n",
      "training 77.22%: 0.575. Loss: 1.343835711479187\n",
      "training 77.29%: 0.575. Loss: 1.5627577304840088\n",
      "training 77.35%: 0.575. Loss: 1.6189734935760498\n",
      "training 77.42%: 0.575. Loss: 1.6832181215286255\n",
      "training 77.48%: 0.575. Loss: 1.7349400520324707\n",
      "training 77.54%: 0.575. Loss: 1.849217414855957\n",
      "training 77.61%: 0.575. Loss: 1.8632622957229614\n",
      "training 77.67%: 0.575. Loss: 1.68486487865448\n",
      "training 77.74%: 0.575. Loss: 2.323176145553589\n",
      "training 77.80%: 0.575. Loss: 1.445236086845398\n",
      "training 77.86%: 0.575. Loss: 1.7782527208328247\n",
      "training 77.93%: 0.575. Loss: 1.7381410598754883\n",
      "training 77.99%: 0.575. Loss: 1.286407709121704\n",
      "training 78.06%: 0.575. Loss: 2.0453665256500244\n",
      "training 78.12%: 0.575. Loss: 2.204786777496338\n",
      "training 78.18%: 0.575. Loss: 1.3947607278823853\n",
      "training 78.25%: 0.575. Loss: 1.7282192707061768\n",
      "training 78.31%: 0.575. Loss: 1.4975329637527466\n",
      "training 78.37%: 0.575. Loss: 2.020601987838745\n",
      "training 78.44%: 0.575. Loss: 2.089536666870117\n",
      "training 78.50%: 0.575. Loss: 1.5036057233810425\n",
      "training 78.57%: 0.575. Loss: 1.5826241970062256\n",
      "training 78.63%: 0.575. Loss: 1.5438868999481201\n",
      "training 78.69%: 0.575. Loss: 1.5086641311645508\n",
      "training 78.76%: 0.575. Loss: 2.240567684173584\n",
      "training 78.82%: 0.574. Loss: 2.2583048343658447\n",
      "training 78.89%: 0.574. Loss: 2.3711581230163574\n",
      "training 78.95%: 0.574. Loss: 1.4193992614746094\n",
      "training 79.01%: 0.574. Loss: 2.0701308250427246\n",
      "training 79.08%: 0.574. Loss: 1.56973397731781\n",
      "training 79.14%: 0.574. Loss: 1.6217862367630005\n",
      "training 79.21%: 0.574. Loss: 1.5115492343902588\n",
      "training 79.27%: 0.574. Loss: 1.9823644161224365\n",
      "training 79.33%: 0.574. Loss: 1.5025080442428589\n",
      "training 79.40%: 0.574. Loss: 1.7328048944473267\n",
      "training 79.46%: 0.574. Loss: 1.756277084350586\n",
      "training 79.53%: 0.574. Loss: 1.7012490034103394\n",
      "training 79.59%: 0.574. Loss: 1.4730805158615112\n",
      "training 79.65%: 0.574. Loss: 1.9834585189819336\n",
      "training 79.72%: 0.574. Loss: 1.2782917022705078\n",
      "training 79.78%: 0.574. Loss: 1.6082764863967896\n",
      "training 79.85%: 0.574. Loss: 1.7790868282318115\n",
      "training 79.91%: 0.574. Loss: 1.4808690547943115\n",
      "training 79.97%: 0.574. Loss: 1.7736570835113525\n",
      "training 80.04%: 0.574. Loss: 1.751171350479126\n",
      "training 80.10%: 0.575. Loss: 1.6507174968719482\n",
      "training 80.17%: 0.574. Loss: 1.755454659461975\n",
      "training 80.23%: 0.574. Loss: 1.881856918334961\n",
      "training 80.29%: 0.574. Loss: 1.4731066226959229\n",
      "training 80.36%: 0.574. Loss: 1.9535033702850342\n",
      "training 80.42%: 0.574. Loss: 1.855398178100586\n",
      "training 80.49%: 0.574. Loss: 1.6883974075317383\n",
      "training 80.55%: 0.574. Loss: 1.68242609500885\n",
      "training 80.61%: 0.574. Loss: 1.9239087104797363\n",
      "training 80.68%: 0.574. Loss: 1.5150635242462158\n",
      "training 80.74%: 0.574. Loss: 1.658817172050476\n",
      "training 80.81%: 0.574. Loss: 1.6956099271774292\n",
      "training 80.87%: 0.574. Loss: 2.1551198959350586\n",
      "training 80.93%: 0.574. Loss: 1.7565253973007202\n",
      "training 81.00%: 0.574. Loss: 1.5015944242477417\n",
      "training 81.06%: 0.574. Loss: 1.3415025472640991\n",
      "training 81.13%: 0.574. Loss: 2.0341951847076416\n",
      "training 81.19%: 0.574. Loss: 1.6473188400268555\n",
      "training 81.25%: 0.574. Loss: 1.6402376890182495\n",
      "training 81.32%: 0.574. Loss: 2.0769639015197754\n",
      "training 81.38%: 0.574. Loss: 1.4911404848098755\n",
      "training 81.45%: 0.574. Loss: 1.73076331615448\n",
      "training 81.51%: 0.574. Loss: 1.9234718084335327\n",
      "training 81.57%: 0.574. Loss: 1.5033854246139526\n",
      "training 81.64%: 0.574. Loss: 1.647763729095459\n",
      "training 81.70%: 0.574. Loss: 1.9073303937911987\n",
      "training 81.77%: 0.574. Loss: 1.8090821504592896\n",
      "training 81.83%: 0.574. Loss: 1.5473581552505493\n",
      "training 81.89%: 0.574. Loss: 1.8243224620819092\n",
      "training 81.96%: 0.574. Loss: 1.570839285850525\n",
      "training 82.02%: 0.574. Loss: 1.7003138065338135\n",
      "training 82.09%: 0.574. Loss: 1.8253015279769897\n",
      "training 82.15%: 0.574. Loss: 1.4854801893234253\n",
      "training 82.21%: 0.574. Loss: 1.884010910987854\n",
      "training 82.28%: 0.574. Loss: 1.5152406692504883\n",
      "training 82.34%: 0.574. Loss: 1.4146394729614258\n",
      "training 82.41%: 0.574. Loss: 1.7142908573150635\n",
      "training 82.47%: 0.574. Loss: 1.5095832347869873\n",
      "training 82.53%: 0.574. Loss: 1.9111279249191284\n",
      "training 82.60%: 0.574. Loss: 1.8015598058700562\n",
      "training 82.66%: 0.574. Loss: 1.9477461576461792\n",
      "training 82.73%: 0.574. Loss: 1.9427969455718994\n",
      "training 82.79%: 0.574. Loss: 2.0141489505767822\n",
      "training 82.85%: 0.574. Loss: 1.7903000116348267\n",
      "training 82.92%: 0.574. Loss: 1.5395112037658691\n",
      "training 82.98%: 0.574. Loss: 1.609225869178772\n",
      "training 83.05%: 0.574. Loss: 1.633676528930664\n",
      "training 83.11%: 0.574. Loss: 1.9397019147872925\n",
      "training 83.17%: 0.574. Loss: 1.8515475988388062\n",
      "training 83.24%: 0.574. Loss: 2.1682705879211426\n",
      "training 83.30%: 0.574. Loss: 1.6487233638763428\n",
      "training 83.37%: 0.574. Loss: 1.2994269132614136\n",
      "training 83.43%: 0.574. Loss: 1.7357667684555054\n",
      "training 83.49%: 0.574. Loss: 1.6532684564590454\n",
      "training 83.56%: 0.574. Loss: 1.7592835426330566\n",
      "training 83.62%: 0.574. Loss: 2.0218398571014404\n",
      "training 83.69%: 0.574. Loss: 1.9029797315597534\n",
      "training 83.75%: 0.574. Loss: 1.810632348060608\n",
      "training 83.81%: 0.574. Loss: 1.6642309427261353\n",
      "training 83.88%: 0.574. Loss: 1.6906238794326782\n",
      "training 83.94%: 0.574. Loss: 1.523252248764038\n",
      "training 84.01%: 0.574. Loss: 2.019601583480835\n",
      "training 84.07%: 0.574. Loss: 1.2293691635131836\n",
      "training 84.13%: 0.574. Loss: 1.9576894044876099\n",
      "training 84.20%: 0.574. Loss: 2.1721131801605225\n",
      "training 84.26%: 0.574. Loss: 1.7268500328063965\n",
      "training 84.33%: 0.574. Loss: 1.968930959701538\n",
      "training 84.39%: 0.573. Loss: 2.010899782180786\n",
      "training 84.45%: 0.574. Loss: 1.6747790575027466\n",
      "training 84.52%: 0.573. Loss: 1.8357983827590942\n",
      "training 84.58%: 0.573. Loss: 1.9598138332366943\n",
      "training 84.64%: 0.574. Loss: 1.32935631275177\n",
      "training 84.71%: 0.574. Loss: 1.9745001792907715\n",
      "training 84.77%: 0.574. Loss: 1.548053503036499\n",
      "training 84.84%: 0.574. Loss: 0.909225344657898\n",
      "training 84.90%: 0.574. Loss: 1.5085123777389526\n",
      "training 84.96%: 0.574. Loss: 1.827216625213623\n",
      "training 85.03%: 0.574. Loss: 1.742166519165039\n",
      "training 85.09%: 0.574. Loss: 1.6547701358795166\n",
      "training 85.16%: 0.574. Loss: 1.890749216079712\n",
      "training 85.22%: 0.574. Loss: 1.5965040922164917\n",
      "training 85.28%: 0.574. Loss: 1.8881915807724\n",
      "training 85.35%: 0.574. Loss: 1.7311676740646362\n",
      "training 85.41%: 0.574. Loss: 1.5565903186798096\n",
      "training 85.48%: 0.573. Loss: 1.9663846492767334\n",
      "training 85.54%: 0.573. Loss: 1.9682444334030151\n",
      "training 85.60%: 0.573. Loss: 1.8037091493606567\n",
      "training 85.67%: 0.574. Loss: 1.2580807209014893\n",
      "training 85.73%: 0.574. Loss: 1.6309400796890259\n",
      "training 85.80%: 0.574. Loss: 1.6532585620880127\n",
      "training 85.86%: 0.574. Loss: 2.0140950679779053\n",
      "training 85.92%: 0.574. Loss: 1.5203291177749634\n",
      "training 85.99%: 0.574. Loss: 1.7304261922836304\n",
      "training 86.05%: 0.574. Loss: 1.3574124574661255\n",
      "training 86.12%: 0.574. Loss: 1.8461288213729858\n",
      "training 86.18%: 0.574. Loss: 1.4897584915161133\n",
      "training 86.24%: 0.574. Loss: 1.5913234949111938\n",
      "training 86.31%: 0.574. Loss: 1.8508254289627075\n",
      "training 86.37%: 0.574. Loss: 1.4515516757965088\n",
      "training 86.44%: 0.574. Loss: 1.7720481157302856\n",
      "training 86.50%: 0.574. Loss: 1.9171173572540283\n",
      "training 86.56%: 0.574. Loss: 1.8570678234100342\n",
      "training 86.63%: 0.574. Loss: 1.6745675802230835\n",
      "training 86.69%: 0.574. Loss: 1.4994980096817017\n",
      "training 86.76%: 0.574. Loss: 1.6504297256469727\n",
      "training 86.82%: 0.574. Loss: 1.743924617767334\n",
      "training 86.88%: 0.574. Loss: 1.6744577884674072\n",
      "training 86.95%: 0.574. Loss: 1.5690149068832397\n",
      "training 87.01%: 0.574. Loss: 1.6434805393218994\n",
      "training 87.08%: 0.574. Loss: 2.2376911640167236\n",
      "training 87.14%: 0.574. Loss: 1.641941785812378\n",
      "training 87.20%: 0.574. Loss: 1.408560037612915\n",
      "training 87.27%: 0.574. Loss: 1.90437912940979\n",
      "training 87.33%: 0.574. Loss: 1.7659618854522705\n",
      "training 87.40%: 0.574. Loss: 1.9844328165054321\n",
      "training 87.46%: 0.574. Loss: 1.577435851097107\n",
      "training 87.52%: 0.574. Loss: 1.5131123065948486\n",
      "training 87.59%: 0.574. Loss: 1.9150439500808716\n",
      "training 87.65%: 0.574. Loss: 2.233428955078125\n",
      "training 87.72%: 0.574. Loss: 1.4415656328201294\n",
      "training 87.78%: 0.574. Loss: 1.6876540184020996\n",
      "training 87.84%: 0.574. Loss: 1.6957194805145264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 87.91%: 0.574. Loss: 1.873509407043457\n",
      "training 87.97%: 0.574. Loss: 1.3577865362167358\n",
      "training 88.04%: 0.574. Loss: 1.9400339126586914\n",
      "training 88.10%: 0.574. Loss: 1.2673369646072388\n",
      "training 88.16%: 0.574. Loss: 1.7223961353302002\n",
      "training 88.23%: 0.574. Loss: 1.9825825691223145\n",
      "training 88.29%: 0.574. Loss: 1.4037216901779175\n",
      "training 88.36%: 0.574. Loss: 1.6057499647140503\n",
      "training 88.42%: 0.574. Loss: 1.4562444686889648\n",
      "training 88.48%: 0.574. Loss: 1.459760069847107\n",
      "training 88.55%: 0.574. Loss: 2.1323277950286865\n",
      "training 88.61%: 0.574. Loss: 2.061964988708496\n",
      "training 88.68%: 0.574. Loss: 1.7196370363235474\n",
      "training 88.74%: 0.574. Loss: 1.9524478912353516\n",
      "training 88.80%: 0.574. Loss: 1.3525571823120117\n",
      "training 88.87%: 0.574. Loss: 1.6455246210098267\n",
      "training 88.93%: 0.574. Loss: 1.2402493953704834\n",
      "training 89.00%: 0.574. Loss: 1.5426007509231567\n",
      "training 89.06%: 0.574. Loss: 1.2524950504302979\n",
      "training 89.12%: 0.574. Loss: 2.5758213996887207\n",
      "training 89.19%: 0.574. Loss: 1.6149787902832031\n",
      "training 89.25%: 0.574. Loss: 1.8969390392303467\n",
      "training 89.32%: 0.574. Loss: 1.7298510074615479\n",
      "training 89.38%: 0.574. Loss: 1.9704039096832275\n",
      "training 89.44%: 0.574. Loss: 1.878409743309021\n",
      "training 89.51%: 0.574. Loss: 1.2197136878967285\n",
      "training 89.57%: 0.574. Loss: 1.866690754890442\n",
      "training 89.64%: 0.574. Loss: 1.7331053018569946\n",
      "training 89.70%: 0.574. Loss: 1.916407585144043\n",
      "training 89.76%: 0.574. Loss: 1.6501178741455078\n",
      "training 89.83%: 0.574. Loss: 1.356284499168396\n",
      "training 89.89%: 0.574. Loss: 1.8833556175231934\n",
      "training 89.96%: 0.574. Loss: 1.9323198795318604\n",
      "training 90.02%: 0.574. Loss: 1.4899317026138306\n",
      "training 90.08%: 0.574. Loss: 1.2948689460754395\n",
      "training 90.15%: 0.574. Loss: 1.4972752332687378\n",
      "training 90.21%: 0.574. Loss: 1.6501808166503906\n",
      "training 90.28%: 0.574. Loss: 1.8122743368148804\n",
      "training 90.34%: 0.574. Loss: 1.8995202779769897\n",
      "training 90.40%: 0.574. Loss: 1.8248703479766846\n",
      "training 90.47%: 0.574. Loss: 1.762803554534912\n",
      "training 90.53%: 0.574. Loss: 1.5983513593673706\n",
      "training 90.60%: 0.574. Loss: 1.5335654020309448\n",
      "training 90.66%: 0.574. Loss: 1.7754188776016235\n",
      "training 90.72%: 0.574. Loss: 1.9350106716156006\n",
      "training 90.79%: 0.574. Loss: 1.2630295753479004\n",
      "training 90.85%: 0.574. Loss: 1.619576096534729\n",
      "training 90.91%: 0.574. Loss: 1.9487850666046143\n",
      "training 90.98%: 0.574. Loss: 1.6424992084503174\n",
      "training 91.04%: 0.574. Loss: 1.61161470413208\n",
      "training 91.11%: 0.574. Loss: 1.400567889213562\n",
      "training 91.17%: 0.574. Loss: 2.0001494884490967\n",
      "training 91.23%: 0.574. Loss: 1.9050538539886475\n",
      "training 91.30%: 0.574. Loss: 1.7588953971862793\n",
      "training 91.36%: 0.574. Loss: 1.5790324211120605\n",
      "training 91.43%: 0.574. Loss: 2.173783779144287\n",
      "training 91.49%: 0.574. Loss: 1.5015673637390137\n",
      "training 91.55%: 0.574. Loss: 1.9806599617004395\n",
      "training 91.62%: 0.574. Loss: 1.4596047401428223\n",
      "training 91.68%: 0.574. Loss: 1.5715595483779907\n",
      "training 91.75%: 0.574. Loss: 1.9787667989730835\n",
      "training 91.81%: 0.574. Loss: 1.8136385679244995\n",
      "training 91.87%: 0.574. Loss: 1.7721456289291382\n",
      "training 91.94%: 0.574. Loss: 1.5452648401260376\n",
      "training 92.00%: 0.574. Loss: 1.3596112728118896\n",
      "training 92.07%: 0.574. Loss: 2.1942570209503174\n",
      "training 92.13%: 0.574. Loss: 1.4538921117782593\n",
      "training 92.19%: 0.574. Loss: 1.4580284357070923\n",
      "training 92.26%: 0.574. Loss: 1.5476447343826294\n",
      "training 92.32%: 0.574. Loss: 1.5614739656448364\n",
      "training 92.39%: 0.574. Loss: 1.5576701164245605\n",
      "training 92.45%: 0.574. Loss: 1.7288539409637451\n",
      "training 92.51%: 0.574. Loss: 1.752679467201233\n",
      "training 92.58%: 0.574. Loss: 2.418303966522217\n",
      "training 92.64%: 0.574. Loss: 1.8450071811676025\n",
      "training 92.71%: 0.574. Loss: 1.8251851797103882\n",
      "training 92.77%: 0.574. Loss: 1.6349122524261475\n",
      "training 92.83%: 0.574. Loss: 1.4447336196899414\n",
      "training 92.90%: 0.574. Loss: 1.811545491218567\n",
      "training 92.96%: 0.574. Loss: 1.900670051574707\n",
      "training 93.03%: 0.574. Loss: 2.0307202339172363\n",
      "training 93.09%: 0.574. Loss: 1.940313458442688\n",
      "training 93.15%: 0.574. Loss: 2.1274657249450684\n",
      "training 93.22%: 0.574. Loss: 1.713392734527588\n",
      "training 93.28%: 0.574. Loss: 1.6680290699005127\n",
      "training 93.35%: 0.574. Loss: 1.859590768814087\n",
      "training 93.41%: 0.574. Loss: 1.4391263723373413\n",
      "training 93.47%: 0.574. Loss: 1.4265252351760864\n",
      "training 93.54%: 0.574. Loss: 1.9345721006393433\n",
      "training 93.60%: 0.574. Loss: 1.6103968620300293\n",
      "training 93.67%: 0.574. Loss: 1.9171655178070068\n",
      "training 93.73%: 0.574. Loss: 1.6442865133285522\n",
      "training 93.79%: 0.574. Loss: 1.6483718156814575\n",
      "training 93.86%: 0.574. Loss: 1.5606437921524048\n",
      "training 93.92%: 0.574. Loss: 1.4256620407104492\n",
      "training 93.99%: 0.574. Loss: 1.7238361835479736\n",
      "training 94.05%: 0.574. Loss: 1.6170541048049927\n",
      "training 94.11%: 0.574. Loss: 2.0320043563842773\n",
      "training 94.18%: 0.574. Loss: 1.8412392139434814\n",
      "training 94.24%: 0.574. Loss: 1.854391098022461\n",
      "training 94.31%: 0.574. Loss: 1.6519708633422852\n",
      "training 94.37%: 0.574. Loss: 2.0368893146514893\n",
      "training 94.43%: 0.574. Loss: 1.6162790060043335\n",
      "training 94.50%: 0.573. Loss: 1.9641540050506592\n",
      "training 94.56%: 0.573. Loss: 1.6646579504013062\n",
      "training 94.63%: 0.573. Loss: 1.8545442819595337\n",
      "training 94.69%: 0.573. Loss: 1.5385611057281494\n",
      "training 94.75%: 0.573. Loss: 2.076263189315796\n",
      "training 94.82%: 0.573. Loss: 1.3561803102493286\n",
      "training 94.88%: 0.573. Loss: 1.6689153909683228\n",
      "training 94.95%: 0.573. Loss: 1.8793240785598755\n",
      "training 95.01%: 0.573. Loss: 2.0162315368652344\n",
      "training 95.07%: 0.573. Loss: 1.6670358180999756\n",
      "training 95.14%: 0.573. Loss: 1.6615867614746094\n",
      "training 95.20%: 0.573. Loss: 2.01078462600708\n",
      "training 95.27%: 0.573. Loss: 2.145338535308838\n",
      "training 95.33%: 0.573. Loss: 1.5947906970977783\n",
      "training 95.39%: 0.573. Loss: 1.576812744140625\n",
      "training 95.46%: 0.573. Loss: 1.5081480741500854\n",
      "training 95.52%: 0.573. Loss: 2.071587562561035\n",
      "training 95.59%: 0.573. Loss: 1.6374889612197876\n",
      "training 95.65%: 0.573. Loss: 1.7449007034301758\n",
      "training 95.71%: 0.573. Loss: 1.4889389276504517\n",
      "training 95.78%: 0.573. Loss: 2.06117582321167\n",
      "training 95.84%: 0.573. Loss: 1.3915164470672607\n",
      "training 95.91%: 0.573. Loss: 1.6776162385940552\n",
      "training 95.97%: 0.573. Loss: 1.7535120248794556\n",
      "training 96.03%: 0.573. Loss: 1.7278867959976196\n",
      "training 96.10%: 0.573. Loss: 1.8136054277420044\n",
      "training 96.16%: 0.574. Loss: 1.6126484870910645\n",
      "training 96.23%: 0.574. Loss: 1.319267749786377\n",
      "training 96.29%: 0.574. Loss: 1.9915932416915894\n",
      "training 96.35%: 0.574. Loss: 1.6882960796356201\n",
      "training 96.42%: 0.574. Loss: 1.8121448755264282\n",
      "training 96.48%: 0.574. Loss: 1.68993079662323\n",
      "training 96.55%: 0.574. Loss: 1.2463891506195068\n",
      "training 96.61%: 0.574. Loss: 1.9634286165237427\n",
      "training 96.67%: 0.574. Loss: 1.4118022918701172\n",
      "training 96.74%: 0.574. Loss: 1.6908910274505615\n",
      "training 96.80%: 0.574. Loss: 1.6648093461990356\n",
      "training 96.87%: 0.574. Loss: 1.6614710092544556\n",
      "training 96.93%: 0.574. Loss: 1.1998196840286255\n",
      "training 96.99%: 0.574. Loss: 1.7398706674575806\n",
      "training 97.06%: 0.574. Loss: 2.0901098251342773\n",
      "training 97.12%: 0.574. Loss: 2.032864809036255\n",
      "training 97.18%: 0.574. Loss: 1.6608035564422607\n",
      "training 97.25%: 0.574. Loss: 1.610283613204956\n",
      "training 97.31%: 0.574. Loss: 1.7455132007598877\n",
      "training 97.38%: 0.574. Loss: 1.4613258838653564\n",
      "training 97.44%: 0.574. Loss: 1.2842453718185425\n",
      "training 97.50%: 0.574. Loss: 1.7639365196228027\n",
      "training 97.57%: 0.574. Loss: 1.620151400566101\n",
      "training 97.63%: 0.574. Loss: 1.6319994926452637\n",
      "training 97.70%: 0.574. Loss: 1.5382294654846191\n",
      "training 97.76%: 0.574. Loss: 1.4054386615753174\n",
      "training 97.82%: 0.574. Loss: 1.5718992948532104\n",
      "training 97.89%: 0.574. Loss: 2.194038152694702\n",
      "training 97.95%: 0.574. Loss: 1.7463198900222778\n",
      "training 98.02%: 0.574. Loss: 1.800074815750122\n",
      "training 98.08%: 0.574. Loss: 1.8795887231826782\n",
      "training 98.14%: 0.574. Loss: 1.8294861316680908\n",
      "training 98.21%: 0.574. Loss: 1.8193602561950684\n",
      "training 98.27%: 0.574. Loss: 1.708154320716858\n",
      "training 98.34%: 0.574. Loss: 1.8882391452789307\n",
      "training 98.40%: 0.574. Loss: 1.4635347127914429\n",
      "training 98.46%: 0.574. Loss: 1.7047748565673828\n",
      "training 98.53%: 0.574. Loss: 1.6231178045272827\n",
      "training 98.59%: 0.574. Loss: 1.363896369934082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 98.66%: 0.574. Loss: 1.6333178281784058\n",
      "training 98.72%: 0.574. Loss: 1.7286285161972046\n",
      "training 98.78%: 0.574. Loss: 2.1640892028808594\n",
      "training 98.85%: 0.574. Loss: 1.9725580215454102\n",
      "training 98.91%: 0.574. Loss: 1.8957099914550781\n",
      "training 98.98%: 0.574. Loss: 1.700912356376648\n",
      "training 99.04%: 0.574. Loss: 1.5817830562591553\n",
      "training 99.10%: 0.574. Loss: 1.639110803604126\n",
      "training 99.17%: 0.574. Loss: 2.1080737113952637\n",
      "training 99.23%: 0.574. Loss: 1.6647168397903442\n",
      "training 99.30%: 0.574. Loss: 1.7590820789337158\n",
      "training 99.36%: 0.574. Loss: 1.636609435081482\n",
      "training 99.42%: 0.574. Loss: 1.7642523050308228\n",
      "training 99.49%: 0.574. Loss: 1.7647948265075684\n",
      "training 99.55%: 0.574. Loss: 1.6118333339691162\n",
      "training 99.62%: 0.574. Loss: 1.7617528438568115\n",
      "training 99.68%: 0.574. Loss: 1.8770774602890015\n",
      "training 99.74%: 0.574. Loss: 2.03719425201416\n",
      "training 99.81%: 0.573. Loss: 1.8784149885177612\n",
      "training 99.87%: 0.574. Loss: 1.7671396732330322\n",
      "training 99.94%: 0.574. Loss: 1.4122605323791504\n",
      "val 0.00%: 0.641. Loss: 1.4247307777404785\n",
      "val 0.64%: 0.562. Loss: 1.873954176902771\n",
      "val 1.27%: 0.552. Loss: 2.0541632175445557\n",
      "val 1.91%: 0.566. Loss: 1.758522868156433\n",
      "val 2.55%: 0.562. Loss: 2.0553553104400635\n",
      "val 3.18%: 0.581. Loss: 1.5748918056488037\n",
      "val 3.82%: 0.598. Loss: 1.2632142305374146\n",
      "val 4.46%: 0.596. Loss: 1.977960467338562\n",
      "val 5.10%: 0.602. Loss: 1.5071592330932617\n",
      "val 5.73%: 0.598. Loss: 1.692207932472229\n",
      "val 6.37%: 0.602. Loss: 1.5907224416732788\n",
      "val 7.01%: 0.602. Loss: 1.5255197286605835\n",
      "val 7.64%: 0.599. Loss: 1.9044873714447021\n",
      "val 8.28%: 0.597. Loss: 1.8039836883544922\n",
      "val 8.92%: 0.589. Loss: 2.074838161468506\n",
      "val 9.55%: 0.592. Loss: 1.586380124092102\n",
      "val 10.19%: 0.590. Loss: 1.9038050174713135\n",
      "val 10.83%: 0.593. Loss: 1.6833641529083252\n",
      "val 11.46%: 0.593. Loss: 1.5394649505615234\n",
      "val 12.10%: 0.593. Loss: 1.6885051727294922\n",
      "val 12.74%: 0.595. Loss: 1.4622431993484497\n",
      "val 13.38%: 0.591. Loss: 1.7493422031402588\n",
      "val 14.01%: 0.585. Loss: 2.103747606277466\n",
      "val 14.65%: 0.581. Loss: 2.0091025829315186\n",
      "val 15.29%: 0.581. Loss: 1.5740247964859009\n",
      "val 15.92%: 0.581. Loss: 1.9676071405410767\n",
      "val 16.56%: 0.582. Loss: 1.5817941427230835\n",
      "val 17.20%: 0.579. Loss: 1.839661955833435\n",
      "val 17.83%: 0.579. Loss: 1.627869725227356\n",
      "val 18.47%: 0.577. Loss: 2.165349245071411\n",
      "val 19.11%: 0.575. Loss: 1.827255368232727\n",
      "val 19.75%: 0.575. Loss: 1.8401843309402466\n",
      "val 20.38%: 0.578. Loss: 1.199827790260315\n",
      "val 21.02%: 0.581. Loss: 1.2965534925460815\n",
      "val 21.66%: 0.583. Loss: 1.5062353610992432\n",
      "val 22.29%: 0.586. Loss: 1.8424731492996216\n",
      "val 22.93%: 0.587. Loss: 1.4985233545303345\n",
      "val 23.57%: 0.588. Loss: 1.7608824968338013\n",
      "val 24.20%: 0.589. Loss: 1.693601369857788\n",
      "val 24.84%: 0.588. Loss: 1.6973408460617065\n",
      "val 25.48%: 0.588. Loss: 1.387439250946045\n",
      "val 26.11%: 0.586. Loss: 1.8845194578170776\n",
      "val 26.75%: 0.588. Loss: 1.4028645753860474\n",
      "val 27.39%: 0.587. Loss: 1.8511548042297363\n",
      "val 28.03%: 0.582. Loss: 2.0765678882598877\n",
      "val 28.66%: 0.579. Loss: 2.0795247554779053\n",
      "val 29.30%: 0.578. Loss: 1.8896305561065674\n",
      "val 29.94%: 0.578. Loss: 1.5426194667816162\n",
      "val 30.57%: 0.575. Loss: 2.0628790855407715\n",
      "val 31.21%: 0.571. Loss: 2.0598514080047607\n",
      "val 31.85%: 0.570. Loss: 2.1867551803588867\n",
      "val 32.48%: 0.570. Loss: 1.6309517621994019\n",
      "val 33.12%: 0.571. Loss: 1.4628381729125977\n",
      "val 33.76%: 0.573. Loss: 1.4650501012802124\n",
      "val 34.39%: 0.575. Loss: 1.4098702669143677\n",
      "val 35.03%: 0.574. Loss: 1.8032827377319336\n",
      "val 35.67%: 0.572. Loss: 2.053903341293335\n",
      "val 36.31%: 0.571. Loss: 2.0368199348449707\n",
      "val 36.94%: 0.573. Loss: 1.3485753536224365\n",
      "val 37.58%: 0.574. Loss: 1.6654893159866333\n",
      "val 38.22%: 0.574. Loss: 1.819547176361084\n",
      "val 38.85%: 0.576. Loss: 1.2751697301864624\n",
      "val 39.49%: 0.575. Loss: 1.6567606925964355\n",
      "val 40.13%: 0.573. Loss: 1.9785305261611938\n",
      "val 40.76%: 0.572. Loss: 1.8166825771331787\n",
      "val 41.40%: 0.572. Loss: 1.8542810678482056\n",
      "val 42.04%: 0.573. Loss: 1.7119617462158203\n",
      "val 42.68%: 0.572. Loss: 1.8572381734848022\n",
      "val 43.31%: 0.574. Loss: 1.311894178390503\n",
      "val 43.95%: 0.574. Loss: 1.6216000318527222\n",
      "val 44.59%: 0.574. Loss: 2.171278953552246\n",
      "val 45.22%: 0.574. Loss: 1.5225245952606201\n",
      "val 45.86%: 0.573. Loss: 2.0575225353240967\n",
      "val 46.50%: 0.574. Loss: 1.5430692434310913\n",
      "val 47.13%: 0.573. Loss: 1.7891448736190796\n",
      "val 47.77%: 0.574. Loss: 1.6364166736602783\n",
      "val 48.41%: 0.574. Loss: 2.0787665843963623\n",
      "val 49.04%: 0.574. Loss: 1.9591444730758667\n",
      "val 49.68%: 0.573. Loss: 1.9837819337844849\n",
      "val 50.32%: 0.572. Loss: 1.9808732271194458\n",
      "val 50.96%: 0.571. Loss: 1.7546709775924683\n",
      "val 51.59%: 0.570. Loss: 1.8042597770690918\n",
      "val 52.23%: 0.570. Loss: 1.7207763195037842\n",
      "val 52.87%: 0.570. Loss: 1.7803103923797607\n",
      "val 53.50%: 0.569. Loss: 1.9677482843399048\n",
      "val 54.14%: 0.568. Loss: 2.080562114715576\n",
      "val 54.78%: 0.568. Loss: 1.7568049430847168\n",
      "val 55.41%: 0.567. Loss: 1.9611668586730957\n",
      "val 56.05%: 0.567. Loss: 1.4830520153045654\n",
      "val 56.69%: 0.567. Loss: 1.7543238401412964\n",
      "val 57.32%: 0.567. Loss: 1.468130111694336\n",
      "val 57.96%: 0.568. Loss: 1.5069243907928467\n",
      "val 58.60%: 0.569. Loss: 1.0757317543029785\n",
      "val 59.24%: 0.569. Loss: 1.5965733528137207\n",
      "val 59.87%: 0.570. Loss: 1.3999769687652588\n",
      "val 60.51%: 0.570. Loss: 2.0538089275360107\n",
      "val 61.15%: 0.569. Loss: 2.0537819862365723\n",
      "val 61.78%: 0.569. Loss: 1.8009352684020996\n",
      "val 62.42%: 0.570. Loss: 1.387880802154541\n",
      "val 63.06%: 0.571. Loss: 1.3510128259658813\n",
      "val 63.69%: 0.571. Loss: 1.582574486732483\n",
      "val 64.33%: 0.570. Loss: 1.7995465993881226\n",
      "val 64.97%: 0.569. Loss: 2.123518466949463\n",
      "val 65.61%: 0.570. Loss: 1.7456799745559692\n",
      "val 66.24%: 0.571. Loss: 1.3336405754089355\n",
      "val 66.88%: 0.572. Loss: 1.283738374710083\n",
      "val 67.52%: 0.573. Loss: 1.4716899394989014\n",
      "val 68.15%: 0.573. Loss: 1.6733970642089844\n",
      "val 68.79%: 0.574. Loss: 1.2102736234664917\n",
      "val 69.43%: 0.574. Loss: 1.8478748798370361\n",
      "val 70.06%: 0.574. Loss: 1.789522647857666\n",
      "val 70.70%: 0.576. Loss: 1.1205263137817383\n",
      "val 71.34%: 0.575. Loss: 1.8881844282150269\n",
      "val 71.97%: 0.575. Loss: 1.6579216718673706\n",
      "val 72.61%: 0.576. Loss: 1.551871657371521\n",
      "val 73.25%: 0.574. Loss: 1.8116767406463623\n",
      "val 73.89%: 0.573. Loss: 2.067965269088745\n",
      "val 74.52%: 0.573. Loss: 1.654529333114624\n",
      "val 75.16%: 0.573. Loss: 1.7144675254821777\n",
      "val 75.80%: 0.573. Loss: 1.968536138534546\n",
      "val 76.43%: 0.573. Loss: 1.342287540435791\n",
      "val 77.07%: 0.572. Loss: 2.013723850250244\n",
      "val 77.71%: 0.572. Loss: 1.8159420490264893\n",
      "val 78.34%: 0.572. Loss: 2.0108489990234375\n",
      "val 78.98%: 0.573. Loss: 1.6221007108688354\n",
      "val 79.62%: 0.572. Loss: 2.0186073780059814\n",
      "val 80.25%: 0.572. Loss: 1.7662763595581055\n",
      "val 80.89%: 0.572. Loss: 1.6535793542861938\n",
      "val 81.53%: 0.571. Loss: 1.9626563787460327\n",
      "val 82.17%: 0.570. Loss: 2.222316265106201\n",
      "val 82.80%: 0.570. Loss: 1.646944284439087\n",
      "val 83.44%: 0.570. Loss: 1.870172381401062\n",
      "val 84.08%: 0.571. Loss: 1.4126932621002197\n",
      "val 84.71%: 0.571. Loss: 1.2938320636749268\n",
      "val 85.35%: 0.570. Loss: 2.0714969635009766\n",
      "val 85.99%: 0.569. Loss: 1.9414114952087402\n",
      "val 86.62%: 0.570. Loss: 1.6503499746322632\n",
      "val 87.26%: 0.570. Loss: 1.5030512809753418\n",
      "val 87.90%: 0.570. Loss: 1.7166465520858765\n",
      "val 88.54%: 0.571. Loss: 1.6394184827804565\n",
      "val 89.17%: 0.570. Loss: 1.6854453086853027\n",
      "val 89.81%: 0.570. Loss: 1.708613634109497\n",
      "val 90.45%: 0.570. Loss: 1.4072132110595703\n",
      "val 91.08%: 0.571. Loss: 1.7290124893188477\n",
      "val 91.72%: 0.570. Loss: 2.065897226333618\n",
      "val 92.36%: 0.570. Loss: 1.8791905641555786\n",
      "val 92.99%: 0.570. Loss: 1.4221930503845215\n",
      "val 93.63%: 0.571. Loss: 1.6462616920471191\n",
      "val 94.27%: 0.570. Loss: 2.3056061267852783\n",
      "val 94.90%: 0.570. Loss: 1.8128037452697754\n",
      "val 95.54%: 0.569. Loss: 1.976188063621521\n",
      "val 96.18%: 0.570. Loss: 1.6323506832122803\n",
      "val 96.82%: 0.570. Loss: 1.8754630088806152\n",
      "val 97.45%: 0.569. Loss: 2.1767754554748535\n",
      "val 98.09%: 0.569. Loss: 1.5141689777374268\n",
      "val 98.73%: 0.570. Loss: 1.6531784534454346\n",
      "val 99.36%: 0.570. Loss: 1.0547664165496826\n",
      "training 0.00%: 0.594. Loss: 1.7644617557525635\n",
      "training 0.06%: 0.625. Loss: 1.549200415611267\n",
      "training 0.13%: 0.641. Loss: 1.379125714302063\n",
      "training 0.19%: 0.641. Loss: 1.3355073928833008\n",
      "training 0.26%: 0.641. Loss: 1.4002714157104492\n",
      "training 0.32%: 0.641. Loss: 1.3144971132278442\n",
      "training 0.38%: 0.636. Loss: 1.4913052320480347\n",
      "training 0.45%: 0.631. Loss: 1.7661678791046143\n",
      "training 0.51%: 0.623. Loss: 1.7311723232269287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 0.58%: 0.623. Loss: 1.3633214235305786\n",
      "training 0.64%: 0.625. Loss: 1.5622152090072632\n",
      "training 0.70%: 0.625. Loss: 1.4612083435058594\n",
      "training 0.77%: 0.620. Loss: 1.6264113187789917\n",
      "training 0.83%: 0.619. Loss: 1.4785358905792236\n",
      "training 0.90%: 0.617. Loss: 1.6848253011703491\n",
      "training 0.96%: 0.613. Loss: 1.82659912109375\n",
      "training 1.02%: 0.611. Loss: 1.4497102499008179\n",
      "training 1.09%: 0.604. Loss: 2.0822582244873047\n",
      "training 1.15%: 0.604. Loss: 1.368241310119629\n",
      "training 1.22%: 0.605. Loss: 1.5818204879760742\n",
      "training 1.28%: 0.606. Loss: 1.4477256536483765\n",
      "training 1.34%: 0.605. Loss: 1.872907042503357\n",
      "training 1.41%: 0.602. Loss: 1.8813132047653198\n",
      "training 1.47%: 0.600. Loss: 1.8448607921600342\n",
      "training 1.54%: 0.598. Loss: 1.7248754501342773\n",
      "training 1.60%: 0.594. Loss: 1.7258460521697998\n",
      "training 1.66%: 0.594. Loss: 1.7964680194854736\n",
      "training 1.73%: 0.593. Loss: 1.7269866466522217\n",
      "training 1.79%: 0.592. Loss: 1.4629478454589844\n",
      "training 1.86%: 0.593. Loss: 1.4113796949386597\n",
      "training 1.92%: 0.592. Loss: 1.5304218530654907\n",
      "training 1.98%: 0.591. Loss: 1.8581783771514893\n",
      "training 2.05%: 0.589. Loss: 1.5116450786590576\n",
      "training 2.11%: 0.591. Loss: 1.4679298400878906\n",
      "training 2.18%: 0.588. Loss: 1.7939225435256958\n",
      "training 2.24%: 0.588. Loss: 1.3899365663528442\n",
      "training 2.30%: 0.590. Loss: 1.2816047668457031\n",
      "training 2.37%: 0.588. Loss: 1.8323562145233154\n",
      "training 2.43%: 0.586. Loss: 1.977136254310608\n",
      "training 2.50%: 0.584. Loss: 2.0650789737701416\n",
      "training 2.56%: 0.583. Loss: 1.7485740184783936\n",
      "training 2.62%: 0.583. Loss: 1.590022325515747\n",
      "training 2.69%: 0.585. Loss: 1.3331897258758545\n",
      "training 2.75%: 0.582. Loss: 1.865952491760254\n",
      "training 2.82%: 0.582. Loss: 1.8100398778915405\n",
      "training 2.88%: 0.581. Loss: 1.6083403825759888\n",
      "training 2.94%: 0.582. Loss: 1.6406445503234863\n",
      "training 3.01%: 0.582. Loss: 1.6378990411758423\n",
      "training 3.07%: 0.584. Loss: 1.4521681070327759\n",
      "training 3.13%: 0.585. Loss: 1.664346694946289\n",
      "training 3.20%: 0.586. Loss: 1.4993618726730347\n",
      "training 3.26%: 0.586. Loss: 1.5450184345245361\n",
      "training 3.33%: 0.587. Loss: 1.2638829946517944\n",
      "training 3.39%: 0.589. Loss: 1.2105011940002441\n",
      "training 3.45%: 0.588. Loss: 1.770053744316101\n",
      "training 3.52%: 0.590. Loss: 1.611655831336975\n",
      "training 3.58%: 0.591. Loss: 1.5687576532363892\n",
      "training 3.65%: 0.592. Loss: 1.3940578699111938\n",
      "training 3.71%: 0.593. Loss: 1.332230806350708\n",
      "training 3.77%: 0.595. Loss: 1.2690118551254272\n",
      "training 3.84%: 0.597. Loss: 1.6671817302703857\n",
      "training 3.90%: 0.597. Loss: 1.7292364835739136\n",
      "training 3.97%: 0.596. Loss: 1.5840107202529907\n",
      "training 4.03%: 0.599. Loss: 1.115924596786499\n",
      "training 4.09%: 0.600. Loss: 1.3392916917800903\n",
      "training 4.16%: 0.601. Loss: 1.408881664276123\n",
      "training 4.22%: 0.601. Loss: 1.596327781677246\n",
      "training 4.29%: 0.602. Loss: 1.2658047676086426\n",
      "training 4.35%: 0.601. Loss: 1.8661600351333618\n",
      "training 4.41%: 0.602. Loss: 1.466860294342041\n",
      "training 4.48%: 0.602. Loss: 1.5679750442504883\n",
      "training 4.54%: 0.601. Loss: 1.4268218278884888\n",
      "training 4.61%: 0.601. Loss: 1.6297303438186646\n",
      "training 4.67%: 0.602. Loss: 1.4380738735198975\n",
      "training 4.73%: 0.604. Loss: 1.372603416442871\n",
      "training 4.80%: 0.603. Loss: 1.9108442068099976\n",
      "training 4.86%: 0.602. Loss: 1.6555542945861816\n",
      "training 4.93%: 0.604. Loss: 1.0569818019866943\n",
      "training 4.99%: 0.603. Loss: 1.73038911819458\n",
      "training 5.05%: 0.603. Loss: 1.744202733039856\n",
      "training 5.12%: 0.603. Loss: 1.494070053100586\n",
      "training 5.18%: 0.604. Loss: 1.4509224891662598\n",
      "training 5.25%: 0.602. Loss: 2.140026092529297\n",
      "training 5.31%: 0.601. Loss: 1.865946888923645\n",
      "training 5.37%: 0.603. Loss: 1.3235803842544556\n",
      "training 5.44%: 0.603. Loss: 1.3537688255310059\n",
      "training 5.50%: 0.603. Loss: 1.4968904256820679\n",
      "training 5.57%: 0.602. Loss: 2.0295395851135254\n",
      "training 5.63%: 0.603. Loss: 1.4922643899917603\n",
      "training 5.69%: 0.603. Loss: 1.937482237815857\n",
      "training 5.76%: 0.604. Loss: 1.277608036994934\n",
      "training 5.82%: 0.604. Loss: 1.4871352910995483\n",
      "training 5.89%: 0.603. Loss: 1.7835761308670044\n",
      "training 5.95%: 0.604. Loss: 1.4128379821777344\n",
      "training 6.01%: 0.603. Loss: 1.8548755645751953\n",
      "training 6.08%: 0.603. Loss: 1.794939637184143\n",
      "training 6.14%: 0.603. Loss: 1.2983813285827637\n",
      "training 6.21%: 0.604. Loss: 1.5387248992919922\n",
      "training 6.27%: 0.604. Loss: 1.8550779819488525\n",
      "training 6.33%: 0.603. Loss: 1.4609811305999756\n",
      "training 6.40%: 0.603. Loss: 1.6587175130844116\n",
      "training 6.46%: 0.603. Loss: 1.741861343383789\n",
      "training 6.53%: 0.603. Loss: 1.6750637292861938\n",
      "training 6.59%: 0.604. Loss: 1.385613203048706\n",
      "training 6.65%: 0.603. Loss: 1.6853108406066895\n",
      "training 6.72%: 0.603. Loss: 1.4912139177322388\n",
      "training 6.78%: 0.602. Loss: 1.973981261253357\n",
      "training 6.85%: 0.602. Loss: 1.73176908493042\n",
      "training 6.91%: 0.602. Loss: 1.5302889347076416\n",
      "training 6.97%: 0.602. Loss: 1.7966253757476807\n",
      "training 7.04%: 0.602. Loss: 1.551550030708313\n",
      "training 7.10%: 0.602. Loss: 1.7873427867889404\n",
      "training 7.17%: 0.602. Loss: 1.3751685619354248\n",
      "training 7.23%: 0.602. Loss: 1.5660845041275024\n",
      "training 7.29%: 0.602. Loss: 1.7805627584457397\n",
      "training 7.36%: 0.602. Loss: 1.6139533519744873\n",
      "training 7.42%: 0.602. Loss: 1.4532111883163452\n",
      "training 7.49%: 0.603. Loss: 1.4676599502563477\n",
      "training 7.55%: 0.603. Loss: 1.5475646257400513\n",
      "training 7.61%: 0.602. Loss: 1.9017372131347656\n",
      "training 7.68%: 0.602. Loss: 1.487783432006836\n",
      "training 7.74%: 0.603. Loss: 1.2974047660827637\n",
      "training 7.81%: 0.603. Loss: 1.8286763429641724\n",
      "training 7.87%: 0.603. Loss: 1.5062013864517212\n",
      "training 7.93%: 0.603. Loss: 1.7633675336837769\n",
      "training 8.00%: 0.603. Loss: 1.6173285245895386\n",
      "training 8.06%: 0.603. Loss: 1.7811520099639893\n",
      "training 8.13%: 0.604. Loss: 1.3619028329849243\n",
      "training 8.19%: 0.604. Loss: 1.3185323476791382\n",
      "training 8.25%: 0.605. Loss: 1.4706321954727173\n",
      "training 8.32%: 0.605. Loss: 1.4566457271575928\n",
      "training 8.38%: 0.604. Loss: 1.7285561561584473\n",
      "training 8.45%: 0.604. Loss: 1.6414414644241333\n",
      "training 8.51%: 0.604. Loss: 1.7040998935699463\n",
      "training 8.57%: 0.604. Loss: 1.6178479194641113\n",
      "training 8.64%: 0.605. Loss: 1.355385661125183\n",
      "training 8.70%: 0.605. Loss: 1.7108049392700195\n",
      "training 8.77%: 0.604. Loss: 1.7443472146987915\n",
      "training 8.83%: 0.605. Loss: 1.3590798377990723\n",
      "training 8.89%: 0.604. Loss: 1.8135457038879395\n",
      "training 8.96%: 0.605. Loss: 1.1366161108016968\n",
      "training 9.02%: 0.605. Loss: 1.7400318384170532\n",
      "training 9.09%: 0.605. Loss: 1.4608021974563599\n",
      "training 9.15%: 0.605. Loss: 1.539671778678894\n",
      "training 9.21%: 0.605. Loss: 1.4756755828857422\n",
      "training 9.28%: 0.605. Loss: 1.4609079360961914\n",
      "training 9.34%: 0.606. Loss: 1.639023780822754\n",
      "training 9.40%: 0.606. Loss: 1.5172739028930664\n",
      "training 9.47%: 0.607. Loss: 1.2878029346466064\n",
      "training 9.53%: 0.606. Loss: 1.7833298444747925\n",
      "training 9.60%: 0.607. Loss: 1.3417701721191406\n",
      "training 9.66%: 0.607. Loss: 1.3761868476867676\n",
      "training 9.72%: 0.607. Loss: 1.3784524202346802\n",
      "training 9.79%: 0.607. Loss: 1.342353343963623\n",
      "training 9.85%: 0.608. Loss: 1.27364182472229\n",
      "training 9.92%: 0.607. Loss: 1.690442442893982\n",
      "training 9.98%: 0.607. Loss: 2.462785482406616\n",
      "training 10.04%: 0.607. Loss: 1.7350863218307495\n",
      "training 10.11%: 0.606. Loss: 1.9153200387954712\n",
      "training 10.17%: 0.606. Loss: 1.647303581237793\n",
      "training 10.24%: 0.606. Loss: 1.6322121620178223\n",
      "training 10.30%: 0.606. Loss: 1.5318783521652222\n",
      "training 10.36%: 0.606. Loss: 1.4781365394592285\n",
      "training 10.43%: 0.607. Loss: 1.44828200340271\n",
      "training 10.49%: 0.606. Loss: 1.9514304399490356\n",
      "training 10.56%: 0.606. Loss: 1.243080496788025\n",
      "training 10.62%: 0.606. Loss: 1.7439011335372925\n",
      "training 10.68%: 0.605. Loss: 2.038255453109741\n",
      "training 10.75%: 0.604. Loss: 1.5366718769073486\n",
      "training 10.81%: 0.605. Loss: 1.1498825550079346\n",
      "training 10.88%: 0.605. Loss: 1.332671046257019\n",
      "training 10.94%: 0.605. Loss: 1.7541395425796509\n",
      "training 11.00%: 0.604. Loss: 1.6973191499710083\n",
      "training 11.07%: 0.605. Loss: 1.1642723083496094\n",
      "training 11.13%: 0.604. Loss: 2.045311689376831\n",
      "training 11.20%: 0.605. Loss: 1.236096978187561\n",
      "training 11.26%: 0.604. Loss: 1.78386652469635\n",
      "training 11.32%: 0.605. Loss: 1.534928560256958\n",
      "training 11.39%: 0.605. Loss: 1.5373284816741943\n",
      "training 11.45%: 0.605. Loss: 1.7530488967895508\n",
      "training 11.52%: 0.604. Loss: 1.839389443397522\n",
      "training 11.58%: 0.604. Loss: 1.7686835527420044\n",
      "training 11.64%: 0.604. Loss: 1.4394922256469727\n",
      "training 11.71%: 0.604. Loss: 1.534433364868164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 11.77%: 0.605. Loss: 1.4800382852554321\n",
      "training 11.84%: 0.605. Loss: 1.5237277746200562\n",
      "training 11.90%: 0.605. Loss: 1.6385962963104248\n",
      "training 11.96%: 0.605. Loss: 1.3980499505996704\n",
      "training 12.03%: 0.605. Loss: 1.799252986907959\n",
      "training 12.09%: 0.605. Loss: 1.5450055599212646\n",
      "training 12.16%: 0.605. Loss: 1.724432110786438\n",
      "training 12.22%: 0.605. Loss: 1.3140023946762085\n",
      "training 12.28%: 0.605. Loss: 1.679939866065979\n",
      "training 12.35%: 0.605. Loss: 2.0410678386688232\n",
      "training 12.41%: 0.605. Loss: 1.3081728219985962\n",
      "training 12.48%: 0.605. Loss: 1.3166416883468628\n",
      "training 12.54%: 0.605. Loss: 1.7607225179672241\n",
      "training 12.60%: 0.604. Loss: 1.7728286981582642\n",
      "training 12.67%: 0.604. Loss: 1.7541776895523071\n",
      "training 12.73%: 0.604. Loss: 1.366097331047058\n",
      "training 12.80%: 0.604. Loss: 1.711378812789917\n",
      "training 12.86%: 0.603. Loss: 1.7517783641815186\n",
      "training 12.92%: 0.604. Loss: 1.3693217039108276\n",
      "training 12.99%: 0.604. Loss: 1.4677112102508545\n",
      "training 13.05%: 0.604. Loss: 1.202693223953247\n",
      "training 13.12%: 0.604. Loss: 1.5352718830108643\n",
      "training 13.18%: 0.604. Loss: 1.5743876695632935\n",
      "training 13.24%: 0.604. Loss: 1.6195507049560547\n",
      "training 13.31%: 0.604. Loss: 1.5675418376922607\n",
      "training 13.37%: 0.604. Loss: 1.5976436138153076\n",
      "training 13.44%: 0.604. Loss: 1.586635708808899\n",
      "training 13.50%: 0.604. Loss: 1.398938536643982\n",
      "training 13.56%: 0.604. Loss: 1.4967707395553589\n",
      "training 13.63%: 0.604. Loss: 1.911109447479248\n",
      "training 13.69%: 0.604. Loss: 1.2641291618347168\n",
      "training 13.76%: 0.604. Loss: 1.8621430397033691\n",
      "training 13.82%: 0.605. Loss: 1.1234846115112305\n",
      "training 13.88%: 0.605. Loss: 1.6142451763153076\n",
      "training 13.95%: 0.604. Loss: 1.5925252437591553\n",
      "training 14.01%: 0.605. Loss: 1.4437992572784424\n",
      "training 14.08%: 0.604. Loss: 1.712839961051941\n",
      "training 14.14%: 0.604. Loss: 1.4767658710479736\n",
      "training 14.20%: 0.605. Loss: 1.3106848001480103\n",
      "training 14.27%: 0.604. Loss: 1.9850670099258423\n",
      "training 14.33%: 0.604. Loss: 1.579284429550171\n",
      "training 14.40%: 0.604. Loss: 1.3865317106246948\n",
      "training 14.46%: 0.604. Loss: 1.682357668876648\n",
      "training 14.52%: 0.604. Loss: 1.6616151332855225\n",
      "training 14.59%: 0.604. Loss: 1.8632580041885376\n",
      "training 14.65%: 0.604. Loss: 1.672463297843933\n",
      "training 14.72%: 0.604. Loss: 1.7669062614440918\n",
      "training 14.78%: 0.604. Loss: 1.7368487119674683\n",
      "training 14.84%: 0.603. Loss: 1.612490177154541\n",
      "training 14.91%: 0.604. Loss: 1.2348297834396362\n",
      "training 14.97%: 0.604. Loss: 1.4211937189102173\n",
      "training 15.04%: 0.604. Loss: 1.252440333366394\n",
      "training 15.10%: 0.604. Loss: 1.8427233695983887\n",
      "training 15.16%: 0.604. Loss: 1.6018084287643433\n",
      "training 15.23%: 0.604. Loss: 1.8376686573028564\n",
      "training 15.29%: 0.604. Loss: 2.08302903175354\n",
      "training 15.36%: 0.603. Loss: 1.6388968229293823\n",
      "training 15.42%: 0.603. Loss: 1.8681856393814087\n",
      "training 15.48%: 0.603. Loss: 1.7906320095062256\n",
      "training 15.55%: 0.603. Loss: 1.6368476152420044\n",
      "training 15.61%: 0.603. Loss: 1.3656070232391357\n",
      "training 15.67%: 0.602. Loss: 1.4806957244873047\n",
      "training 15.74%: 0.603. Loss: 1.3881158828735352\n",
      "training 15.80%: 0.603. Loss: 1.2755630016326904\n",
      "training 15.87%: 0.602. Loss: 2.001720428466797\n",
      "training 15.93%: 0.602. Loss: 1.5378817319869995\n",
      "training 15.99%: 0.602. Loss: 1.526210904121399\n",
      "training 16.06%: 0.602. Loss: 1.7404532432556152\n",
      "training 16.12%: 0.602. Loss: 1.9350465536117554\n",
      "training 16.19%: 0.602. Loss: 1.7144505977630615\n",
      "training 16.25%: 0.602. Loss: 1.4643486738204956\n",
      "training 16.31%: 0.602. Loss: 1.6287659406661987\n",
      "training 16.38%: 0.602. Loss: 1.2524060010910034\n",
      "training 16.44%: 0.602. Loss: 1.3665701150894165\n",
      "training 16.51%: 0.602. Loss: 1.4859827756881714\n",
      "training 16.57%: 0.602. Loss: 1.8205584287643433\n",
      "training 16.63%: 0.602. Loss: 1.542791485786438\n",
      "training 16.70%: 0.602. Loss: 1.6031023263931274\n",
      "training 16.76%: 0.602. Loss: 1.7130608558654785\n",
      "training 16.83%: 0.602. Loss: 1.7623003721237183\n",
      "training 16.89%: 0.602. Loss: 1.7482757568359375\n",
      "training 16.95%: 0.602. Loss: 1.685900092124939\n",
      "training 17.02%: 0.602. Loss: 1.2355817556381226\n",
      "training 17.08%: 0.602. Loss: 1.74739670753479\n",
      "training 17.15%: 0.602. Loss: 1.7031019926071167\n",
      "training 17.21%: 0.601. Loss: 1.7476894855499268\n",
      "training 17.27%: 0.601. Loss: 1.7426743507385254\n",
      "training 17.34%: 0.601. Loss: 1.6099774837493896\n",
      "training 17.40%: 0.602. Loss: 1.4232025146484375\n",
      "training 17.47%: 0.602. Loss: 1.637298345565796\n",
      "training 17.53%: 0.602. Loss: 1.8506534099578857\n",
      "training 17.59%: 0.601. Loss: 1.586955189704895\n",
      "training 17.66%: 0.601. Loss: 1.4395554065704346\n",
      "training 17.72%: 0.602. Loss: 1.3395872116088867\n",
      "training 17.79%: 0.602. Loss: 1.633638620376587\n",
      "training 17.85%: 0.601. Loss: 1.9126958847045898\n",
      "training 17.91%: 0.601. Loss: 2.028329610824585\n",
      "training 17.98%: 0.601. Loss: 1.8266921043395996\n",
      "training 18.04%: 0.601. Loss: 1.5704289674758911\n",
      "training 18.11%: 0.601. Loss: 1.4590002298355103\n",
      "training 18.17%: 0.601. Loss: 2.0453720092773438\n",
      "training 18.23%: 0.601. Loss: 1.2851790189743042\n",
      "training 18.30%: 0.601. Loss: 2.038405179977417\n",
      "training 18.36%: 0.601. Loss: 1.437181830406189\n",
      "training 18.43%: 0.601. Loss: 1.481632113456726\n",
      "training 18.49%: 0.601. Loss: 1.4200270175933838\n",
      "training 18.55%: 0.601. Loss: 1.8800859451293945\n",
      "training 18.62%: 0.601. Loss: 1.6078993082046509\n",
      "training 18.68%: 0.600. Loss: 2.2882606983184814\n",
      "training 18.75%: 0.600. Loss: 1.6470292806625366\n",
      "training 18.81%: 0.600. Loss: 1.2160481214523315\n",
      "training 18.87%: 0.600. Loss: 2.0401835441589355\n",
      "training 18.94%: 0.600. Loss: 1.8038030862808228\n",
      "training 19.00%: 0.600. Loss: 1.7837190628051758\n",
      "training 19.07%: 0.600. Loss: 1.4970977306365967\n",
      "training 19.13%: 0.600. Loss: 1.1546512842178345\n",
      "training 19.19%: 0.601. Loss: 1.3220369815826416\n",
      "training 19.26%: 0.601. Loss: 1.6061882972717285\n",
      "training 19.32%: 0.601. Loss: 1.4968159198760986\n",
      "training 19.39%: 0.601. Loss: 1.5454928874969482\n",
      "training 19.45%: 0.601. Loss: 1.777411699295044\n",
      "training 19.51%: 0.600. Loss: 1.6805288791656494\n",
      "training 19.58%: 0.601. Loss: 1.2988201379776\n",
      "training 19.64%: 0.601. Loss: 1.5703667402267456\n",
      "training 19.71%: 0.601. Loss: 1.5039457082748413\n",
      "training 19.77%: 0.601. Loss: 1.8679770231246948\n",
      "training 19.83%: 0.601. Loss: 1.6240696907043457\n",
      "training 19.90%: 0.601. Loss: 1.546785831451416\n",
      "training 19.96%: 0.601. Loss: 1.5672341585159302\n",
      "training 20.03%: 0.601. Loss: 1.3721128702163696\n",
      "training 20.09%: 0.601. Loss: 1.6359896659851074\n",
      "training 20.15%: 0.601. Loss: 1.416847825050354\n",
      "training 20.22%: 0.601. Loss: 2.09429931640625\n",
      "training 20.28%: 0.601. Loss: 1.7342132329940796\n",
      "training 20.35%: 0.601. Loss: 1.576151728630066\n",
      "training 20.41%: 0.600. Loss: 1.804993748664856\n",
      "training 20.47%: 0.601. Loss: 1.2253243923187256\n",
      "training 20.54%: 0.601. Loss: 1.5530664920806885\n",
      "training 20.60%: 0.601. Loss: 1.415202260017395\n",
      "training 20.67%: 0.601. Loss: 1.5133392810821533\n",
      "training 20.73%: 0.601. Loss: 1.786976933479309\n",
      "training 20.79%: 0.601. Loss: 1.9548276662826538\n",
      "training 20.86%: 0.601. Loss: 1.4278125762939453\n",
      "training 20.92%: 0.601. Loss: 1.771479845046997\n",
      "training 20.99%: 0.600. Loss: 1.5427210330963135\n",
      "training 21.05%: 0.600. Loss: 1.7177566289901733\n",
      "training 21.11%: 0.600. Loss: 2.165452480316162\n",
      "training 21.18%: 0.600. Loss: 1.6752936840057373\n",
      "training 21.24%: 0.600. Loss: 1.8848342895507812\n",
      "training 21.31%: 0.600. Loss: 1.4787070751190186\n",
      "training 21.37%: 0.600. Loss: 2.104567766189575\n",
      "training 21.43%: 0.600. Loss: 1.451914668083191\n",
      "training 21.50%: 0.599. Loss: 1.8191006183624268\n",
      "training 21.56%: 0.599. Loss: 1.5200207233428955\n",
      "training 21.63%: 0.600. Loss: 1.436539888381958\n",
      "training 21.69%: 0.600. Loss: 1.1849479675292969\n",
      "training 21.75%: 0.600. Loss: 1.7527557611465454\n",
      "training 21.82%: 0.599. Loss: 1.692163348197937\n",
      "training 21.88%: 0.600. Loss: 1.2345460653305054\n",
      "training 21.94%: 0.600. Loss: 1.4356114864349365\n",
      "training 22.01%: 0.600. Loss: 1.6052693128585815\n",
      "training 22.07%: 0.600. Loss: 1.8615912199020386\n",
      "training 22.14%: 0.600. Loss: 1.6656759977340698\n",
      "training 22.20%: 0.600. Loss: 1.6374824047088623\n",
      "training 22.26%: 0.599. Loss: 2.0157811641693115\n",
      "training 22.33%: 0.599. Loss: 1.5255669355392456\n",
      "training 22.39%: 0.600. Loss: 1.3726859092712402\n",
      "training 22.46%: 0.600. Loss: 1.2999347448349\n",
      "training 22.52%: 0.600. Loss: 1.4567586183547974\n",
      "training 22.58%: 0.600. Loss: 1.7423758506774902\n",
      "training 22.65%: 0.600. Loss: 1.6757779121398926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 22.71%: 0.599. Loss: 1.6884982585906982\n",
      "training 22.78%: 0.600. Loss: 1.3677997589111328\n",
      "training 22.84%: 0.599. Loss: 1.8339532613754272\n",
      "training 22.90%: 0.599. Loss: 1.6457185745239258\n",
      "training 22.97%: 0.599. Loss: 1.6391764879226685\n",
      "training 23.03%: 0.599. Loss: 1.4338065385818481\n",
      "training 23.10%: 0.599. Loss: 1.3992061614990234\n",
      "training 23.16%: 0.599. Loss: 1.8490005731582642\n",
      "training 23.22%: 0.599. Loss: 1.561469316482544\n",
      "training 23.29%: 0.599. Loss: 1.4129589796066284\n",
      "training 23.35%: 0.599. Loss: 1.7800240516662598\n",
      "training 23.42%: 0.599. Loss: 1.9566264152526855\n",
      "training 23.48%: 0.599. Loss: 1.8147283792495728\n",
      "training 23.54%: 0.599. Loss: 1.8028851747512817\n",
      "training 23.61%: 0.599. Loss: 1.5383111238479614\n",
      "training 23.67%: 0.599. Loss: 1.3068442344665527\n",
      "training 23.74%: 0.599. Loss: 1.8046486377716064\n",
      "training 23.80%: 0.599. Loss: 1.0143299102783203\n",
      "training 23.86%: 0.599. Loss: 1.6329121589660645\n",
      "training 23.93%: 0.600. Loss: 1.497488021850586\n",
      "training 23.99%: 0.600. Loss: 1.728779673576355\n",
      "training 24.06%: 0.599. Loss: 1.835861325263977\n",
      "training 24.12%: 0.599. Loss: 1.62297785282135\n",
      "training 24.18%: 0.600. Loss: 1.249652624130249\n",
      "training 24.25%: 0.600. Loss: 1.1718684434890747\n",
      "training 24.31%: 0.600. Loss: 1.5367779731750488\n",
      "training 24.38%: 0.600. Loss: 1.50701105594635\n",
      "training 24.44%: 0.600. Loss: 1.8615683317184448\n",
      "training 24.50%: 0.600. Loss: 1.5548948049545288\n",
      "training 24.57%: 0.600. Loss: 1.7133933305740356\n",
      "training 24.63%: 0.599. Loss: 2.2958710193634033\n",
      "training 24.70%: 0.600. Loss: 1.5436270236968994\n",
      "training 24.76%: 0.599. Loss: 1.6891981363296509\n",
      "training 24.82%: 0.600. Loss: 1.4721184968948364\n",
      "training 24.89%: 0.600. Loss: 1.4362269639968872\n",
      "training 24.95%: 0.600. Loss: 1.5238667726516724\n",
      "training 25.02%: 0.600. Loss: 1.1691056489944458\n",
      "training 25.08%: 0.600. Loss: 1.4751416444778442\n",
      "training 25.14%: 0.600. Loss: 1.9611531496047974\n",
      "training 25.21%: 0.600. Loss: 1.548872947692871\n",
      "training 25.27%: 0.600. Loss: 1.7684361934661865\n",
      "training 25.34%: 0.600. Loss: 1.4670363664627075\n",
      "training 25.40%: 0.600. Loss: 1.5211472511291504\n",
      "training 25.46%: 0.600. Loss: 1.4189460277557373\n",
      "training 25.53%: 0.600. Loss: 1.5174384117126465\n",
      "training 25.59%: 0.600. Loss: 1.8477364778518677\n",
      "training 25.66%: 0.601. Loss: 1.8361241817474365\n",
      "training 25.72%: 0.601. Loss: 1.6182498931884766\n",
      "training 25.78%: 0.600. Loss: 1.7040103673934937\n",
      "training 25.85%: 0.601. Loss: 1.538908839225769\n",
      "training 25.91%: 0.601. Loss: 1.5558983087539673\n",
      "training 25.98%: 0.601. Loss: 1.2001874446868896\n",
      "training 26.04%: 0.600. Loss: 1.9620494842529297\n",
      "training 26.10%: 0.600. Loss: 1.8449229001998901\n",
      "training 26.17%: 0.600. Loss: 1.2216582298278809\n",
      "training 26.23%: 0.600. Loss: 1.4919342994689941\n",
      "training 26.30%: 0.601. Loss: 1.1837129592895508\n",
      "training 26.36%: 0.601. Loss: 1.6237130165100098\n",
      "training 26.42%: 0.601. Loss: 1.3459235429763794\n",
      "training 26.49%: 0.602. Loss: 1.5930968523025513\n",
      "training 26.55%: 0.602. Loss: 1.5929510593414307\n",
      "training 26.62%: 0.601. Loss: 1.6332372426986694\n",
      "training 26.68%: 0.601. Loss: 1.4905842542648315\n",
      "training 26.74%: 0.601. Loss: 2.3643884658813477\n",
      "training 26.81%: 0.601. Loss: 1.4612975120544434\n",
      "training 26.87%: 0.601. Loss: 1.6192814111709595\n",
      "training 26.94%: 0.601. Loss: 1.301950216293335\n",
      "training 27.00%: 0.602. Loss: 1.4711949825286865\n",
      "training 27.06%: 0.602. Loss: 2.004256010055542\n",
      "training 27.13%: 0.602. Loss: 1.4010047912597656\n",
      "training 27.19%: 0.602. Loss: 1.8924978971481323\n",
      "training 27.26%: 0.602. Loss: 1.7216750383377075\n",
      "training 27.32%: 0.602. Loss: 1.498120903968811\n",
      "training 27.38%: 0.601. Loss: 1.7355263233184814\n",
      "training 27.45%: 0.602. Loss: 1.3770018815994263\n",
      "training 27.51%: 0.602. Loss: 1.5326555967330933\n",
      "training 27.58%: 0.602. Loss: 1.7378486394882202\n",
      "training 27.64%: 0.602. Loss: 1.4865764379501343\n",
      "training 27.70%: 0.602. Loss: 1.5162692070007324\n",
      "training 27.77%: 0.602. Loss: 1.6627835035324097\n",
      "training 27.83%: 0.602. Loss: 1.9355418682098389\n",
      "training 27.90%: 0.601. Loss: 1.7870789766311646\n",
      "training 27.96%: 0.601. Loss: 1.6449109315872192\n",
      "training 28.02%: 0.601. Loss: 1.7694411277770996\n",
      "training 28.09%: 0.601. Loss: 1.9041268825531006\n",
      "training 28.15%: 0.601. Loss: 1.6722774505615234\n",
      "training 28.21%: 0.601. Loss: 1.5283303260803223\n",
      "training 28.28%: 0.601. Loss: 1.7702842950820923\n",
      "training 28.34%: 0.601. Loss: 1.3933156728744507\n",
      "training 28.41%: 0.601. Loss: 1.578940510749817\n",
      "training 28.47%: 0.601. Loss: 2.0619256496429443\n",
      "training 28.53%: 0.601. Loss: 1.331136703491211\n",
      "training 28.60%: 0.601. Loss: 0.964551568031311\n",
      "training 28.66%: 0.601. Loss: 1.5133613348007202\n",
      "training 28.73%: 0.601. Loss: 1.2814972400665283\n",
      "training 28.79%: 0.601. Loss: 1.8089179992675781\n",
      "training 28.85%: 0.601. Loss: 2.085772752761841\n",
      "training 28.92%: 0.601. Loss: 1.6063352823257446\n",
      "training 28.98%: 0.601. Loss: 1.6021956205368042\n",
      "training 29.05%: 0.601. Loss: 1.8921841382980347\n",
      "training 29.11%: 0.601. Loss: 1.4283933639526367\n",
      "training 29.17%: 0.601. Loss: 1.2640491724014282\n",
      "training 29.24%: 0.601. Loss: 1.5201823711395264\n",
      "training 29.30%: 0.602. Loss: 1.510774850845337\n",
      "training 29.37%: 0.601. Loss: 1.8829460144042969\n",
      "training 29.43%: 0.602. Loss: 1.2300399541854858\n",
      "training 29.49%: 0.602. Loss: 1.5719493627548218\n",
      "training 29.56%: 0.602. Loss: 1.631216287612915\n",
      "training 29.62%: 0.601. Loss: 1.6856719255447388\n",
      "training 29.69%: 0.602. Loss: 1.3711137771606445\n",
      "training 29.75%: 0.602. Loss: 1.7544593811035156\n",
      "training 29.81%: 0.602. Loss: 1.7781058549880981\n",
      "training 29.88%: 0.602. Loss: 1.5894652605056763\n",
      "training 29.94%: 0.602. Loss: 1.4001643657684326\n",
      "training 30.01%: 0.602. Loss: 1.5168324708938599\n",
      "training 30.07%: 0.602. Loss: 1.7926355600357056\n",
      "training 30.13%: 0.602. Loss: 1.7424901723861694\n",
      "training 30.20%: 0.602. Loss: 1.3729573488235474\n",
      "training 30.26%: 0.602. Loss: 1.1378893852233887\n",
      "training 30.33%: 0.602. Loss: 1.6656564474105835\n",
      "training 30.39%: 0.602. Loss: 1.2977715730667114\n",
      "training 30.45%: 0.602. Loss: 1.829740047454834\n",
      "training 30.52%: 0.602. Loss: 1.5317189693450928\n",
      "training 30.58%: 0.602. Loss: 1.5252599716186523\n",
      "training 30.65%: 0.602. Loss: 1.5448020696640015\n",
      "training 30.71%: 0.602. Loss: 1.6361571550369263\n",
      "training 30.77%: 0.602. Loss: 1.4487353563308716\n",
      "training 30.84%: 0.602. Loss: 2.173129081726074\n",
      "training 30.90%: 0.602. Loss: 1.6251400709152222\n",
      "training 30.97%: 0.602. Loss: 1.3655693531036377\n",
      "training 31.03%: 0.602. Loss: 1.440930724143982\n",
      "training 31.09%: 0.602. Loss: 1.946850299835205\n",
      "training 31.16%: 0.602. Loss: 1.3220443725585938\n",
      "training 31.22%: 0.602. Loss: 1.4821341037750244\n",
      "training 31.29%: 0.602. Loss: 1.3829647302627563\n",
      "training 31.35%: 0.603. Loss: 1.6905525922775269\n",
      "training 31.41%: 0.602. Loss: 2.054894208908081\n",
      "training 31.48%: 0.602. Loss: 1.469555139541626\n",
      "training 31.54%: 0.602. Loss: 1.7433226108551025\n",
      "training 31.61%: 0.602. Loss: 1.880802869796753\n",
      "training 31.67%: 0.602. Loss: 1.6431128978729248\n",
      "training 31.73%: 0.602. Loss: 1.4836997985839844\n",
      "training 31.80%: 0.602. Loss: 1.585656762123108\n",
      "training 31.86%: 0.602. Loss: 1.7841482162475586\n",
      "training 31.93%: 0.602. Loss: 1.810173511505127\n",
      "training 31.99%: 0.602. Loss: 1.417901873588562\n",
      "training 32.05%: 0.602. Loss: 1.4631600379943848\n",
      "training 32.12%: 0.602. Loss: 1.3374598026275635\n",
      "training 32.18%: 0.602. Loss: 1.674688696861267\n",
      "training 32.25%: 0.602. Loss: 1.8681102991104126\n",
      "training 32.31%: 0.602. Loss: 2.21860671043396\n",
      "training 32.37%: 0.602. Loss: 1.871798038482666\n",
      "training 32.44%: 0.602. Loss: 1.4702379703521729\n",
      "training 32.50%: 0.602. Loss: 1.538460612297058\n",
      "training 32.57%: 0.602. Loss: 1.6781219244003296\n",
      "training 32.63%: 0.602. Loss: 1.6805211305618286\n",
      "training 32.69%: 0.602. Loss: 1.5427159070968628\n",
      "training 32.76%: 0.602. Loss: 1.8101699352264404\n",
      "training 32.82%: 0.602. Loss: 1.498030424118042\n",
      "training 32.89%: 0.602. Loss: 1.658240795135498\n",
      "training 32.95%: 0.602. Loss: 1.4883015155792236\n",
      "training 33.01%: 0.602. Loss: 1.8470354080200195\n",
      "training 33.08%: 0.602. Loss: 2.1607203483581543\n",
      "training 33.14%: 0.602. Loss: 1.6636734008789062\n",
      "training 33.21%: 0.602. Loss: 1.5975914001464844\n",
      "training 33.27%: 0.602. Loss: 1.5243788957595825\n",
      "training 33.33%: 0.602. Loss: 1.7392991781234741\n",
      "training 33.40%: 0.602. Loss: 1.622922420501709\n",
      "training 33.46%: 0.602. Loss: 1.7948557138442993\n",
      "training 33.53%: 0.602. Loss: 1.8123321533203125\n",
      "training 33.59%: 0.602. Loss: 1.4919958114624023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 33.65%: 0.601. Loss: 1.5513825416564941\n",
      "training 33.72%: 0.602. Loss: 1.284928798675537\n",
      "training 33.78%: 0.602. Loss: 1.2048801183700562\n",
      "training 33.85%: 0.602. Loss: 1.507549524307251\n",
      "training 33.91%: 0.602. Loss: 1.3180512189865112\n",
      "training 33.97%: 0.602. Loss: 1.5844612121582031\n",
      "training 34.04%: 0.601. Loss: 2.0877223014831543\n",
      "training 34.10%: 0.601. Loss: 1.4832102060317993\n",
      "training 34.17%: 0.601. Loss: 2.1196954250335693\n",
      "training 34.23%: 0.601. Loss: 1.4126096963882446\n",
      "training 34.29%: 0.601. Loss: 1.1926212310791016\n",
      "training 34.36%: 0.601. Loss: 1.5969899892807007\n",
      "training 34.42%: 0.601. Loss: 1.1854034662246704\n",
      "training 34.48%: 0.601. Loss: 1.6318278312683105\n",
      "training 34.55%: 0.601. Loss: 1.5336244106292725\n",
      "training 34.61%: 0.601. Loss: 1.552513599395752\n",
      "training 34.68%: 0.601. Loss: 1.6392793655395508\n",
      "training 34.74%: 0.601. Loss: 1.5008981227874756\n",
      "training 34.80%: 0.602. Loss: 1.2504723072052002\n",
      "training 34.87%: 0.602. Loss: 1.599435806274414\n",
      "training 34.93%: 0.602. Loss: 1.352858304977417\n",
      "training 35.00%: 0.602. Loss: 1.7616466283798218\n",
      "training 35.06%: 0.602. Loss: 1.9930092096328735\n",
      "training 35.12%: 0.601. Loss: 2.1560587882995605\n",
      "training 35.19%: 0.602. Loss: 1.3225728273391724\n",
      "training 35.25%: 0.601. Loss: 1.789456844329834\n",
      "training 35.32%: 0.601. Loss: 1.663814663887024\n",
      "training 35.38%: 0.602. Loss: 1.3870949745178223\n",
      "training 35.44%: 0.602. Loss: 1.546130895614624\n",
      "training 35.51%: 0.602. Loss: 1.5823601484298706\n",
      "training 35.57%: 0.602. Loss: 1.4743643999099731\n",
      "training 35.64%: 0.602. Loss: 1.108075499534607\n",
      "training 35.70%: 0.602. Loss: 1.950212836265564\n",
      "training 35.76%: 0.601. Loss: 1.8453562259674072\n",
      "training 35.83%: 0.602. Loss: 1.3633594512939453\n",
      "training 35.89%: 0.602. Loss: 1.6685736179351807\n",
      "training 35.96%: 0.601. Loss: 1.7757093906402588\n",
      "training 36.02%: 0.601. Loss: 1.5784038305282593\n",
      "training 36.08%: 0.602. Loss: 1.542954921722412\n",
      "training 36.15%: 0.602. Loss: 1.6422631740570068\n",
      "training 36.21%: 0.601. Loss: 1.7373543977737427\n",
      "training 36.28%: 0.602. Loss: 1.1412748098373413\n",
      "training 36.34%: 0.602. Loss: 1.7518821954727173\n",
      "training 36.40%: 0.602. Loss: 2.181108236312866\n",
      "training 36.47%: 0.602. Loss: 1.0833897590637207\n",
      "training 36.53%: 0.602. Loss: 1.2373427152633667\n",
      "training 36.60%: 0.602. Loss: 1.5679823160171509\n",
      "training 36.66%: 0.602. Loss: 1.4418935775756836\n",
      "training 36.72%: 0.602. Loss: 1.652392864227295\n",
      "training 36.79%: 0.602. Loss: 1.5791000127792358\n",
      "training 36.85%: 0.602. Loss: 1.7683743238449097\n",
      "training 36.92%: 0.602. Loss: 1.5651053190231323\n",
      "training 36.98%: 0.602. Loss: 1.7276091575622559\n",
      "training 37.04%: 0.602. Loss: 1.7432596683502197\n",
      "training 37.11%: 0.602. Loss: 1.5357818603515625\n",
      "training 37.17%: 0.602. Loss: 1.1961058378219604\n",
      "training 37.24%: 0.602. Loss: 1.6631537675857544\n",
      "training 37.30%: 0.602. Loss: 2.101594924926758\n",
      "training 37.36%: 0.601. Loss: 1.6632499694824219\n",
      "training 37.43%: 0.601. Loss: 1.7954761981964111\n",
      "training 37.49%: 0.601. Loss: 1.4954615831375122\n",
      "training 37.56%: 0.601. Loss: 1.586129069328308\n",
      "training 37.62%: 0.601. Loss: 1.6705304384231567\n",
      "training 37.68%: 0.601. Loss: 1.2199925184249878\n",
      "training 37.75%: 0.601. Loss: 1.6816496849060059\n",
      "training 37.81%: 0.601. Loss: 1.7338109016418457\n",
      "training 37.88%: 0.601. Loss: 1.4559175968170166\n",
      "training 37.94%: 0.601. Loss: 1.7639471292495728\n",
      "training 38.00%: 0.601. Loss: 1.3980660438537598\n",
      "training 38.07%: 0.601. Loss: 1.9571375846862793\n",
      "training 38.13%: 0.601. Loss: 1.6554594039916992\n",
      "training 38.20%: 0.601. Loss: 1.71474027633667\n",
      "training 38.26%: 0.601. Loss: 1.2632949352264404\n",
      "training 38.32%: 0.601. Loss: 1.8758996725082397\n",
      "training 38.39%: 0.601. Loss: 1.795414686203003\n",
      "training 38.45%: 0.601. Loss: 1.5032765865325928\n",
      "training 38.52%: 0.601. Loss: 1.7685062885284424\n",
      "training 38.58%: 0.601. Loss: 1.547790288925171\n",
      "training 38.64%: 0.601. Loss: 1.8574278354644775\n",
      "training 38.71%: 0.601. Loss: 1.333667278289795\n",
      "training 38.77%: 0.601. Loss: 1.6288988590240479\n",
      "training 38.84%: 0.601. Loss: 1.412368893623352\n",
      "training 38.90%: 0.601. Loss: 1.515859603881836\n",
      "training 38.96%: 0.601. Loss: 1.3298438787460327\n",
      "training 39.03%: 0.601. Loss: 1.7078537940979004\n",
      "training 39.09%: 0.601. Loss: 1.510457992553711\n",
      "training 39.16%: 0.601. Loss: 1.3733184337615967\n",
      "training 39.22%: 0.601. Loss: 1.468105673789978\n",
      "training 39.28%: 0.601. Loss: 1.3514468669891357\n",
      "training 39.35%: 0.601. Loss: 1.7741323709487915\n",
      "training 39.41%: 0.601. Loss: 1.834428071975708\n",
      "training 39.48%: 0.601. Loss: 1.2358969449996948\n",
      "training 39.54%: 0.601. Loss: 1.503570318222046\n",
      "training 39.60%: 0.602. Loss: 1.354196548461914\n",
      "training 39.67%: 0.602. Loss: 1.5966520309448242\n",
      "training 39.73%: 0.601. Loss: 1.981390357017517\n",
      "training 39.80%: 0.601. Loss: 2.2316408157348633\n",
      "training 39.86%: 0.601. Loss: 1.6852471828460693\n",
      "training 39.92%: 0.601. Loss: 1.3704063892364502\n",
      "training 39.99%: 0.601. Loss: 1.253196358680725\n",
      "training 40.05%: 0.601. Loss: 1.602823257446289\n",
      "training 40.12%: 0.601. Loss: 1.488228440284729\n",
      "training 40.18%: 0.601. Loss: 1.984975814819336\n",
      "training 40.24%: 0.601. Loss: 1.4181734323501587\n",
      "training 40.31%: 0.601. Loss: 1.609235405921936\n",
      "training 40.37%: 0.601. Loss: 1.782785177230835\n",
      "training 40.44%: 0.601. Loss: 1.3938907384872437\n",
      "training 40.50%: 0.602. Loss: 1.3602960109710693\n",
      "training 40.56%: 0.602. Loss: 1.2229673862457275\n",
      "training 40.63%: 0.602. Loss: 1.7117247581481934\n",
      "training 40.69%: 0.602. Loss: 1.5356659889221191\n",
      "training 40.75%: 0.602. Loss: 1.7018195390701294\n",
      "training 40.82%: 0.602. Loss: 1.1828665733337402\n",
      "training 40.88%: 0.602. Loss: 1.6443426609039307\n",
      "training 40.95%: 0.602. Loss: 1.6699912548065186\n",
      "training 41.01%: 0.602. Loss: 2.099130630493164\n",
      "training 41.07%: 0.602. Loss: 1.4245185852050781\n",
      "training 41.14%: 0.602. Loss: 1.3863332271575928\n",
      "training 41.20%: 0.602. Loss: 1.3685365915298462\n",
      "training 41.27%: 0.602. Loss: 1.4350335597991943\n",
      "training 41.33%: 0.602. Loss: 1.6070212125778198\n",
      "training 41.39%: 0.602. Loss: 1.613770604133606\n",
      "training 41.46%: 0.601. Loss: 1.7497063875198364\n",
      "training 41.52%: 0.602. Loss: 1.2583258152008057\n",
      "training 41.59%: 0.602. Loss: 1.6128085851669312\n",
      "training 41.65%: 0.602. Loss: 1.622255802154541\n",
      "training 41.71%: 0.602. Loss: 1.2343717813491821\n",
      "training 41.78%: 0.602. Loss: 1.6034432649612427\n",
      "training 41.84%: 0.602. Loss: 1.52391517162323\n",
      "training 41.91%: 0.602. Loss: 1.844447374343872\n",
      "training 41.97%: 0.602. Loss: 1.8456182479858398\n",
      "training 42.03%: 0.602. Loss: 1.3523017168045044\n",
      "training 42.10%: 0.602. Loss: 1.5860704183578491\n",
      "training 42.16%: 0.602. Loss: 1.8000140190124512\n",
      "training 42.23%: 0.602. Loss: 1.2480918169021606\n",
      "training 42.29%: 0.602. Loss: 1.8687877655029297\n",
      "training 42.35%: 0.602. Loss: 1.4787713289260864\n",
      "training 42.42%: 0.602. Loss: 1.9015812873840332\n",
      "training 42.48%: 0.602. Loss: 1.6209250688552856\n",
      "training 42.55%: 0.602. Loss: 1.7717690467834473\n",
      "training 42.61%: 0.602. Loss: 1.7077676057815552\n",
      "training 42.67%: 0.602. Loss: 1.4930272102355957\n",
      "training 42.74%: 0.602. Loss: 1.2351278066635132\n",
      "training 42.80%: 0.602. Loss: 1.6115143299102783\n",
      "training 42.87%: 0.602. Loss: 1.3064223527908325\n",
      "training 42.93%: 0.602. Loss: 1.8427245616912842\n",
      "training 42.99%: 0.602. Loss: 1.737156629562378\n",
      "training 43.06%: 0.602. Loss: 1.844387173652649\n",
      "training 43.12%: 0.602. Loss: 1.6665902137756348\n",
      "training 43.19%: 0.601. Loss: 1.8221443891525269\n",
      "training 43.25%: 0.602. Loss: 1.2354530096054077\n",
      "training 43.31%: 0.602. Loss: 1.565751552581787\n",
      "training 43.38%: 0.601. Loss: 1.8255864381790161\n",
      "training 43.44%: 0.601. Loss: 1.9948292970657349\n",
      "training 43.51%: 0.601. Loss: 1.4962916374206543\n",
      "training 43.57%: 0.601. Loss: 1.9852839708328247\n",
      "training 43.63%: 0.601. Loss: 1.843625783920288\n",
      "training 43.70%: 0.601. Loss: 1.4795918464660645\n",
      "training 43.76%: 0.601. Loss: 1.7708930969238281\n",
      "training 43.83%: 0.601. Loss: 1.8294167518615723\n",
      "training 43.89%: 0.601. Loss: 1.5911846160888672\n",
      "training 43.95%: 0.601. Loss: 1.7215968370437622\n",
      "training 44.02%: 0.601. Loss: 1.597977638244629\n",
      "training 44.08%: 0.601. Loss: 1.8619049787521362\n",
      "training 44.15%: 0.601. Loss: 1.2834200859069824\n",
      "training 44.21%: 0.601. Loss: 1.4404488801956177\n",
      "training 44.27%: 0.601. Loss: 1.4805598258972168\n",
      "training 44.34%: 0.601. Loss: 1.3619558811187744\n",
      "training 44.40%: 0.601. Loss: 1.935416340827942\n",
      "training 44.47%: 0.601. Loss: 1.8708081245422363\n",
      "training 44.53%: 0.600. Loss: 1.7560940980911255\n",
      "training 44.59%: 0.601. Loss: 1.3131502866744995\n",
      "training 44.66%: 0.601. Loss: 1.6642136573791504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 44.72%: 0.601. Loss: 1.3952574729919434\n",
      "training 44.79%: 0.601. Loss: 1.5989714860916138\n",
      "training 44.85%: 0.601. Loss: 1.711435079574585\n",
      "training 44.91%: 0.600. Loss: 1.6608058214187622\n",
      "training 44.98%: 0.600. Loss: 1.6783863306045532\n",
      "training 45.04%: 0.600. Loss: 1.4329487085342407\n",
      "training 45.11%: 0.600. Loss: 1.5952218770980835\n",
      "training 45.17%: 0.600. Loss: 1.7251720428466797\n",
      "training 45.23%: 0.600. Loss: 1.4130712747573853\n",
      "training 45.30%: 0.600. Loss: 1.6934430599212646\n",
      "training 45.36%: 0.600. Loss: 0.9784759283065796\n",
      "training 45.43%: 0.600. Loss: 1.7420824766159058\n",
      "training 45.49%: 0.600. Loss: 1.7362602949142456\n",
      "training 45.55%: 0.600. Loss: 1.9391930103302002\n",
      "training 45.62%: 0.600. Loss: 1.6228569746017456\n",
      "training 45.68%: 0.600. Loss: 1.9827855825424194\n",
      "training 45.75%: 0.600. Loss: 1.7304737567901611\n",
      "training 45.81%: 0.600. Loss: 1.3445231914520264\n",
      "training 45.87%: 0.600. Loss: 1.5914020538330078\n",
      "training 45.94%: 0.600. Loss: 1.7499735355377197\n",
      "training 46.00%: 0.600. Loss: 1.8853110074996948\n",
      "training 46.07%: 0.600. Loss: 1.9898539781570435\n",
      "training 46.13%: 0.600. Loss: 1.4682667255401611\n",
      "training 46.19%: 0.600. Loss: 1.8457330465316772\n",
      "training 46.26%: 0.600. Loss: 1.751726508140564\n",
      "training 46.32%: 0.600. Loss: 1.4108219146728516\n",
      "training 46.39%: 0.600. Loss: 1.3467779159545898\n",
      "training 46.45%: 0.600. Loss: 1.5262188911437988\n",
      "training 46.51%: 0.599. Loss: 1.571598768234253\n",
      "training 46.58%: 0.600. Loss: 1.5523698329925537\n",
      "training 46.64%: 0.600. Loss: 1.6099052429199219\n",
      "training 46.71%: 0.599. Loss: 1.6702171564102173\n",
      "training 46.77%: 0.599. Loss: 1.892439842224121\n",
      "training 46.83%: 0.599. Loss: 1.9648929834365845\n",
      "training 46.90%: 0.599. Loss: 1.6528011560440063\n",
      "training 46.96%: 0.599. Loss: 1.851822018623352\n",
      "training 47.02%: 0.599. Loss: 1.675502061843872\n",
      "training 47.09%: 0.599. Loss: 1.8035461902618408\n",
      "training 47.15%: 0.599. Loss: 1.7451350688934326\n",
      "training 47.22%: 0.599. Loss: 1.5570762157440186\n",
      "training 47.28%: 0.599. Loss: 1.7051172256469727\n",
      "training 47.34%: 0.599. Loss: 1.5222601890563965\n",
      "training 47.41%: 0.599. Loss: 1.894640326499939\n",
      "training 47.47%: 0.599. Loss: 1.4580107927322388\n",
      "training 47.54%: 0.599. Loss: 1.833102822303772\n",
      "training 47.60%: 0.599. Loss: 1.6670022010803223\n",
      "training 47.66%: 0.599. Loss: 1.4172122478485107\n",
      "training 47.73%: 0.599. Loss: 1.9387054443359375\n",
      "training 47.79%: 0.599. Loss: 1.4301034212112427\n",
      "training 47.86%: 0.599. Loss: 1.408444881439209\n",
      "training 47.92%: 0.599. Loss: 1.7056503295898438\n",
      "training 47.98%: 0.599. Loss: 1.2911946773529053\n",
      "training 48.05%: 0.599. Loss: 1.7253202199935913\n",
      "training 48.11%: 0.599. Loss: 1.6864229440689087\n",
      "training 48.18%: 0.599. Loss: 1.5067310333251953\n",
      "training 48.24%: 0.599. Loss: 1.756392478942871\n",
      "training 48.30%: 0.599. Loss: 1.7353429794311523\n",
      "training 48.37%: 0.599. Loss: 1.7543604373931885\n",
      "training 48.43%: 0.599. Loss: 1.6204081773757935\n",
      "training 48.50%: 0.599. Loss: 1.5843212604522705\n",
      "training 48.56%: 0.599. Loss: 1.7837886810302734\n",
      "training 48.62%: 0.599. Loss: 2.0626041889190674\n",
      "training 48.69%: 0.599. Loss: 1.5699177980422974\n",
      "training 48.75%: 0.599. Loss: 1.4724175930023193\n",
      "training 48.82%: 0.598. Loss: 1.7929753065109253\n",
      "training 48.88%: 0.599. Loss: 1.4122962951660156\n",
      "training 48.94%: 0.599. Loss: 1.5113294124603271\n",
      "training 49.01%: 0.598. Loss: 2.007159948348999\n",
      "training 49.07%: 0.599. Loss: 1.4509721994400024\n",
      "training 49.14%: 0.599. Loss: 1.3344252109527588\n",
      "training 49.20%: 0.599. Loss: 1.62615168094635\n",
      "training 49.26%: 0.599. Loss: 1.4858002662658691\n",
      "training 49.33%: 0.599. Loss: 1.0790380239486694\n",
      "training 49.39%: 0.599. Loss: 1.568897008895874\n",
      "training 49.46%: 0.599. Loss: 1.318932294845581\n",
      "training 49.52%: 0.599. Loss: 1.9912126064300537\n",
      "training 49.58%: 0.599. Loss: 1.6665345430374146\n",
      "training 49.65%: 0.599. Loss: 1.6482932567596436\n",
      "training 49.71%: 0.599. Loss: 1.5548490285873413\n",
      "training 49.78%: 0.599. Loss: 1.6340360641479492\n",
      "training 49.84%: 0.599. Loss: 1.7423086166381836\n",
      "training 49.90%: 0.599. Loss: 1.7487084865570068\n",
      "training 49.97%: 0.599. Loss: 1.3974509239196777\n",
      "training 50.03%: 0.599. Loss: 1.6272872686386108\n",
      "training 50.10%: 0.599. Loss: 1.0675832033157349\n",
      "training 50.16%: 0.599. Loss: 1.2640005350112915\n",
      "training 50.22%: 0.599. Loss: 1.697499394416809\n",
      "training 50.29%: 0.599. Loss: 1.7314811944961548\n",
      "training 50.35%: 0.599. Loss: 2.05128812789917\n",
      "training 50.42%: 0.599. Loss: 2.0087153911590576\n",
      "training 50.48%: 0.599. Loss: 1.965097427368164\n",
      "training 50.54%: 0.599. Loss: 1.843802571296692\n",
      "training 50.61%: 0.599. Loss: 1.7187390327453613\n",
      "training 50.67%: 0.599. Loss: 1.9308782815933228\n",
      "training 50.74%: 0.599. Loss: 1.8823959827423096\n",
      "training 50.80%: 0.599. Loss: 1.727550745010376\n",
      "training 50.86%: 0.599. Loss: 1.605400800704956\n",
      "training 50.93%: 0.599. Loss: 1.4269920587539673\n",
      "training 50.99%: 0.599. Loss: 1.6180262565612793\n",
      "training 51.06%: 0.599. Loss: 1.2913581132888794\n",
      "training 51.12%: 0.599. Loss: 1.6772253513336182\n",
      "training 51.18%: 0.599. Loss: 1.796478509902954\n",
      "training 51.25%: 0.599. Loss: 1.6605807542800903\n",
      "training 51.31%: 0.599. Loss: 1.1601568460464478\n",
      "training 51.38%: 0.599. Loss: 1.2555350065231323\n",
      "training 51.44%: 0.599. Loss: 1.7217029333114624\n",
      "training 51.50%: 0.599. Loss: 1.6540324687957764\n",
      "training 51.57%: 0.599. Loss: 1.729087471961975\n",
      "training 51.63%: 0.599. Loss: 1.7181644439697266\n",
      "training 51.70%: 0.599. Loss: 1.454227089881897\n",
      "training 51.76%: 0.599. Loss: 1.672966480255127\n",
      "training 51.82%: 0.599. Loss: 1.952440619468689\n",
      "training 51.89%: 0.598. Loss: 2.082474946975708\n",
      "training 51.95%: 0.598. Loss: 1.5850036144256592\n",
      "training 52.02%: 0.598. Loss: 1.8388947248458862\n",
      "training 52.08%: 0.598. Loss: 2.016312837600708\n",
      "training 52.14%: 0.598. Loss: 1.2248823642730713\n",
      "training 52.21%: 0.598. Loss: 1.5745470523834229\n",
      "training 52.27%: 0.598. Loss: 1.851457118988037\n",
      "training 52.34%: 0.598. Loss: 1.184624433517456\n",
      "training 52.40%: 0.598. Loss: 2.3901517391204834\n",
      "training 52.46%: 0.598. Loss: 1.7251083850860596\n",
      "training 52.53%: 0.598. Loss: 2.1097381114959717\n",
      "training 52.59%: 0.598. Loss: 1.5302269458770752\n",
      "training 52.66%: 0.598. Loss: 1.5879833698272705\n",
      "training 52.72%: 0.598. Loss: 2.0839741230010986\n",
      "training 52.78%: 0.598. Loss: 1.4995365142822266\n",
      "training 52.85%: 0.598. Loss: 1.72377347946167\n",
      "training 52.91%: 0.598. Loss: 1.6636203527450562\n",
      "training 52.98%: 0.598. Loss: 1.6007094383239746\n",
      "training 53.04%: 0.598. Loss: 1.4718831777572632\n",
      "training 53.10%: 0.598. Loss: 1.1222150325775146\n",
      "training 53.17%: 0.598. Loss: 1.33915114402771\n",
      "training 53.23%: 0.598. Loss: 1.7508544921875\n",
      "training 53.29%: 0.598. Loss: 1.44571852684021\n",
      "training 53.36%: 0.598. Loss: 1.532253384590149\n",
      "training 53.42%: 0.598. Loss: 1.419238567352295\n",
      "training 53.49%: 0.598. Loss: 1.2888810634613037\n",
      "training 53.55%: 0.598. Loss: 2.3960697650909424\n",
      "training 53.61%: 0.598. Loss: 1.8181829452514648\n",
      "training 53.68%: 0.598. Loss: 1.9222034215927124\n",
      "training 53.74%: 0.598. Loss: 1.3596248626708984\n",
      "training 53.81%: 0.598. Loss: 1.2002490758895874\n",
      "training 53.87%: 0.598. Loss: 1.563535213470459\n",
      "training 53.93%: 0.598. Loss: 1.5442746877670288\n",
      "training 54.00%: 0.598. Loss: 1.5599467754364014\n",
      "training 54.06%: 0.598. Loss: 2.113204002380371\n",
      "training 54.13%: 0.598. Loss: 1.8964518308639526\n",
      "training 54.19%: 0.598. Loss: 1.5482022762298584\n",
      "training 54.25%: 0.598. Loss: 1.4864017963409424\n",
      "training 54.32%: 0.598. Loss: 1.6543294191360474\n",
      "training 54.38%: 0.598. Loss: 1.8683019876480103\n",
      "training 54.45%: 0.598. Loss: 1.7337007522583008\n",
      "training 54.51%: 0.598. Loss: 1.6516162157058716\n",
      "training 54.57%: 0.598. Loss: 1.3161779642105103\n",
      "training 54.64%: 0.598. Loss: 1.6443355083465576\n",
      "training 54.70%: 0.598. Loss: 1.5449234247207642\n",
      "training 54.77%: 0.598. Loss: 1.926113247871399\n",
      "training 54.83%: 0.598. Loss: 1.4748079776763916\n",
      "training 54.89%: 0.598. Loss: 1.513236403465271\n",
      "training 54.96%: 0.598. Loss: 1.148032546043396\n",
      "training 55.02%: 0.598. Loss: 1.7492296695709229\n",
      "training 55.09%: 0.598. Loss: 1.9268455505371094\n",
      "training 55.15%: 0.598. Loss: 1.4389840364456177\n",
      "training 55.21%: 0.598. Loss: 1.6051743030548096\n",
      "training 55.28%: 0.598. Loss: 1.5497205257415771\n",
      "training 55.34%: 0.598. Loss: 1.7249091863632202\n",
      "training 55.41%: 0.598. Loss: 1.6686389446258545\n",
      "training 55.47%: 0.598. Loss: 1.5036996603012085\n",
      "training 55.53%: 0.598. Loss: 1.6236590147018433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 55.60%: 0.598. Loss: 1.5264153480529785\n",
      "training 55.66%: 0.598. Loss: 1.9602913856506348\n",
      "training 55.73%: 0.598. Loss: 1.630444884300232\n",
      "training 55.79%: 0.598. Loss: 1.5729129314422607\n",
      "training 55.85%: 0.598. Loss: 1.4532932043075562\n",
      "training 55.92%: 0.598. Loss: 1.8879461288452148\n",
      "training 55.98%: 0.598. Loss: 1.5680891275405884\n",
      "training 56.05%: 0.598. Loss: 1.7590322494506836\n",
      "training 56.11%: 0.598. Loss: 1.3564587831497192\n",
      "training 56.17%: 0.598. Loss: 1.741101861000061\n",
      "training 56.24%: 0.598. Loss: 1.9013861417770386\n",
      "training 56.30%: 0.598. Loss: 1.4204940795898438\n",
      "training 56.37%: 0.598. Loss: 1.683670997619629\n",
      "training 56.43%: 0.598. Loss: 1.6838537454605103\n",
      "training 56.49%: 0.597. Loss: 2.1430962085723877\n",
      "training 56.56%: 0.598. Loss: 1.3368802070617676\n",
      "training 56.62%: 0.597. Loss: 1.8428248167037964\n",
      "training 56.69%: 0.598. Loss: 1.6353946924209595\n",
      "training 56.75%: 0.598. Loss: 1.44841730594635\n",
      "training 56.81%: 0.598. Loss: 1.4595987796783447\n",
      "training 56.88%: 0.598. Loss: 1.5993413925170898\n",
      "training 56.94%: 0.598. Loss: 1.6150513887405396\n",
      "training 57.01%: 0.598. Loss: 1.5255504846572876\n",
      "training 57.07%: 0.598. Loss: 1.4352842569351196\n",
      "training 57.13%: 0.598. Loss: 1.5118920803070068\n",
      "training 57.20%: 0.598. Loss: 1.4519635438919067\n",
      "training 57.26%: 0.598. Loss: 1.3563642501831055\n",
      "training 57.33%: 0.598. Loss: 1.8618271350860596\n",
      "training 57.39%: 0.598. Loss: 2.09523606300354\n",
      "training 57.45%: 0.598. Loss: 1.217202067375183\n",
      "training 57.52%: 0.598. Loss: 1.2952712774276733\n",
      "training 57.58%: 0.598. Loss: 1.7542870044708252\n",
      "training 57.65%: 0.598. Loss: 1.6075291633605957\n",
      "training 57.71%: 0.598. Loss: 1.6059579849243164\n",
      "training 57.77%: 0.598. Loss: 1.6939117908477783\n",
      "training 57.84%: 0.598. Loss: 1.767166256904602\n",
      "training 57.90%: 0.598. Loss: 1.6750997304916382\n",
      "training 57.97%: 0.598. Loss: 1.4743067026138306\n",
      "training 58.03%: 0.598. Loss: 1.373296856880188\n",
      "training 58.09%: 0.598. Loss: 1.8422094583511353\n",
      "training 58.16%: 0.598. Loss: 1.2650195360183716\n",
      "training 58.22%: 0.598. Loss: 2.107863664627075\n",
      "training 58.29%: 0.598. Loss: 1.3379979133605957\n",
      "training 58.35%: 0.598. Loss: 1.999033808708191\n",
      "training 58.41%: 0.598. Loss: 1.6829674243927002\n",
      "training 58.48%: 0.598. Loss: 1.3503087759017944\n",
      "training 58.54%: 0.598. Loss: 1.9354255199432373\n",
      "training 58.61%: 0.598. Loss: 1.4663166999816895\n",
      "training 58.67%: 0.598. Loss: 1.5598562955856323\n",
      "training 58.73%: 0.598. Loss: 1.8296759128570557\n",
      "training 58.80%: 0.598. Loss: 1.4834463596343994\n",
      "training 58.86%: 0.597. Loss: 1.7576251029968262\n",
      "training 58.93%: 0.597. Loss: 1.7319732904434204\n",
      "training 58.99%: 0.597. Loss: 1.93263578414917\n",
      "training 59.05%: 0.597. Loss: 1.4450743198394775\n",
      "training 59.12%: 0.597. Loss: 1.6196409463882446\n",
      "training 59.18%: 0.597. Loss: 1.3431520462036133\n",
      "training 59.25%: 0.597. Loss: 1.560864806175232\n",
      "training 59.31%: 0.597. Loss: 1.863618016242981\n",
      "training 59.37%: 0.597. Loss: 1.6653789281845093\n",
      "training 59.44%: 0.597. Loss: 1.6719506978988647\n",
      "training 59.50%: 0.597. Loss: 1.8291229009628296\n",
      "training 59.56%: 0.597. Loss: 1.489924430847168\n",
      "training 59.63%: 0.597. Loss: 1.575907588005066\n",
      "training 59.69%: 0.597. Loss: 1.4101459980010986\n",
      "training 59.76%: 0.597. Loss: 1.4448163509368896\n",
      "training 59.82%: 0.597. Loss: 1.5943020582199097\n",
      "training 59.88%: 0.597. Loss: 1.724715232849121\n",
      "training 59.95%: 0.597. Loss: 1.2812840938568115\n",
      "training 60.01%: 0.597. Loss: 1.096555233001709\n",
      "training 60.08%: 0.597. Loss: 1.4571855068206787\n",
      "training 60.14%: 0.597. Loss: 1.6640980243682861\n",
      "training 60.20%: 0.597. Loss: 1.6100105047225952\n",
      "training 60.27%: 0.597. Loss: 1.576943278312683\n",
      "training 60.33%: 0.597. Loss: 1.9515622854232788\n",
      "training 60.40%: 0.597. Loss: 1.5718625783920288\n",
      "training 60.46%: 0.597. Loss: 1.5468811988830566\n",
      "training 60.52%: 0.597. Loss: 1.6582545042037964\n",
      "training 60.59%: 0.597. Loss: 1.5026687383651733\n",
      "training 60.65%: 0.597. Loss: 1.4626266956329346\n",
      "training 60.72%: 0.597. Loss: 1.533619999885559\n",
      "training 60.78%: 0.597. Loss: 1.5812067985534668\n",
      "training 60.84%: 0.597. Loss: 1.634698748588562\n",
      "training 60.91%: 0.597. Loss: 1.6012494564056396\n",
      "training 60.97%: 0.597. Loss: 1.561550259590149\n",
      "training 61.04%: 0.597. Loss: 1.2664448022842407\n",
      "training 61.10%: 0.597. Loss: 1.7018355131149292\n",
      "training 61.16%: 0.597. Loss: 1.7025303840637207\n",
      "training 61.23%: 0.598. Loss: 1.3704382181167603\n",
      "training 61.29%: 0.598. Loss: 1.4349392652511597\n",
      "training 61.36%: 0.598. Loss: 1.4732366800308228\n",
      "training 61.42%: 0.598. Loss: 1.5641355514526367\n",
      "training 61.48%: 0.598. Loss: 1.4850537776947021\n",
      "training 61.55%: 0.598. Loss: 1.8758141994476318\n",
      "training 61.61%: 0.598. Loss: 1.844007134437561\n",
      "training 61.68%: 0.598. Loss: 1.3680120706558228\n",
      "training 61.74%: 0.597. Loss: 2.067641496658325\n",
      "training 61.80%: 0.598. Loss: 1.31818687915802\n",
      "training 61.87%: 0.598. Loss: 1.6129094362258911\n",
      "training 61.93%: 0.598. Loss: 1.5057706832885742\n",
      "training 62.00%: 0.597. Loss: 1.5269259214401245\n",
      "training 62.06%: 0.597. Loss: 1.7562977075576782\n",
      "training 62.12%: 0.597. Loss: 1.7122398614883423\n",
      "training 62.19%: 0.597. Loss: 1.4571441411972046\n",
      "training 62.25%: 0.597. Loss: 1.8523492813110352\n",
      "training 62.32%: 0.597. Loss: 1.5847357511520386\n",
      "training 62.38%: 0.597. Loss: 1.4199751615524292\n",
      "training 62.44%: 0.597. Loss: 1.3322383165359497\n",
      "training 62.51%: 0.597. Loss: 1.6046156883239746\n",
      "training 62.57%: 0.598. Loss: 1.5196863412857056\n",
      "training 62.64%: 0.598. Loss: 1.5489356517791748\n",
      "training 62.70%: 0.598. Loss: 1.5587314367294312\n",
      "training 62.76%: 0.597. Loss: 1.7532203197479248\n",
      "training 62.83%: 0.597. Loss: 1.9149690866470337\n",
      "training 62.89%: 0.597. Loss: 1.6349173784255981\n",
      "training 62.96%: 0.597. Loss: 1.8583626747131348\n",
      "training 63.02%: 0.597. Loss: 1.8719402551651\n",
      "training 63.08%: 0.597. Loss: 1.6084562540054321\n",
      "training 63.15%: 0.597. Loss: 1.3381553888320923\n",
      "training 63.21%: 0.598. Loss: 1.197112798690796\n",
      "training 63.28%: 0.598. Loss: 1.8318957090377808\n",
      "training 63.34%: 0.598. Loss: 1.7927556037902832\n",
      "training 63.40%: 0.598. Loss: 1.4813183546066284\n",
      "training 63.47%: 0.597. Loss: 1.9203447103500366\n",
      "training 63.53%: 0.598. Loss: 1.6814688444137573\n",
      "training 63.60%: 0.598. Loss: 1.7327898740768433\n",
      "training 63.66%: 0.598. Loss: 1.6293355226516724\n",
      "training 63.72%: 0.598. Loss: 1.656337022781372\n",
      "training 63.79%: 0.597. Loss: 2.5402443408966064\n",
      "training 63.85%: 0.597. Loss: 1.5536226034164429\n",
      "training 63.92%: 0.597. Loss: 1.5276174545288086\n",
      "training 63.98%: 0.597. Loss: 1.5689560174942017\n",
      "training 64.04%: 0.597. Loss: 1.7873339653015137\n",
      "training 64.11%: 0.597. Loss: 1.3279917240142822\n",
      "training 64.17%: 0.597. Loss: 2.1275010108947754\n",
      "training 64.24%: 0.597. Loss: 1.776857852935791\n",
      "training 64.30%: 0.597. Loss: 1.9799973964691162\n",
      "training 64.36%: 0.597. Loss: 1.6358267068862915\n",
      "training 64.43%: 0.597. Loss: 1.409073829650879\n",
      "training 64.49%: 0.597. Loss: 1.5105786323547363\n",
      "training 64.56%: 0.597. Loss: 1.822452187538147\n",
      "training 64.62%: 0.597. Loss: 1.8812990188598633\n",
      "training 64.68%: 0.597. Loss: 1.345139980316162\n",
      "training 64.75%: 0.597. Loss: 1.8818066120147705\n",
      "training 64.81%: 0.597. Loss: 1.7103571891784668\n",
      "training 64.88%: 0.597. Loss: 2.2256205081939697\n",
      "training 64.94%: 0.597. Loss: 1.5465282201766968\n",
      "training 65.00%: 0.597. Loss: 1.3403462171554565\n",
      "training 65.07%: 0.597. Loss: 1.7553462982177734\n",
      "training 65.13%: 0.597. Loss: 1.8358083963394165\n",
      "training 65.20%: 0.597. Loss: 1.6201809644699097\n",
      "training 65.26%: 0.597. Loss: 1.5134663581848145\n",
      "training 65.32%: 0.597. Loss: 1.7064679861068726\n",
      "training 65.39%: 0.597. Loss: 1.6396845579147339\n",
      "training 65.45%: 0.597. Loss: 1.657336950302124\n",
      "training 65.52%: 0.597. Loss: 1.381024956703186\n",
      "training 65.58%: 0.597. Loss: 1.4631757736206055\n",
      "training 65.64%: 0.597. Loss: 1.4450690746307373\n",
      "training 65.71%: 0.597. Loss: 1.7602484226226807\n",
      "training 65.77%: 0.597. Loss: 1.066698670387268\n",
      "training 65.83%: 0.597. Loss: 1.8996803760528564\n",
      "training 65.90%: 0.597. Loss: 1.9724253416061401\n",
      "training 65.96%: 0.597. Loss: 2.319023370742798\n",
      "training 66.03%: 0.597. Loss: 1.6326637268066406\n",
      "training 66.09%: 0.597. Loss: 1.5431768894195557\n",
      "training 66.15%: 0.597. Loss: 1.280969500541687\n",
      "training 66.22%: 0.597. Loss: 1.6506516933441162\n",
      "training 66.28%: 0.597. Loss: 1.9550673961639404\n",
      "training 66.35%: 0.597. Loss: 1.6469568014144897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 66.41%: 0.597. Loss: 1.5568182468414307\n",
      "training 66.47%: 0.597. Loss: 2.046268939971924\n",
      "training 66.54%: 0.597. Loss: 1.4941856861114502\n",
      "training 66.60%: 0.597. Loss: 1.6799191236495972\n",
      "training 66.67%: 0.597. Loss: 1.9993014335632324\n",
      "training 66.73%: 0.597. Loss: 1.7129868268966675\n",
      "training 66.79%: 0.597. Loss: 1.26241135597229\n",
      "training 66.86%: 0.597. Loss: 1.6791633367538452\n",
      "training 66.92%: 0.597. Loss: 1.844152569770813\n",
      "training 66.99%: 0.597. Loss: 1.8680036067962646\n",
      "training 67.05%: 0.596. Loss: 2.1011881828308105\n",
      "training 67.11%: 0.597. Loss: 1.4068353176116943\n",
      "training 67.18%: 0.597. Loss: 1.669830083847046\n",
      "training 67.24%: 0.597. Loss: 1.7787790298461914\n",
      "training 67.31%: 0.596. Loss: 1.6597435474395752\n",
      "training 67.37%: 0.596. Loss: 2.0321168899536133\n",
      "training 67.43%: 0.596. Loss: 1.4078819751739502\n",
      "training 67.50%: 0.596. Loss: 2.202085256576538\n",
      "training 67.56%: 0.596. Loss: 1.6724127531051636\n",
      "training 67.63%: 0.596. Loss: 1.3558738231658936\n",
      "training 67.69%: 0.596. Loss: 1.4641395807266235\n",
      "training 67.75%: 0.596. Loss: 1.839898705482483\n",
      "training 67.82%: 0.596. Loss: 1.2981058359146118\n",
      "training 67.88%: 0.597. Loss: 1.2588937282562256\n",
      "training 67.95%: 0.597. Loss: 1.6201777458190918\n",
      "training 68.01%: 0.597. Loss: 1.6807323694229126\n",
      "training 68.07%: 0.597. Loss: 1.6853991746902466\n",
      "training 68.14%: 0.596. Loss: 1.5750433206558228\n",
      "training 68.20%: 0.597. Loss: 1.1854770183563232\n",
      "training 68.27%: 0.597. Loss: 1.9426212310791016\n",
      "training 68.33%: 0.597. Loss: 1.5519920587539673\n",
      "training 68.39%: 0.597. Loss: 1.5040004253387451\n",
      "training 68.46%: 0.597. Loss: 1.4861953258514404\n",
      "training 68.52%: 0.597. Loss: 1.8734544515609741\n",
      "training 68.59%: 0.597. Loss: 1.77994704246521\n",
      "training 68.65%: 0.596. Loss: 1.9256640672683716\n",
      "training 68.71%: 0.596. Loss: 1.7026371955871582\n",
      "training 68.78%: 0.596. Loss: 1.5331498384475708\n",
      "training 68.84%: 0.596. Loss: 2.0406205654144287\n",
      "training 68.91%: 0.596. Loss: 1.5242764949798584\n",
      "training 68.97%: 0.596. Loss: 1.4491775035858154\n",
      "training 69.03%: 0.596. Loss: 1.360916018486023\n",
      "training 69.10%: 0.596. Loss: 1.6489096879959106\n",
      "training 69.16%: 0.596. Loss: 1.4098365306854248\n",
      "training 69.23%: 0.596. Loss: 1.9319641590118408\n",
      "training 69.29%: 0.596. Loss: 2.108009099960327\n",
      "training 69.35%: 0.596. Loss: 1.802119255065918\n",
      "training 69.42%: 0.596. Loss: 1.2587761878967285\n",
      "training 69.48%: 0.596. Loss: 1.7386579513549805\n",
      "training 69.55%: 0.596. Loss: 1.4958394765853882\n",
      "training 69.61%: 0.596. Loss: 1.3091611862182617\n",
      "training 69.67%: 0.596. Loss: 1.760190725326538\n",
      "training 69.74%: 0.596. Loss: 1.9727070331573486\n",
      "training 69.80%: 0.596. Loss: 1.8566645383834839\n",
      "training 69.87%: 0.596. Loss: 1.9927793741226196\n",
      "training 69.93%: 0.596. Loss: 1.6329902410507202\n",
      "training 69.99%: 0.596. Loss: 1.4497135877609253\n",
      "training 70.06%: 0.596. Loss: 1.3336747884750366\n",
      "training 70.12%: 0.596. Loss: 1.8239786624908447\n",
      "training 70.19%: 0.596. Loss: 1.4599926471710205\n",
      "training 70.25%: 0.596. Loss: 1.6687896251678467\n",
      "training 70.31%: 0.596. Loss: 1.7004544734954834\n",
      "training 70.38%: 0.596. Loss: 1.3925906419754028\n",
      "training 70.44%: 0.596. Loss: 1.658031940460205\n",
      "training 70.51%: 0.596. Loss: 1.5842584371566772\n",
      "training 70.57%: 0.596. Loss: 1.7821595668792725\n",
      "training 70.63%: 0.596. Loss: 1.3159770965576172\n",
      "training 70.70%: 0.596. Loss: 1.9170396327972412\n",
      "training 70.76%: 0.596. Loss: 1.5555661916732788\n",
      "training 70.83%: 0.596. Loss: 1.7573504447937012\n",
      "training 70.89%: 0.596. Loss: 1.6157410144805908\n",
      "training 70.95%: 0.596. Loss: 1.6704225540161133\n",
      "training 71.02%: 0.596. Loss: 1.7190227508544922\n",
      "training 71.08%: 0.596. Loss: 1.8103573322296143\n",
      "training 71.15%: 0.596. Loss: 1.7142280340194702\n",
      "training 71.21%: 0.596. Loss: 1.7388975620269775\n",
      "training 71.27%: 0.596. Loss: 1.6476430892944336\n",
      "training 71.34%: 0.596. Loss: 1.94010329246521\n",
      "training 71.40%: 0.596. Loss: 1.5231821537017822\n",
      "training 71.47%: 0.596. Loss: 2.323198080062866\n",
      "training 71.53%: 0.596. Loss: 1.9044629335403442\n",
      "training 71.59%: 0.596. Loss: 2.1612064838409424\n",
      "training 71.66%: 0.596. Loss: 1.5095453262329102\n",
      "training 71.72%: 0.596. Loss: 1.9472607374191284\n",
      "training 71.79%: 0.596. Loss: 1.5288933515548706\n",
      "training 71.85%: 0.596. Loss: 1.4846370220184326\n",
      "training 71.91%: 0.596. Loss: 1.5942559242248535\n",
      "training 71.98%: 0.596. Loss: 1.9600138664245605\n",
      "training 72.04%: 0.595. Loss: 1.7571659088134766\n",
      "training 72.10%: 0.595. Loss: 1.7177680730819702\n",
      "training 72.17%: 0.596. Loss: 1.3864266872406006\n",
      "training 72.23%: 0.596. Loss: 1.4072775840759277\n",
      "training 72.30%: 0.596. Loss: 1.434951663017273\n",
      "training 72.36%: 0.596. Loss: 1.3089168071746826\n",
      "training 72.42%: 0.596. Loss: 1.453656554222107\n",
      "training 72.49%: 0.595. Loss: 1.7531139850616455\n",
      "training 72.55%: 0.596. Loss: 1.1652528047561646\n",
      "training 72.62%: 0.596. Loss: 1.4127289056777954\n",
      "training 72.68%: 0.596. Loss: 1.4690982103347778\n",
      "training 72.74%: 0.596. Loss: 1.7631195783615112\n",
      "training 72.81%: 0.596. Loss: 1.9205576181411743\n",
      "training 72.87%: 0.595. Loss: 1.5944844484329224\n",
      "training 72.94%: 0.596. Loss: 1.5204631090164185\n",
      "training 73.00%: 0.596. Loss: 1.437051773071289\n",
      "training 73.06%: 0.595. Loss: 1.6387802362442017\n",
      "training 73.13%: 0.596. Loss: 1.281511664390564\n",
      "training 73.19%: 0.596. Loss: 1.4549248218536377\n",
      "training 73.26%: 0.596. Loss: 1.4047454595565796\n",
      "training 73.32%: 0.596. Loss: 1.496466875076294\n",
      "training 73.38%: 0.596. Loss: 1.7160987854003906\n",
      "training 73.45%: 0.596. Loss: 1.3842008113861084\n",
      "training 73.51%: 0.596. Loss: 1.5863637924194336\n",
      "training 73.58%: 0.596. Loss: 1.6000421047210693\n",
      "training 73.64%: 0.596. Loss: 1.5218470096588135\n",
      "training 73.70%: 0.596. Loss: 1.903895616531372\n",
      "training 73.77%: 0.596. Loss: 1.7743868827819824\n",
      "training 73.83%: 0.595. Loss: 1.506055235862732\n",
      "training 73.90%: 0.595. Loss: 1.6666795015335083\n",
      "training 73.96%: 0.596. Loss: 1.4541858434677124\n",
      "training 74.02%: 0.595. Loss: 1.6791969537734985\n",
      "training 74.09%: 0.595. Loss: 1.7297227382659912\n",
      "training 74.15%: 0.595. Loss: 1.469520926475525\n",
      "training 74.22%: 0.595. Loss: 1.501476764678955\n",
      "training 74.28%: 0.595. Loss: 2.079699993133545\n",
      "training 74.34%: 0.595. Loss: 1.7823922634124756\n",
      "training 74.41%: 0.595. Loss: 1.801207184791565\n",
      "training 74.47%: 0.595. Loss: 1.5332531929016113\n",
      "training 74.54%: 0.595. Loss: 1.6507447957992554\n",
      "training 74.60%: 0.595. Loss: 1.4188917875289917\n",
      "training 74.66%: 0.595. Loss: 1.74093496799469\n",
      "training 74.73%: 0.595. Loss: 1.64093017578125\n",
      "training 74.79%: 0.595. Loss: 1.621057391166687\n",
      "training 74.86%: 0.595. Loss: 1.6571440696716309\n",
      "training 74.92%: 0.595. Loss: 1.877914547920227\n",
      "training 74.98%: 0.595. Loss: 1.7069694995880127\n",
      "training 75.05%: 0.595. Loss: 1.8632962703704834\n",
      "training 75.11%: 0.595. Loss: 1.811601161956787\n",
      "training 75.18%: 0.595. Loss: 1.897290825843811\n",
      "training 75.24%: 0.595. Loss: 1.3603004217147827\n",
      "training 75.30%: 0.595. Loss: 1.752135992050171\n",
      "training 75.37%: 0.595. Loss: 1.3888940811157227\n",
      "training 75.43%: 0.595. Loss: 1.29347825050354\n",
      "training 75.50%: 0.595. Loss: 2.0681281089782715\n",
      "training 75.56%: 0.595. Loss: 1.7822787761688232\n",
      "training 75.62%: 0.595. Loss: 1.6781558990478516\n",
      "training 75.69%: 0.595. Loss: 1.5555537939071655\n",
      "training 75.75%: 0.595. Loss: 1.7109389305114746\n",
      "training 75.82%: 0.595. Loss: 2.0770277976989746\n",
      "training 75.88%: 0.595. Loss: 1.742330551147461\n",
      "training 75.94%: 0.595. Loss: 1.8270878791809082\n",
      "training 76.01%: 0.595. Loss: 1.660780429840088\n",
      "training 76.07%: 0.595. Loss: 1.7696480751037598\n",
      "training 76.14%: 0.595. Loss: 1.3757575750350952\n",
      "training 76.20%: 0.595. Loss: 1.692435622215271\n",
      "training 76.26%: 0.595. Loss: 1.7135653495788574\n",
      "training 76.33%: 0.595. Loss: 1.5297725200653076\n",
      "training 76.39%: 0.595. Loss: 1.695908784866333\n",
      "training 76.46%: 0.595. Loss: 1.4512900114059448\n",
      "training 76.52%: 0.595. Loss: 1.4425374269485474\n",
      "training 76.58%: 0.595. Loss: 1.3236643075942993\n",
      "training 76.65%: 0.595. Loss: 1.6482017040252686\n",
      "training 76.71%: 0.595. Loss: 1.8045884370803833\n",
      "training 76.78%: 0.595. Loss: 1.2614010572433472\n",
      "training 76.84%: 0.595. Loss: 2.0904366970062256\n",
      "training 76.90%: 0.595. Loss: 1.4753386974334717\n",
      "training 76.97%: 0.595. Loss: 1.9162758588790894\n",
      "training 77.03%: 0.595. Loss: 1.6423689126968384\n",
      "training 77.10%: 0.595. Loss: 1.300181269645691\n",
      "training 77.16%: 0.595. Loss: 1.629189372062683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 77.22%: 0.595. Loss: 1.5929160118103027\n",
      "training 77.29%: 0.595. Loss: 1.4782679080963135\n",
      "training 77.35%: 0.595. Loss: 1.3359330892562866\n",
      "training 77.42%: 0.595. Loss: 1.2993996143341064\n",
      "training 77.48%: 0.595. Loss: 1.6698696613311768\n",
      "training 77.54%: 0.595. Loss: 1.6728780269622803\n",
      "training 77.61%: 0.595. Loss: 1.5416045188903809\n",
      "training 77.67%: 0.595. Loss: 1.3248013257980347\n",
      "training 77.74%: 0.595. Loss: 1.9233812093734741\n",
      "training 77.80%: 0.595. Loss: 1.8892827033996582\n",
      "training 77.86%: 0.595. Loss: 1.6525347232818604\n",
      "training 77.93%: 0.595. Loss: 1.4203481674194336\n",
      "training 77.99%: 0.595. Loss: 1.7692123651504517\n",
      "training 78.06%: 0.595. Loss: 1.3945338726043701\n",
      "training 78.12%: 0.595. Loss: 1.4078497886657715\n",
      "training 78.18%: 0.595. Loss: 1.5171595811843872\n",
      "training 78.25%: 0.595. Loss: 1.4643703699111938\n",
      "training 78.31%: 0.595. Loss: 1.4913631677627563\n",
      "training 78.37%: 0.595. Loss: 1.848244071006775\n",
      "training 78.44%: 0.595. Loss: 1.9745489358901978\n",
      "training 78.50%: 0.595. Loss: 1.6750563383102417\n",
      "training 78.57%: 0.595. Loss: 1.6477549076080322\n",
      "training 78.63%: 0.595. Loss: 1.5283759832382202\n",
      "training 78.69%: 0.595. Loss: 1.38185715675354\n",
      "training 78.76%: 0.595. Loss: 1.5352373123168945\n",
      "training 78.82%: 0.595. Loss: 2.032191753387451\n",
      "training 78.89%: 0.595. Loss: 1.653348684310913\n",
      "training 78.95%: 0.595. Loss: 1.6949925422668457\n",
      "training 79.01%: 0.595. Loss: 1.448218822479248\n",
      "training 79.08%: 0.595. Loss: 1.546515941619873\n",
      "training 79.14%: 0.595. Loss: 2.0003304481506348\n",
      "training 79.21%: 0.595. Loss: 1.8132520914077759\n",
      "training 79.27%: 0.595. Loss: 1.9627455472946167\n",
      "training 79.33%: 0.595. Loss: 1.5870921611785889\n",
      "training 79.40%: 0.595. Loss: 1.6590031385421753\n",
      "training 79.46%: 0.595. Loss: 1.3242161273956299\n",
      "training 79.53%: 0.595. Loss: 1.9366523027420044\n",
      "training 79.59%: 0.595. Loss: 1.599861741065979\n",
      "training 79.65%: 0.595. Loss: 1.3411333560943604\n",
      "training 79.72%: 0.595. Loss: 1.4972541332244873\n",
      "training 79.78%: 0.595. Loss: 1.7827893495559692\n",
      "training 79.85%: 0.595. Loss: 1.3982797861099243\n",
      "training 79.91%: 0.595. Loss: 1.4364861249923706\n",
      "training 79.97%: 0.595. Loss: 1.5788874626159668\n",
      "training 80.04%: 0.595. Loss: 2.1332762241363525\n",
      "training 80.10%: 0.595. Loss: 1.4251823425292969\n",
      "training 80.17%: 0.595. Loss: 1.7935224771499634\n",
      "training 80.23%: 0.595. Loss: 1.8625277280807495\n",
      "training 80.29%: 0.595. Loss: 1.740194320678711\n",
      "training 80.36%: 0.595. Loss: 2.0538852214813232\n",
      "training 80.42%: 0.595. Loss: 1.5909889936447144\n",
      "training 80.49%: 0.595. Loss: 1.6533044576644897\n",
      "training 80.55%: 0.595. Loss: 1.7359981536865234\n",
      "training 80.61%: 0.595. Loss: 1.4264914989471436\n",
      "training 80.68%: 0.595. Loss: 1.7150174379348755\n",
      "training 80.74%: 0.595. Loss: 1.4915345907211304\n",
      "training 80.81%: 0.595. Loss: 2.4435601234436035\n",
      "training 80.87%: 0.595. Loss: 1.6671569347381592\n",
      "training 80.93%: 0.595. Loss: 1.7820826768875122\n",
      "training 81.00%: 0.595. Loss: 1.4174120426177979\n",
      "training 81.06%: 0.595. Loss: 1.7065725326538086\n",
      "training 81.13%: 0.595. Loss: 1.5060397386550903\n",
      "training 81.19%: 0.595. Loss: 1.6160762310028076\n",
      "training 81.25%: 0.595. Loss: 1.4689732789993286\n",
      "training 81.32%: 0.595. Loss: 1.7493541240692139\n",
      "training 81.38%: 0.595. Loss: 2.05047345161438\n",
      "training 81.45%: 0.595. Loss: 1.6679631471633911\n",
      "training 81.51%: 0.595. Loss: 1.335323452949524\n",
      "training 81.57%: 0.595. Loss: 1.647276759147644\n",
      "training 81.64%: 0.595. Loss: 1.716630458831787\n",
      "training 81.70%: 0.595. Loss: 1.6073590517044067\n",
      "training 81.77%: 0.595. Loss: 1.5275322198867798\n",
      "training 81.83%: 0.595. Loss: 1.4333046674728394\n",
      "training 81.89%: 0.595. Loss: 1.6962151527404785\n",
      "training 81.96%: 0.595. Loss: 1.3045364618301392\n",
      "training 82.02%: 0.595. Loss: 1.4988590478897095\n",
      "training 82.09%: 0.595. Loss: 1.3388676643371582\n",
      "training 82.15%: 0.595. Loss: 1.4283579587936401\n",
      "training 82.21%: 0.595. Loss: 1.4125678539276123\n",
      "training 82.28%: 0.595. Loss: 1.507690668106079\n",
      "training 82.34%: 0.595. Loss: 1.5775744915008545\n",
      "training 82.41%: 0.595. Loss: 1.538207769393921\n",
      "training 82.47%: 0.595. Loss: 1.4706439971923828\n",
      "training 82.53%: 0.595. Loss: 1.9510002136230469\n",
      "training 82.60%: 0.595. Loss: 1.6614713668823242\n",
      "training 82.66%: 0.595. Loss: 1.6926616430282593\n",
      "training 82.73%: 0.595. Loss: 1.2546437978744507\n",
      "training 82.79%: 0.595. Loss: 1.6609727144241333\n",
      "training 82.85%: 0.595. Loss: 2.0321481227874756\n",
      "training 82.92%: 0.595. Loss: 2.236708402633667\n",
      "training 82.98%: 0.595. Loss: 1.5220439434051514\n",
      "training 83.05%: 0.595. Loss: 1.7368377447128296\n",
      "training 83.11%: 0.595. Loss: 1.6206015348434448\n",
      "training 83.17%: 0.595. Loss: 1.5803591012954712\n",
      "training 83.24%: 0.595. Loss: 1.7912304401397705\n",
      "training 83.30%: 0.595. Loss: 1.7726144790649414\n",
      "training 83.37%: 0.595. Loss: 1.8228518962860107\n",
      "training 83.43%: 0.595. Loss: 1.2997075319290161\n",
      "training 83.49%: 0.595. Loss: 1.564612865447998\n",
      "training 83.56%: 0.595. Loss: 1.542579174041748\n",
      "training 83.62%: 0.595. Loss: 1.8196722269058228\n",
      "training 83.69%: 0.595. Loss: 1.9900933504104614\n",
      "training 83.75%: 0.595. Loss: 1.4662468433380127\n",
      "training 83.81%: 0.595. Loss: 1.7078036069869995\n",
      "training 83.88%: 0.595. Loss: 1.5409303903579712\n",
      "training 83.94%: 0.595. Loss: 1.631034255027771\n",
      "training 84.01%: 0.595. Loss: 1.3468540906906128\n",
      "training 84.07%: 0.595. Loss: 1.3895277976989746\n",
      "training 84.13%: 0.595. Loss: 1.3956035375595093\n",
      "training 84.20%: 0.595. Loss: 1.8145912885665894\n",
      "training 84.26%: 0.595. Loss: 1.5815178155899048\n",
      "training 84.33%: 0.595. Loss: 1.7407675981521606\n",
      "training 84.39%: 0.595. Loss: 1.3958262205123901\n",
      "training 84.45%: 0.595. Loss: 1.6048636436462402\n",
      "training 84.52%: 0.595. Loss: 1.6736600399017334\n",
      "training 84.58%: 0.595. Loss: 1.6925064325332642\n",
      "training 84.64%: 0.595. Loss: 1.57590913772583\n",
      "training 84.71%: 0.595. Loss: 1.598738193511963\n",
      "training 84.77%: 0.595. Loss: 1.4049248695373535\n",
      "training 84.84%: 0.595. Loss: 1.2409204244613647\n",
      "training 84.90%: 0.595. Loss: 1.5420427322387695\n",
      "training 84.96%: 0.595. Loss: 1.7139676809310913\n",
      "training 85.03%: 0.595. Loss: 1.4807002544403076\n",
      "training 85.09%: 0.595. Loss: 1.7896878719329834\n",
      "training 85.16%: 0.595. Loss: 1.4260927438735962\n",
      "training 85.22%: 0.595. Loss: 2.0293750762939453\n",
      "training 85.28%: 0.595. Loss: 1.5757622718811035\n",
      "training 85.35%: 0.595. Loss: 1.9860103130340576\n",
      "training 85.41%: 0.595. Loss: 1.5626295804977417\n",
      "training 85.48%: 0.594. Loss: 1.6585607528686523\n",
      "training 85.54%: 0.594. Loss: 1.9037693738937378\n",
      "training 85.60%: 0.594. Loss: 1.4379912614822388\n",
      "training 85.67%: 0.594. Loss: 1.317886233329773\n",
      "training 85.73%: 0.594. Loss: 1.2747868299484253\n",
      "training 85.80%: 0.595. Loss: 1.373410940170288\n",
      "training 85.86%: 0.594. Loss: 1.7200678586959839\n",
      "training 85.92%: 0.594. Loss: 1.7130751609802246\n",
      "training 85.99%: 0.594. Loss: 2.1053273677825928\n",
      "training 86.05%: 0.594. Loss: 1.4590109586715698\n",
      "training 86.12%: 0.594. Loss: 1.9773386716842651\n",
      "training 86.18%: 0.594. Loss: 1.6797714233398438\n",
      "training 86.24%: 0.594. Loss: 1.112555742263794\n",
      "training 86.31%: 0.594. Loss: 1.4821137189865112\n",
      "training 86.37%: 0.594. Loss: 1.6660133600234985\n",
      "training 86.44%: 0.594. Loss: 1.5097332000732422\n",
      "training 86.50%: 0.594. Loss: 1.6041887998580933\n",
      "training 86.56%: 0.594. Loss: 2.0549070835113525\n",
      "training 86.63%: 0.594. Loss: 1.1347222328186035\n",
      "training 86.69%: 0.595. Loss: 1.3818621635437012\n",
      "training 86.76%: 0.594. Loss: 1.6296941041946411\n",
      "training 86.82%: 0.594. Loss: 1.5788908004760742\n",
      "training 86.88%: 0.594. Loss: 1.5499614477157593\n",
      "training 86.95%: 0.594. Loss: 1.7873464822769165\n",
      "training 87.01%: 0.594. Loss: 1.6306853294372559\n",
      "training 87.08%: 0.594. Loss: 1.5001459121704102\n",
      "training 87.14%: 0.594. Loss: 1.583472728729248\n",
      "training 87.20%: 0.594. Loss: 1.6781948804855347\n",
      "training 87.27%: 0.595. Loss: 1.5816571712493896\n",
      "training 87.33%: 0.595. Loss: 1.3006805181503296\n",
      "training 87.40%: 0.595. Loss: 1.6534929275512695\n",
      "training 87.46%: 0.595. Loss: 1.5281531810760498\n",
      "training 87.52%: 0.595. Loss: 1.4763113260269165\n",
      "training 87.59%: 0.595. Loss: 1.688964605331421\n",
      "training 87.65%: 0.595. Loss: 1.8037917613983154\n",
      "training 87.72%: 0.594. Loss: 1.7580316066741943\n",
      "training 87.78%: 0.594. Loss: 1.679376244544983\n",
      "training 87.84%: 0.594. Loss: 1.6512733697891235\n",
      "training 87.91%: 0.594. Loss: 1.4951486587524414\n",
      "training 87.97%: 0.595. Loss: 1.4196068048477173\n",
      "training 88.04%: 0.595. Loss: 1.0350615978240967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 88.10%: 0.595. Loss: 1.758800745010376\n",
      "training 88.16%: 0.595. Loss: 1.5304603576660156\n",
      "training 88.23%: 0.595. Loss: 1.5487899780273438\n",
      "training 88.29%: 0.595. Loss: 1.8310705423355103\n",
      "training 88.36%: 0.595. Loss: 1.3156253099441528\n",
      "training 88.42%: 0.595. Loss: 1.9785983562469482\n",
      "training 88.48%: 0.595. Loss: 1.8472195863723755\n",
      "training 88.55%: 0.595. Loss: 1.647194743156433\n",
      "training 88.61%: 0.595. Loss: 1.7645671367645264\n",
      "training 88.68%: 0.595. Loss: 1.5112916231155396\n",
      "training 88.74%: 0.595. Loss: 1.7705421447753906\n",
      "training 88.80%: 0.595. Loss: 1.3973861932754517\n",
      "training 88.87%: 0.595. Loss: 2.2614333629608154\n",
      "training 88.93%: 0.594. Loss: 1.9787025451660156\n",
      "training 89.00%: 0.594. Loss: 1.68740975856781\n",
      "training 89.06%: 0.594. Loss: 1.6764507293701172\n",
      "training 89.12%: 0.594. Loss: 1.467213749885559\n",
      "training 89.19%: 0.595. Loss: 1.4424798488616943\n",
      "training 89.25%: 0.595. Loss: 1.5920215845108032\n",
      "training 89.32%: 0.594. Loss: 2.114192247390747\n",
      "training 89.38%: 0.594. Loss: 1.8543378114700317\n",
      "training 89.44%: 0.594. Loss: 1.5127549171447754\n",
      "training 89.51%: 0.594. Loss: 1.6552083492279053\n",
      "training 89.57%: 0.594. Loss: 1.7770326137542725\n",
      "training 89.64%: 0.594. Loss: 1.9409388303756714\n",
      "training 89.70%: 0.594. Loss: 1.682013750076294\n",
      "training 89.76%: 0.594. Loss: 1.4085861444473267\n",
      "training 89.83%: 0.594. Loss: 1.701310634613037\n",
      "training 89.89%: 0.594. Loss: 1.7655993700027466\n",
      "training 89.96%: 0.594. Loss: 1.3149043321609497\n",
      "training 90.02%: 0.594. Loss: 1.46290922164917\n",
      "training 90.08%: 0.594. Loss: 1.6085529327392578\n",
      "training 90.15%: 0.594. Loss: 1.6410490274429321\n",
      "training 90.21%: 0.594. Loss: 1.3669365644454956\n",
      "training 90.28%: 0.594. Loss: 1.8874529600143433\n",
      "training 90.34%: 0.594. Loss: 1.833379864692688\n",
      "training 90.40%: 0.594. Loss: 1.6253806352615356\n",
      "training 90.47%: 0.594. Loss: 1.562881350517273\n",
      "training 90.53%: 0.594. Loss: 1.5590499639511108\n",
      "training 90.60%: 0.594. Loss: 1.3355774879455566\n",
      "training 90.66%: 0.594. Loss: 1.2827104330062866\n",
      "training 90.72%: 0.594. Loss: 1.6020660400390625\n",
      "training 90.79%: 0.594. Loss: 1.6155576705932617\n",
      "training 90.85%: 0.594. Loss: 1.4276049137115479\n",
      "training 90.91%: 0.594. Loss: 2.040517807006836\n",
      "training 90.98%: 0.594. Loss: 1.798675298690796\n",
      "training 91.04%: 0.594. Loss: 1.8979945182800293\n",
      "training 91.11%: 0.594. Loss: 1.620277762413025\n",
      "training 91.17%: 0.594. Loss: 1.6109917163848877\n",
      "training 91.23%: 0.594. Loss: 1.6682236194610596\n",
      "training 91.30%: 0.594. Loss: 2.292882204055786\n",
      "training 91.36%: 0.594. Loss: 1.7706917524337769\n",
      "training 91.43%: 0.594. Loss: 1.5976817607879639\n",
      "training 91.49%: 0.594. Loss: 1.1251248121261597\n",
      "training 91.55%: 0.594. Loss: 1.5295367240905762\n",
      "training 91.62%: 0.594. Loss: 1.7962756156921387\n",
      "training 91.68%: 0.594. Loss: 1.715362787246704\n",
      "training 91.75%: 0.594. Loss: 1.9112303256988525\n",
      "training 91.81%: 0.594. Loss: 2.26314115524292\n",
      "training 91.87%: 0.594. Loss: 1.8060095310211182\n",
      "training 91.94%: 0.594. Loss: 1.585863709449768\n",
      "training 92.00%: 0.594. Loss: 1.510574221611023\n",
      "training 92.07%: 0.594. Loss: 1.4521682262420654\n",
      "training 92.13%: 0.594. Loss: 1.8360710144042969\n",
      "training 92.19%: 0.594. Loss: 1.5224312543869019\n",
      "training 92.26%: 0.594. Loss: 1.7840632200241089\n",
      "training 92.32%: 0.594. Loss: 2.0322957038879395\n",
      "training 92.39%: 0.594. Loss: 1.3970192670822144\n",
      "training 92.45%: 0.594. Loss: 1.4425188302993774\n",
      "training 92.51%: 0.594. Loss: 1.6802678108215332\n",
      "training 92.58%: 0.594. Loss: 2.1037890911102295\n",
      "training 92.64%: 0.594. Loss: 1.5184745788574219\n",
      "training 92.71%: 0.594. Loss: 1.594889760017395\n",
      "training 92.77%: 0.594. Loss: 1.4080660343170166\n",
      "training 92.83%: 0.594. Loss: 1.8696837425231934\n",
      "training 92.90%: 0.594. Loss: 1.6416001319885254\n",
      "training 92.96%: 0.594. Loss: 2.187940835952759\n",
      "training 93.03%: 0.594. Loss: 1.48630952835083\n",
      "training 93.09%: 0.594. Loss: 1.4746023416519165\n",
      "training 93.15%: 0.594. Loss: 1.8613351583480835\n",
      "training 93.22%: 0.594. Loss: 2.140897750854492\n",
      "training 93.28%: 0.594. Loss: 1.8937753438949585\n",
      "training 93.35%: 0.594. Loss: 1.4424024820327759\n",
      "training 93.41%: 0.594. Loss: 1.5428212881088257\n",
      "training 93.47%: 0.594. Loss: 1.7282897233963013\n",
      "training 93.54%: 0.594. Loss: 1.7621049880981445\n",
      "training 93.60%: 0.594. Loss: 1.5303643941879272\n",
      "training 93.67%: 0.594. Loss: 1.5703144073486328\n",
      "training 93.73%: 0.594. Loss: 1.882050633430481\n",
      "training 93.79%: 0.594. Loss: 1.8566224575042725\n",
      "training 93.86%: 0.594. Loss: 1.9645740985870361\n",
      "training 93.92%: 0.594. Loss: 1.5774060487747192\n",
      "training 93.99%: 0.594. Loss: 1.7945586442947388\n",
      "training 94.05%: 0.593. Loss: 1.690585970878601\n",
      "training 94.11%: 0.594. Loss: 1.395719051361084\n",
      "training 94.18%: 0.594. Loss: 1.2229881286621094\n",
      "training 94.24%: 0.594. Loss: 1.8907760381698608\n",
      "training 94.31%: 0.593. Loss: 1.9897924661636353\n",
      "training 94.37%: 0.594. Loss: 1.5275806188583374\n",
      "training 94.43%: 0.594. Loss: 1.453728437423706\n",
      "training 94.50%: 0.594. Loss: 1.3413101434707642\n",
      "training 94.56%: 0.594. Loss: 1.4572640657424927\n",
      "training 94.63%: 0.594. Loss: 1.51761794090271\n",
      "training 94.69%: 0.594. Loss: 1.8567396402359009\n",
      "training 94.75%: 0.594. Loss: 1.4517614841461182\n",
      "training 94.82%: 0.594. Loss: 1.5800609588623047\n",
      "training 94.88%: 0.594. Loss: 1.59939706325531\n",
      "training 94.95%: 0.593. Loss: 1.763710618019104\n",
      "training 95.01%: 0.593. Loss: 1.8591214418411255\n",
      "training 95.07%: 0.593. Loss: 1.5569654703140259\n",
      "training 95.14%: 0.593. Loss: 1.5175083875656128\n",
      "training 95.20%: 0.594. Loss: 1.6117357015609741\n",
      "training 95.27%: 0.593. Loss: 1.9436501264572144\n",
      "training 95.33%: 0.593. Loss: 1.5558087825775146\n",
      "training 95.39%: 0.593. Loss: 2.056814432144165\n",
      "training 95.46%: 0.593. Loss: 1.5571849346160889\n",
      "training 95.52%: 0.593. Loss: 1.7097578048706055\n",
      "training 95.59%: 0.593. Loss: 1.8834567070007324\n",
      "training 95.65%: 0.593. Loss: 2.0567734241485596\n",
      "training 95.71%: 0.593. Loss: 1.4777499437332153\n",
      "training 95.78%: 0.593. Loss: 1.4135679006576538\n",
      "training 95.84%: 0.593. Loss: 1.6897624731063843\n",
      "training 95.91%: 0.593. Loss: 1.386042833328247\n",
      "training 95.97%: 0.593. Loss: 1.541764497756958\n",
      "training 96.03%: 0.593. Loss: 1.1367108821868896\n",
      "training 96.10%: 0.593. Loss: 1.6245168447494507\n",
      "training 96.16%: 0.593. Loss: 1.4704331159591675\n",
      "training 96.23%: 0.593. Loss: 1.4489232301712036\n",
      "training 96.29%: 0.594. Loss: 1.0783696174621582\n",
      "training 96.35%: 0.593. Loss: 1.6785494089126587\n",
      "training 96.42%: 0.593. Loss: 1.8322778940200806\n",
      "training 96.48%: 0.593. Loss: 1.3014661073684692\n",
      "training 96.55%: 0.593. Loss: 2.010678768157959\n",
      "training 96.61%: 0.593. Loss: 1.2545548677444458\n",
      "training 96.67%: 0.594. Loss: 1.7815792560577393\n",
      "training 96.74%: 0.593. Loss: 1.4492392539978027\n",
      "training 96.80%: 0.593. Loss: 1.992202877998352\n",
      "training 96.87%: 0.593. Loss: 1.7098370790481567\n",
      "training 96.93%: 0.594. Loss: 1.3463044166564941\n",
      "training 96.99%: 0.594. Loss: 1.6544311046600342\n",
      "training 97.06%: 0.594. Loss: 1.573472499847412\n",
      "training 97.12%: 0.594. Loss: 1.516006350517273\n",
      "training 97.18%: 0.594. Loss: 1.2300329208374023\n",
      "training 97.25%: 0.594. Loss: 1.8768339157104492\n",
      "training 97.31%: 0.594. Loss: 1.3613454103469849\n",
      "training 97.38%: 0.594. Loss: 1.8635516166687012\n",
      "training 97.44%: 0.594. Loss: 1.4447258710861206\n",
      "training 97.50%: 0.594. Loss: 1.6984182596206665\n",
      "training 97.57%: 0.594. Loss: 1.3008692264556885\n",
      "training 97.63%: 0.594. Loss: 1.464873194694519\n",
      "training 97.70%: 0.594. Loss: 1.4791024923324585\n",
      "training 97.76%: 0.594. Loss: 1.6532424688339233\n",
      "training 97.82%: 0.594. Loss: 1.4688735008239746\n",
      "training 97.89%: 0.594. Loss: 2.0016517639160156\n",
      "training 97.95%: 0.594. Loss: 1.4843628406524658\n",
      "training 98.02%: 0.594. Loss: 1.5148543119430542\n",
      "training 98.08%: 0.594. Loss: 1.9463423490524292\n",
      "training 98.14%: 0.594. Loss: 1.5855201482772827\n",
      "training 98.21%: 0.594. Loss: 1.2719643115997314\n",
      "training 98.27%: 0.594. Loss: 1.486241102218628\n",
      "training 98.34%: 0.594. Loss: 1.3814400434494019\n",
      "training 98.40%: 0.594. Loss: 1.444758415222168\n",
      "training 98.46%: 0.594. Loss: 1.9205042123794556\n",
      "training 98.53%: 0.594. Loss: 1.4994754791259766\n",
      "training 98.59%: 0.594. Loss: 1.5675827264785767\n",
      "training 98.66%: 0.594. Loss: 1.5622912645339966\n",
      "training 98.72%: 0.594. Loss: 1.978313684463501\n",
      "training 98.78%: 0.594. Loss: 1.4873275756835938\n",
      "training 98.85%: 0.594. Loss: 1.5415375232696533\n",
      "training 98.91%: 0.594. Loss: 1.726211428642273\n",
      "training 98.98%: 0.594. Loss: 1.6315747499465942\n",
      "training 99.04%: 0.594. Loss: 1.819064974784851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 99.10%: 0.594. Loss: 1.3519207239151\n",
      "training 99.17%: 0.594. Loss: 1.8744341135025024\n",
      "training 99.23%: 0.594. Loss: 1.2087013721466064\n",
      "training 99.30%: 0.594. Loss: 1.7538050413131714\n",
      "training 99.36%: 0.594. Loss: 1.0496505498886108\n",
      "training 99.42%: 0.594. Loss: 1.4965025186538696\n",
      "training 99.49%: 0.594. Loss: 1.858628273010254\n",
      "training 99.55%: 0.594. Loss: 1.8193116188049316\n",
      "training 99.62%: 0.594. Loss: 1.7243359088897705\n",
      "training 99.68%: 0.594. Loss: 1.6209304332733154\n",
      "training 99.74%: 0.594. Loss: 1.6832492351531982\n",
      "training 99.81%: 0.594. Loss: 1.6340371370315552\n",
      "training 99.87%: 0.594. Loss: 1.7190639972686768\n",
      "training 99.94%: 0.594. Loss: 0.8397052884101868\n",
      "val 0.00%: 0.453. Loss: 2.331153154373169\n",
      "val 0.64%: 0.492. Loss: 1.8785314559936523\n",
      "val 1.27%: 0.557. Loss: 1.31060791015625\n",
      "val 1.91%: 0.562. Loss: 1.5594850778579712\n",
      "val 2.55%: 0.609. Loss: 0.8945354223251343\n",
      "val 3.18%: 0.596. Loss: 1.804311990737915\n",
      "val 3.82%: 0.598. Loss: 1.5509589910507202\n",
      "val 4.46%: 0.600. Loss: 1.5357913970947266\n",
      "val 5.10%: 0.606. Loss: 1.5945028066635132\n",
      "val 5.73%: 0.613. Loss: 1.5524206161499023\n",
      "val 6.37%: 0.609. Loss: 1.2878154516220093\n",
      "val 7.01%: 0.604. Loss: 1.7493078708648682\n",
      "val 7.64%: 0.606. Loss: 1.4528485536575317\n",
      "val 8.28%: 0.598. Loss: 2.1596145629882812\n",
      "val 8.92%: 0.597. Loss: 1.8457026481628418\n",
      "val 9.55%: 0.598. Loss: 1.609168529510498\n",
      "val 10.19%: 0.600. Loss: 1.4387496709823608\n",
      "val 10.83%: 0.601. Loss: 1.3950860500335693\n",
      "val 11.46%: 0.599. Loss: 1.7781133651733398\n",
      "val 12.10%: 0.596. Loss: 1.838160514831543\n",
      "val 12.74%: 0.595. Loss: 1.7515764236450195\n",
      "val 13.38%: 0.592. Loss: 1.5931092500686646\n",
      "val 14.01%: 0.592. Loss: 1.467604160308838\n",
      "val 14.65%: 0.588. Loss: 2.1263930797576904\n",
      "val 15.29%: 0.588. Loss: 1.5246307849884033\n",
      "val 15.92%: 0.584. Loss: 1.7623193264007568\n",
      "val 16.56%: 0.583. Loss: 1.666500449180603\n",
      "val 17.20%: 0.583. Loss: 1.9649208784103394\n",
      "val 17.83%: 0.582. Loss: 1.552479863166809\n",
      "val 18.47%: 0.583. Loss: 1.6798611879348755\n",
      "val 19.11%: 0.583. Loss: 1.5728951692581177\n",
      "val 19.75%: 0.582. Loss: 1.9201310873031616\n",
      "val 20.38%: 0.577. Loss: 2.1772689819335938\n",
      "val 21.02%: 0.577. Loss: 1.8594967126846313\n",
      "val 21.66%: 0.575. Loss: 1.7832187414169312\n",
      "val 22.29%: 0.574. Loss: 1.9404683113098145\n",
      "val 22.93%: 0.573. Loss: 1.7282699346542358\n",
      "val 23.57%: 0.571. Loss: 1.8154858350753784\n",
      "val 24.20%: 0.571. Loss: 1.6691126823425293\n",
      "val 24.84%: 0.574. Loss: 1.3397315740585327\n",
      "val 25.48%: 0.572. Loss: 1.926468849182129\n",
      "val 26.11%: 0.571. Loss: 1.8844623565673828\n",
      "val 26.75%: 0.573. Loss: 1.4971286058425903\n",
      "val 27.39%: 0.575. Loss: 1.303295373916626\n",
      "val 28.03%: 0.576. Loss: 1.6375573873519897\n",
      "val 28.66%: 0.577. Loss: 1.752485990524292\n",
      "val 29.30%: 0.578. Loss: 1.7739475965499878\n",
      "val 29.94%: 0.576. Loss: 1.9390596151351929\n",
      "val 30.57%: 0.577. Loss: 1.2890543937683105\n",
      "val 31.21%: 0.577. Loss: 2.0278213024139404\n",
      "val 31.85%: 0.578. Loss: 1.4531171321868896\n",
      "val 32.48%: 0.578. Loss: 1.488821029663086\n",
      "val 33.12%: 0.578. Loss: 1.6747606992721558\n",
      "val 33.76%: 0.578. Loss: 1.8017311096191406\n",
      "val 34.39%: 0.577. Loss: 1.6518876552581787\n",
      "val 35.03%: 0.578. Loss: 1.6253479719161987\n",
      "val 35.67%: 0.579. Loss: 1.410637617111206\n",
      "val 36.31%: 0.580. Loss: 1.3171658515930176\n",
      "val 36.94%: 0.580. Loss: 1.4512368440628052\n",
      "val 37.58%: 0.579. Loss: 1.9578739404678345\n",
      "val 38.22%: 0.580. Loss: 1.472190499305725\n",
      "val 38.85%: 0.581. Loss: 1.623496174812317\n",
      "val 39.49%: 0.580. Loss: 1.863944172859192\n",
      "val 40.13%: 0.578. Loss: 1.892508625984192\n",
      "val 40.76%: 0.578. Loss: 1.9978511333465576\n",
      "val 41.40%: 0.577. Loss: 2.1096746921539307\n",
      "val 42.04%: 0.578. Loss: 1.3060673475265503\n",
      "val 42.68%: 0.578. Loss: 1.9803224802017212\n",
      "val 43.31%: 0.579. Loss: 1.6093995571136475\n",
      "val 43.95%: 0.579. Loss: 1.9254804849624634\n",
      "val 44.59%: 0.579. Loss: 1.6954963207244873\n",
      "val 45.22%: 0.580. Loss: 1.7920106649398804\n",
      "val 45.86%: 0.580. Loss: 1.3738343715667725\n",
      "val 46.50%: 0.582. Loss: 1.3685111999511719\n",
      "val 47.13%: 0.582. Loss: 1.5101079940795898\n",
      "val 47.77%: 0.583. Loss: 1.6037335395812988\n",
      "val 48.41%: 0.583. Loss: 2.0138041973114014\n",
      "val 49.04%: 0.584. Loss: 1.676134467124939\n",
      "val 49.68%: 0.582. Loss: 1.9651832580566406\n",
      "val 50.32%: 0.583. Loss: 1.5261865854263306\n",
      "val 50.96%: 0.583. Loss: 1.5631054639816284\n",
      "val 51.59%: 0.583. Loss: 1.7627089023590088\n",
      "val 52.23%: 0.583. Loss: 1.657386302947998\n",
      "val 52.87%: 0.583. Loss: 1.486716389656067\n",
      "val 53.50%: 0.584. Loss: 1.5276415348052979\n",
      "val 54.14%: 0.583. Loss: 1.512762427330017\n",
      "val 54.78%: 0.584. Loss: 1.5031046867370605\n",
      "val 55.41%: 0.584. Loss: 1.596086859703064\n",
      "val 56.05%: 0.585. Loss: 1.5027638673782349\n",
      "val 56.69%: 0.584. Loss: 1.63679039478302\n",
      "val 57.32%: 0.584. Loss: 1.8165074586868286\n",
      "val 57.96%: 0.585. Loss: 1.2592182159423828\n",
      "val 58.60%: 0.584. Loss: 2.0438740253448486\n",
      "val 59.24%: 0.583. Loss: 2.2241010665893555\n",
      "val 59.87%: 0.583. Loss: 1.7411772012710571\n",
      "val 60.51%: 0.581. Loss: 2.398940086364746\n",
      "val 61.15%: 0.582. Loss: 1.4737260341644287\n",
      "val 61.78%: 0.583. Loss: 1.63644540309906\n",
      "val 62.42%: 0.582. Loss: 1.8252969980239868\n",
      "val 63.06%: 0.582. Loss: 1.6951394081115723\n",
      "val 63.69%: 0.582. Loss: 1.6919636726379395\n",
      "val 64.33%: 0.582. Loss: 2.0636582374572754\n",
      "val 64.97%: 0.583. Loss: 1.5086193084716797\n",
      "val 65.61%: 0.582. Loss: 2.0097432136535645\n",
      "val 66.24%: 0.582. Loss: 1.8159589767456055\n",
      "val 66.88%: 0.581. Loss: 2.182112216949463\n",
      "val 67.52%: 0.581. Loss: 1.451785922050476\n",
      "val 68.15%: 0.581. Loss: 1.4018120765686035\n",
      "val 68.79%: 0.580. Loss: 1.9678359031677246\n",
      "val 69.43%: 0.580. Loss: 2.1629786491394043\n",
      "val 70.06%: 0.580. Loss: 1.4123395681381226\n",
      "val 70.70%: 0.581. Loss: 1.4167989492416382\n",
      "val 71.34%: 0.580. Loss: 1.6620218753814697\n",
      "val 71.97%: 0.580. Loss: 1.7119667530059814\n",
      "val 72.61%: 0.581. Loss: 1.5413035154342651\n",
      "val 73.25%: 0.581. Loss: 1.6413273811340332\n",
      "val 73.89%: 0.582. Loss: 1.5180517435073853\n",
      "val 74.52%: 0.582. Loss: 1.754810094833374\n",
      "val 75.16%: 0.582. Loss: 1.4956971406936646\n",
      "val 75.80%: 0.583. Loss: 1.7041257619857788\n",
      "val 76.43%: 0.583. Loss: 1.3665915727615356\n",
      "val 77.07%: 0.583. Loss: 1.9086369276046753\n",
      "val 77.71%: 0.583. Loss: 1.5865044593811035\n",
      "val 78.34%: 0.582. Loss: 1.7032372951507568\n",
      "val 78.98%: 0.582. Loss: 1.7810231447219849\n",
      "val 79.62%: 0.582. Loss: 1.665894865989685\n",
      "val 80.25%: 0.581. Loss: 1.8577991724014282\n",
      "val 80.89%: 0.582. Loss: 1.2658700942993164\n",
      "val 81.53%: 0.583. Loss: 1.569245457649231\n",
      "val 82.17%: 0.583. Loss: 1.5195457935333252\n",
      "val 82.80%: 0.583. Loss: 1.661821961402893\n",
      "val 83.44%: 0.583. Loss: 1.590713381767273\n",
      "val 84.08%: 0.583. Loss: 2.082064628601074\n",
      "val 84.71%: 0.582. Loss: 1.5536425113677979\n",
      "val 85.35%: 0.582. Loss: 1.846327304840088\n",
      "val 85.99%: 0.583. Loss: 1.4979276657104492\n",
      "val 86.62%: 0.583. Loss: 1.7772774696350098\n",
      "val 87.26%: 0.583. Loss: 1.775628685951233\n",
      "val 87.90%: 0.584. Loss: 1.3591256141662598\n",
      "val 88.54%: 0.584. Loss: 1.419530987739563\n",
      "val 89.17%: 0.585. Loss: 1.3800877332687378\n",
      "val 89.81%: 0.585. Loss: 1.3139333724975586\n",
      "val 90.45%: 0.585. Loss: 1.6178255081176758\n",
      "val 91.08%: 0.586. Loss: 1.1538643836975098\n",
      "val 91.72%: 0.587. Loss: 1.5078051090240479\n",
      "val 92.36%: 0.587. Loss: 1.424607515335083\n",
      "val 92.99%: 0.587. Loss: 1.875404953956604\n",
      "val 93.63%: 0.587. Loss: 1.6316864490509033\n",
      "val 94.27%: 0.587. Loss: 1.7810362577438354\n",
      "val 94.90%: 0.587. Loss: 1.8270432949066162\n",
      "val 95.54%: 0.586. Loss: 1.5354526042938232\n",
      "val 96.18%: 0.587. Loss: 1.3630293607711792\n",
      "val 96.82%: 0.586. Loss: 1.7190793752670288\n",
      "val 97.45%: 0.586. Loss: 1.97053861618042\n",
      "val 98.09%: 0.585. Loss: 1.841270923614502\n",
      "val 98.73%: 0.586. Loss: 1.6943362951278687\n",
      "val 99.36%: 0.586. Loss: 1.2432141304016113\n",
      "training 0.00%: 0.578. Loss: 1.5695562362670898\n",
      "training 0.06%: 0.633. Loss: 1.124172568321228\n",
      "training 0.13%: 0.635. Loss: 1.4478962421417236\n",
      "training 0.19%: 0.621. Loss: 1.5960392951965332\n",
      "training 0.26%: 0.616. Loss: 1.809532642364502\n",
      "training 0.32%: 0.609. Loss: 1.3396958112716675\n",
      "training 0.38%: 0.614. Loss: 1.422326922416687\n",
      "training 0.45%: 0.621. Loss: 1.656713604927063\n",
      "training 0.51%: 0.606. Loss: 1.8940324783325195\n",
      "training 0.58%: 0.602. Loss: 1.5664339065551758\n",
      "training 0.64%: 0.608. Loss: 1.317949891090393\n",
      "training 0.70%: 0.608. Loss: 1.5408660173416138\n",
      "training 0.77%: 0.607. Loss: 1.6350786685943604\n",
      "training 0.83%: 0.610. Loss: 1.3980764150619507\n",
      "training 0.90%: 0.609. Loss: 1.583805799484253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 0.96%: 0.616. Loss: 1.0566165447235107\n",
      "training 1.02%: 0.616. Loss: 1.7199825048446655\n",
      "training 1.09%: 0.619. Loss: 1.5948166847229004\n",
      "training 1.15%: 0.622. Loss: 0.9126173853874207\n",
      "training 1.22%: 0.628. Loss: 1.3784091472625732\n",
      "training 1.28%: 0.627. Loss: 1.5069966316223145\n",
      "training 1.34%: 0.628. Loss: 1.3995167016983032\n",
      "training 1.41%: 0.631. Loss: 1.191755771636963\n",
      "training 1.47%: 0.631. Loss: 1.7907097339630127\n",
      "training 1.54%: 0.624. Loss: 1.6650365591049194\n",
      "training 1.60%: 0.623. Loss: 1.5819278955459595\n",
      "training 1.66%: 0.623. Loss: 1.3549038171768188\n",
      "training 1.73%: 0.624. Loss: 1.5655171871185303\n",
      "training 1.79%: 0.624. Loss: 1.5250654220581055\n",
      "training 1.86%: 0.625. Loss: 1.8265659809112549\n",
      "training 1.92%: 0.624. Loss: 1.7938803434371948\n",
      "training 1.98%: 0.625. Loss: 1.5566396713256836\n",
      "training 2.05%: 0.625. Loss: 1.4788234233856201\n",
      "training 2.11%: 0.625. Loss: 1.3729777336120605\n",
      "training 2.18%: 0.626. Loss: 0.9956451654434204\n",
      "training 2.24%: 0.629. Loss: 1.3073463439941406\n",
      "training 2.30%: 0.627. Loss: 1.7846667766571045\n",
      "training 2.37%: 0.626. Loss: 1.4027633666992188\n",
      "training 2.43%: 0.625. Loss: 1.831967830657959\n",
      "training 2.50%: 0.621. Loss: 1.732133150100708\n",
      "training 2.56%: 0.622. Loss: 1.5040006637573242\n",
      "training 2.62%: 0.619. Loss: 1.9576563835144043\n",
      "training 2.69%: 0.620. Loss: 1.4821282625198364\n",
      "training 2.75%: 0.620. Loss: 1.452080249786377\n",
      "training 2.82%: 0.618. Loss: 1.644534707069397\n",
      "training 2.88%: 0.617. Loss: 1.480101227760315\n",
      "training 2.94%: 0.616. Loss: 1.833211898803711\n",
      "training 3.01%: 0.617. Loss: 1.6378322839736938\n",
      "training 3.07%: 0.617. Loss: 1.4485950469970703\n",
      "training 3.13%: 0.619. Loss: 1.018919825553894\n",
      "training 3.20%: 0.620. Loss: 1.1874315738677979\n",
      "training 3.26%: 0.621. Loss: 1.3072198629379272\n",
      "training 3.33%: 0.620. Loss: 1.6688536405563354\n",
      "training 3.39%: 0.619. Loss: 1.755497932434082\n",
      "training 3.45%: 0.620. Loss: 1.385888934135437\n",
      "training 3.52%: 0.622. Loss: 1.096252679824829\n",
      "training 3.58%: 0.622. Loss: 1.4665040969848633\n",
      "training 3.65%: 0.622. Loss: 1.5898046493530273\n",
      "training 3.71%: 0.624. Loss: 1.1677125692367554\n",
      "training 3.77%: 0.623. Loss: 1.5376808643341064\n",
      "training 3.84%: 0.621. Loss: 1.7898014783859253\n",
      "training 3.90%: 0.621. Loss: 1.6221238374710083\n",
      "training 3.97%: 0.621. Loss: 1.3444819450378418\n",
      "training 4.03%: 0.622. Loss: 1.1534425020217896\n",
      "training 4.09%: 0.621. Loss: 1.8535935878753662\n",
      "training 4.16%: 0.620. Loss: 1.888571858406067\n",
      "training 4.22%: 0.619. Loss: 1.5391852855682373\n",
      "training 4.29%: 0.619. Loss: 1.6446598768234253\n",
      "training 4.35%: 0.620. Loss: 0.9983670711517334\n",
      "training 4.41%: 0.620. Loss: 1.3664896488189697\n",
      "training 4.48%: 0.621. Loss: 1.463547706604004\n",
      "training 4.54%: 0.618. Loss: 2.0114612579345703\n",
      "training 4.61%: 0.618. Loss: 1.6315406560897827\n",
      "training 4.67%: 0.618. Loss: 1.5318446159362793\n",
      "training 4.73%: 0.618. Loss: 1.314315676689148\n",
      "training 4.80%: 0.619. Loss: 1.3073397874832153\n",
      "training 4.86%: 0.617. Loss: 1.9710198640823364\n",
      "training 4.93%: 0.617. Loss: 1.6003557443618774\n",
      "training 4.99%: 0.617. Loss: 1.5295981168746948\n",
      "training 5.05%: 0.617. Loss: 1.5182472467422485\n",
      "training 5.12%: 0.617. Loss: 1.5110499858856201\n",
      "training 5.18%: 0.615. Loss: 1.9676628112792969\n",
      "training 5.25%: 0.614. Loss: 1.6221058368682861\n",
      "training 5.31%: 0.615. Loss: 1.4601032733917236\n",
      "training 5.37%: 0.614. Loss: 1.7501144409179688\n",
      "training 5.44%: 0.613. Loss: 1.856002688407898\n",
      "training 5.50%: 0.613. Loss: 1.468031406402588\n",
      "training 5.57%: 0.613. Loss: 1.4788126945495605\n",
      "training 5.63%: 0.612. Loss: 1.717324137687683\n",
      "training 5.69%: 0.613. Loss: 1.1193956136703491\n",
      "training 5.76%: 0.613. Loss: 1.5407521724700928\n",
      "training 5.82%: 0.613. Loss: 1.6588759422302246\n",
      "training 5.89%: 0.612. Loss: 1.35275137424469\n",
      "training 5.95%: 0.613. Loss: 1.520448923110962\n",
      "training 6.01%: 0.613. Loss: 1.421417236328125\n",
      "training 6.08%: 0.613. Loss: 1.5658758878707886\n",
      "training 6.14%: 0.614. Loss: 1.271715760231018\n",
      "training 6.21%: 0.613. Loss: 1.8396416902542114\n",
      "training 6.27%: 0.614. Loss: 1.0123379230499268\n",
      "training 6.33%: 0.614. Loss: 1.5506336688995361\n",
      "training 6.40%: 0.614. Loss: 1.3605408668518066\n",
      "training 6.46%: 0.615. Loss: 1.2438056468963623\n",
      "training 6.53%: 0.615. Loss: 1.1233793497085571\n",
      "training 6.59%: 0.616. Loss: 1.282913327217102\n",
      "training 6.65%: 0.616. Loss: 1.663429617881775\n",
      "training 6.72%: 0.615. Loss: 1.8344879150390625\n",
      "training 6.78%: 0.615. Loss: 1.727738618850708\n",
      "training 6.85%: 0.616. Loss: 1.032122015953064\n",
      "training 6.91%: 0.616. Loss: 1.5503711700439453\n",
      "training 6.97%: 0.617. Loss: 1.5089415311813354\n",
      "training 7.04%: 0.618. Loss: 1.340260624885559\n",
      "training 7.10%: 0.617. Loss: 1.6008360385894775\n",
      "training 7.17%: 0.618. Loss: 1.4422202110290527\n",
      "training 7.23%: 0.618. Loss: 1.5626578330993652\n",
      "training 7.29%: 0.618. Loss: 1.5723215341567993\n",
      "training 7.36%: 0.618. Loss: 1.4788455963134766\n",
      "training 7.42%: 0.618. Loss: 1.2245378494262695\n",
      "training 7.49%: 0.618. Loss: 1.3319973945617676\n",
      "training 7.55%: 0.618. Loss: 1.478040337562561\n",
      "training 7.61%: 0.618. Loss: 1.077749252319336\n",
      "training 7.68%: 0.619. Loss: 1.3436191082000732\n",
      "training 7.74%: 0.618. Loss: 1.5312526226043701\n",
      "training 7.81%: 0.619. Loss: 1.3244514465332031\n",
      "training 7.87%: 0.620. Loss: 1.1585369110107422\n",
      "training 7.93%: 0.620. Loss: 1.4455734491348267\n",
      "training 8.00%: 0.620. Loss: 1.4062117338180542\n",
      "training 8.06%: 0.620. Loss: 1.9748486280441284\n",
      "training 8.13%: 0.620. Loss: 1.2197604179382324\n",
      "training 8.19%: 0.620. Loss: 1.3201287984848022\n",
      "training 8.25%: 0.620. Loss: 1.7535903453826904\n",
      "training 8.32%: 0.619. Loss: 1.6301673650741577\n",
      "training 8.38%: 0.620. Loss: 1.2841265201568604\n",
      "training 8.45%: 0.620. Loss: 1.5431267023086548\n",
      "training 8.51%: 0.620. Loss: 1.583878755569458\n",
      "training 8.57%: 0.619. Loss: 1.8815910816192627\n",
      "training 8.64%: 0.619. Loss: 1.9008163213729858\n",
      "training 8.70%: 0.619. Loss: 1.3363226652145386\n",
      "training 8.77%: 0.619. Loss: 1.707716941833496\n",
      "training 8.83%: 0.620. Loss: 1.1333017349243164\n",
      "training 8.89%: 0.620. Loss: 1.373293161392212\n",
      "training 8.96%: 0.620. Loss: 1.8939259052276611\n",
      "training 9.02%: 0.619. Loss: 1.6860941648483276\n",
      "training 9.09%: 0.619. Loss: 1.697878122329712\n",
      "training 9.15%: 0.619. Loss: 1.2772068977355957\n",
      "training 9.21%: 0.619. Loss: 1.6826304197311401\n",
      "training 9.28%: 0.619. Loss: 1.30667245388031\n",
      "training 9.34%: 0.619. Loss: 1.2849102020263672\n",
      "training 9.40%: 0.619. Loss: 1.2775028944015503\n",
      "training 9.47%: 0.620. Loss: 1.495401382446289\n",
      "training 9.53%: 0.621. Loss: 1.2134901285171509\n",
      "training 9.60%: 0.621. Loss: 1.41095769405365\n",
      "training 9.66%: 0.621. Loss: 1.367802619934082\n",
      "training 9.72%: 0.621. Loss: 1.2406634092330933\n",
      "training 9.79%: 0.621. Loss: 1.6743650436401367\n",
      "training 9.85%: 0.621. Loss: 1.3979508876800537\n",
      "training 9.92%: 0.621. Loss: 1.8041107654571533\n",
      "training 9.98%: 0.621. Loss: 1.2762110233306885\n",
      "training 10.04%: 0.621. Loss: 1.6190851926803589\n",
      "training 10.11%: 0.620. Loss: 1.424422264099121\n",
      "training 10.17%: 0.620. Loss: 1.7094451189041138\n",
      "training 10.24%: 0.620. Loss: 1.6698449850082397\n",
      "training 10.30%: 0.620. Loss: 1.6356914043426514\n",
      "training 10.36%: 0.620. Loss: 1.6023085117340088\n",
      "training 10.43%: 0.620. Loss: 0.916939377784729\n",
      "training 10.49%: 0.620. Loss: 1.60824716091156\n",
      "training 10.56%: 0.620. Loss: 1.4900952577590942\n",
      "training 10.62%: 0.620. Loss: 1.7043558359146118\n",
      "training 10.68%: 0.620. Loss: 1.3712047338485718\n",
      "training 10.75%: 0.620. Loss: 1.388892650604248\n",
      "training 10.81%: 0.620. Loss: 1.5393133163452148\n",
      "training 10.88%: 0.620. Loss: 1.8667329549789429\n",
      "training 10.94%: 0.620. Loss: 1.2922143936157227\n",
      "training 11.00%: 0.619. Loss: 1.8935348987579346\n",
      "training 11.07%: 0.619. Loss: 1.7849984169006348\n",
      "training 11.13%: 0.619. Loss: 1.4441043138504028\n",
      "training 11.20%: 0.619. Loss: 1.6013962030410767\n",
      "training 11.26%: 0.619. Loss: 1.5157297849655151\n",
      "training 11.32%: 0.619. Loss: 1.4899343252182007\n",
      "training 11.39%: 0.619. Loss: 1.3077574968338013\n",
      "training 11.45%: 0.619. Loss: 1.0256879329681396\n",
      "training 11.52%: 0.619. Loss: 2.1148929595947266\n",
      "training 11.58%: 0.619. Loss: 1.6417607069015503\n",
      "training 11.64%: 0.618. Loss: 1.7124665975570679\n",
      "training 11.71%: 0.618. Loss: 1.45826256275177\n",
      "training 11.77%: 0.618. Loss: 1.2530386447906494\n",
      "training 11.84%: 0.618. Loss: 1.5606505870819092\n",
      "training 11.90%: 0.618. Loss: 1.5715126991271973\n",
      "training 11.96%: 0.618. Loss: 1.202290654182434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 12.03%: 0.618. Loss: 1.5878336429595947\n",
      "training 12.09%: 0.618. Loss: 1.3698865175247192\n",
      "training 12.16%: 0.617. Loss: 1.6093542575836182\n",
      "training 12.22%: 0.617. Loss: 1.65086829662323\n",
      "training 12.28%: 0.617. Loss: 1.453484058380127\n",
      "training 12.35%: 0.617. Loss: 1.471468448638916\n",
      "training 12.41%: 0.617. Loss: 1.710968255996704\n",
      "training 12.48%: 0.616. Loss: 1.973651647567749\n",
      "training 12.54%: 0.617. Loss: 1.148746132850647\n",
      "training 12.60%: 0.617. Loss: 1.6602035760879517\n",
      "training 12.67%: 0.617. Loss: 1.409595251083374\n",
      "training 12.73%: 0.617. Loss: 1.3451027870178223\n",
      "training 12.80%: 0.617. Loss: 1.3065929412841797\n",
      "training 12.86%: 0.617. Loss: 1.0413835048675537\n",
      "training 12.92%: 0.617. Loss: 2.0948212146759033\n",
      "training 12.99%: 0.616. Loss: 1.658729076385498\n",
      "training 13.05%: 0.617. Loss: 1.1634886264801025\n",
      "training 13.12%: 0.617. Loss: 1.5865370035171509\n",
      "training 13.18%: 0.616. Loss: 1.3899551630020142\n",
      "training 13.24%: 0.616. Loss: 1.4493179321289062\n",
      "training 13.31%: 0.616. Loss: 1.596409559249878\n",
      "training 13.37%: 0.617. Loss: 1.3201797008514404\n",
      "training 13.44%: 0.616. Loss: 1.7237523794174194\n",
      "training 13.50%: 0.616. Loss: 1.630342960357666\n",
      "training 13.56%: 0.616. Loss: 1.6261792182922363\n",
      "training 13.63%: 0.616. Loss: 1.524627923965454\n",
      "training 13.69%: 0.616. Loss: 1.3498421907424927\n",
      "training 13.76%: 0.617. Loss: 1.0373194217681885\n",
      "training 13.82%: 0.617. Loss: 1.5928454399108887\n",
      "training 13.88%: 0.617. Loss: 1.7317591905593872\n",
      "training 13.95%: 0.617. Loss: 1.7114275693893433\n",
      "training 14.01%: 0.617. Loss: 1.2447707653045654\n",
      "training 14.08%: 0.617. Loss: 1.8031423091888428\n",
      "training 14.14%: 0.617. Loss: 1.8029409646987915\n",
      "training 14.20%: 0.617. Loss: 1.7308684587478638\n",
      "training 14.27%: 0.617. Loss: 1.4418506622314453\n",
      "training 14.33%: 0.617. Loss: 1.3011250495910645\n",
      "training 14.40%: 0.617. Loss: 1.2715381383895874\n",
      "training 14.46%: 0.617. Loss: 1.8569890260696411\n",
      "training 14.52%: 0.616. Loss: 1.4715923070907593\n",
      "training 14.59%: 0.616. Loss: 1.4687206745147705\n",
      "training 14.65%: 0.616. Loss: 1.5239142179489136\n",
      "training 14.72%: 0.616. Loss: 2.3155548572540283\n",
      "training 14.78%: 0.616. Loss: 1.5865583419799805\n",
      "training 14.84%: 0.616. Loss: 1.676103949546814\n",
      "training 14.91%: 0.616. Loss: 1.27472984790802\n",
      "training 14.97%: 0.616. Loss: 1.8123400211334229\n",
      "training 15.04%: 0.615. Loss: 1.7557220458984375\n",
      "training 15.10%: 0.615. Loss: 1.3744935989379883\n",
      "training 15.16%: 0.615. Loss: 1.6958190202713013\n",
      "training 15.23%: 0.615. Loss: 1.3754554986953735\n",
      "training 15.29%: 0.616. Loss: 1.3250542879104614\n",
      "training 15.36%: 0.616. Loss: 1.7300710678100586\n",
      "training 15.42%: 0.616. Loss: 1.4672214984893799\n",
      "training 15.48%: 0.616. Loss: 1.4370863437652588\n",
      "training 15.55%: 0.616. Loss: 1.4361252784729004\n",
      "training 15.61%: 0.616. Loss: 0.9327314496040344\n",
      "training 15.67%: 0.616. Loss: 1.415506362915039\n",
      "training 15.74%: 0.616. Loss: 1.3751790523529053\n",
      "training 15.80%: 0.616. Loss: 1.339971661567688\n",
      "training 15.87%: 0.616. Loss: 1.401499629020691\n",
      "training 15.93%: 0.616. Loss: 1.5649257898330688\n",
      "training 15.99%: 0.616. Loss: 1.6945855617523193\n",
      "training 16.06%: 0.616. Loss: 1.520907998085022\n",
      "training 16.12%: 0.617. Loss: 1.2558320760726929\n",
      "training 16.19%: 0.617. Loss: 1.4180177450180054\n",
      "training 16.25%: 0.617. Loss: 1.4582469463348389\n",
      "training 16.31%: 0.617. Loss: 1.479733943939209\n",
      "training 16.38%: 0.617. Loss: 1.430328607559204\n",
      "training 16.44%: 0.617. Loss: 1.3255789279937744\n",
      "training 16.51%: 0.617. Loss: 1.500855565071106\n",
      "training 16.57%: 0.617. Loss: 1.6283509731292725\n",
      "training 16.63%: 0.617. Loss: 1.545678973197937\n",
      "training 16.70%: 0.617. Loss: 1.3762246370315552\n",
      "training 16.76%: 0.617. Loss: 1.631319522857666\n",
      "training 16.83%: 0.617. Loss: 1.6156136989593506\n",
      "training 16.89%: 0.617. Loss: 1.5865968465805054\n",
      "training 16.95%: 0.618. Loss: 1.332531213760376\n",
      "training 17.02%: 0.617. Loss: 1.7864165306091309\n",
      "training 17.08%: 0.617. Loss: 1.4587831497192383\n",
      "training 17.15%: 0.617. Loss: 1.6063745021820068\n",
      "training 17.21%: 0.617. Loss: 1.8062268495559692\n",
      "training 17.27%: 0.617. Loss: 1.5293043851852417\n",
      "training 17.34%: 0.617. Loss: 1.9697492122650146\n",
      "training 17.40%: 0.617. Loss: 1.5722436904907227\n",
      "training 17.47%: 0.617. Loss: 1.8950368165969849\n",
      "training 17.53%: 0.617. Loss: 1.4286770820617676\n",
      "training 17.59%: 0.617. Loss: 1.432985544204712\n",
      "training 17.66%: 0.617. Loss: 1.2600023746490479\n",
      "training 17.72%: 0.617. Loss: 1.5449925661087036\n",
      "training 17.79%: 0.617. Loss: 1.535231113433838\n",
      "training 17.85%: 0.617. Loss: 1.6120463609695435\n",
      "training 17.91%: 0.617. Loss: 1.2809877395629883\n",
      "training 17.98%: 0.617. Loss: 1.749921202659607\n",
      "training 18.04%: 0.617. Loss: 1.1992788314819336\n",
      "training 18.11%: 0.617. Loss: 1.5216909646987915\n",
      "training 18.17%: 0.617. Loss: 1.5504400730133057\n",
      "training 18.23%: 0.617. Loss: 1.6337214708328247\n",
      "training 18.30%: 0.617. Loss: 1.2089152336120605\n",
      "training 18.36%: 0.617. Loss: 1.5418046712875366\n",
      "training 18.43%: 0.617. Loss: 1.5438429117202759\n",
      "training 18.49%: 0.617. Loss: 1.7521381378173828\n",
      "training 18.55%: 0.617. Loss: 1.9037811756134033\n",
      "training 18.62%: 0.617. Loss: 1.350155234336853\n",
      "training 18.68%: 0.617. Loss: 1.0659453868865967\n",
      "training 18.75%: 0.617. Loss: 1.8854777812957764\n",
      "training 18.81%: 0.617. Loss: 1.586367130279541\n",
      "training 18.87%: 0.617. Loss: 1.5663061141967773\n",
      "training 18.94%: 0.616. Loss: 2.1601715087890625\n",
      "training 19.00%: 0.616. Loss: 1.3183027505874634\n",
      "training 19.07%: 0.616. Loss: 1.2462491989135742\n",
      "training 19.13%: 0.616. Loss: 1.490790605545044\n",
      "training 19.19%: 0.616. Loss: 1.4116828441619873\n",
      "training 19.26%: 0.616. Loss: 1.5195155143737793\n",
      "training 19.32%: 0.617. Loss: 1.3390653133392334\n",
      "training 19.39%: 0.617. Loss: 1.4493160247802734\n",
      "training 19.45%: 0.616. Loss: 1.6854846477508545\n",
      "training 19.51%: 0.616. Loss: 1.341997504234314\n",
      "training 19.58%: 0.616. Loss: 1.5929189920425415\n",
      "training 19.64%: 0.616. Loss: 1.375389814376831\n",
      "training 19.71%: 0.616. Loss: 1.4942597150802612\n",
      "training 19.77%: 0.616. Loss: 1.7212603092193604\n",
      "training 19.83%: 0.616. Loss: 1.368281602859497\n",
      "training 19.90%: 0.616. Loss: 1.612485647201538\n",
      "training 19.96%: 0.616. Loss: 1.5111780166625977\n",
      "training 20.03%: 0.617. Loss: 1.1653043031692505\n",
      "training 20.09%: 0.617. Loss: 1.4767450094223022\n",
      "training 20.15%: 0.617. Loss: 1.489330768585205\n",
      "training 20.22%: 0.617. Loss: 1.5508782863616943\n",
      "training 20.28%: 0.617. Loss: 1.3448110818862915\n",
      "training 20.35%: 0.617. Loss: 1.855164647102356\n",
      "training 20.41%: 0.617. Loss: 1.3954906463623047\n",
      "training 20.47%: 0.617. Loss: 1.3112976551055908\n",
      "training 20.54%: 0.617. Loss: 1.675750970840454\n",
      "training 20.60%: 0.617. Loss: 1.1249959468841553\n",
      "training 20.67%: 0.617. Loss: 1.513169288635254\n",
      "training 20.73%: 0.617. Loss: 1.4466568231582642\n",
      "training 20.79%: 0.617. Loss: 1.3666446208953857\n",
      "training 20.86%: 0.617. Loss: 1.2982412576675415\n",
      "training 20.92%: 0.617. Loss: 1.488656759262085\n",
      "training 20.99%: 0.617. Loss: 1.4321568012237549\n",
      "training 21.05%: 0.617. Loss: 1.0080857276916504\n",
      "training 21.11%: 0.617. Loss: 1.444321870803833\n",
      "training 21.18%: 0.618. Loss: 1.0791963338851929\n",
      "training 21.24%: 0.618. Loss: 1.6096359491348267\n",
      "training 21.31%: 0.618. Loss: 1.4117470979690552\n",
      "training 21.37%: 0.618. Loss: 1.5353869199752808\n",
      "training 21.43%: 0.618. Loss: 1.5233654975891113\n",
      "training 21.50%: 0.618. Loss: 1.622101902961731\n",
      "training 21.56%: 0.617. Loss: 1.6506420373916626\n",
      "training 21.63%: 0.617. Loss: 1.6347777843475342\n",
      "training 21.69%: 0.617. Loss: 1.8101555109024048\n",
      "training 21.75%: 0.617. Loss: 1.6801470518112183\n",
      "training 21.82%: 0.617. Loss: 1.6858621835708618\n",
      "training 21.88%: 0.617. Loss: 1.0643463134765625\n",
      "training 21.94%: 0.617. Loss: 1.646474838256836\n",
      "training 22.01%: 0.617. Loss: 1.640263319015503\n",
      "training 22.07%: 0.617. Loss: 1.6545053720474243\n",
      "training 22.14%: 0.617. Loss: 1.672374963760376\n",
      "training 22.20%: 0.617. Loss: 1.4684516191482544\n",
      "training 22.26%: 0.617. Loss: 1.8231019973754883\n",
      "training 22.33%: 0.617. Loss: 1.7661182880401611\n",
      "training 22.39%: 0.617. Loss: 1.3605973720550537\n",
      "training 22.46%: 0.617. Loss: 1.6010537147521973\n",
      "training 22.52%: 0.617. Loss: 1.2982689142227173\n",
      "training 22.58%: 0.617. Loss: 1.7173916101455688\n",
      "training 22.65%: 0.617. Loss: 1.2325748205184937\n",
      "training 22.71%: 0.617. Loss: 1.1642471551895142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 22.78%: 0.618. Loss: 1.594848871231079\n",
      "training 22.84%: 0.618. Loss: 1.1356719732284546\n",
      "training 22.90%: 0.618. Loss: 1.7127162218093872\n",
      "training 22.97%: 0.618. Loss: 1.8207484483718872\n",
      "training 23.03%: 0.618. Loss: 1.4864295721054077\n",
      "training 23.10%: 0.617. Loss: 2.0250778198242188\n",
      "training 23.16%: 0.618. Loss: 1.3768901824951172\n",
      "training 23.22%: 0.618. Loss: 1.402534008026123\n",
      "training 23.29%: 0.618. Loss: 1.3630542755126953\n",
      "training 23.35%: 0.618. Loss: 1.359061360359192\n",
      "training 23.42%: 0.618. Loss: 1.1407138109207153\n",
      "training 23.48%: 0.618. Loss: 1.4596786499023438\n",
      "training 23.54%: 0.618. Loss: 1.5761938095092773\n",
      "training 23.61%: 0.618. Loss: 1.4814945459365845\n",
      "training 23.67%: 0.618. Loss: 1.3113601207733154\n",
      "training 23.74%: 0.618. Loss: 1.4160711765289307\n",
      "training 23.80%: 0.618. Loss: 1.8868969678878784\n",
      "training 23.86%: 0.618. Loss: 1.7257579565048218\n",
      "training 23.93%: 0.619. Loss: 1.235708236694336\n",
      "training 23.99%: 0.619. Loss: 1.2494783401489258\n",
      "training 24.06%: 0.619. Loss: 1.6287469863891602\n",
      "training 24.12%: 0.619. Loss: 1.2566688060760498\n",
      "training 24.18%: 0.619. Loss: 1.5973410606384277\n",
      "training 24.25%: 0.619. Loss: 1.1952131986618042\n",
      "training 24.31%: 0.619. Loss: 1.191536545753479\n",
      "training 24.38%: 0.619. Loss: 1.6950503587722778\n",
      "training 24.44%: 0.619. Loss: 1.2745137214660645\n",
      "training 24.50%: 0.619. Loss: 1.3298604488372803\n",
      "training 24.57%: 0.619. Loss: 1.5330042839050293\n",
      "training 24.63%: 0.620. Loss: 1.3986258506774902\n",
      "training 24.70%: 0.619. Loss: 1.4876346588134766\n",
      "training 24.76%: 0.619. Loss: 1.6568015813827515\n",
      "training 24.82%: 0.619. Loss: 1.3442307710647583\n",
      "training 24.89%: 0.619. Loss: 1.5606228113174438\n",
      "training 24.95%: 0.619. Loss: 1.791823387145996\n",
      "training 25.02%: 0.619. Loss: 1.6696655750274658\n",
      "training 25.08%: 0.619. Loss: 1.4233399629592896\n",
      "training 25.14%: 0.619. Loss: 1.8824617862701416\n",
      "training 25.21%: 0.618. Loss: 1.6684085130691528\n",
      "training 25.27%: 0.618. Loss: 1.4748963117599487\n",
      "training 25.34%: 0.618. Loss: 1.5397645235061646\n",
      "training 25.40%: 0.618. Loss: 1.3521089553833008\n",
      "training 25.46%: 0.618. Loss: 1.5873908996582031\n",
      "training 25.53%: 0.618. Loss: 1.3936148881912231\n",
      "training 25.59%: 0.618. Loss: 1.6024609804153442\n",
      "training 25.66%: 0.619. Loss: 1.173248052597046\n",
      "training 25.72%: 0.619. Loss: 1.4038552045822144\n",
      "training 25.78%: 0.619. Loss: 1.3359941244125366\n",
      "training 25.85%: 0.619. Loss: 1.5884820222854614\n",
      "training 25.91%: 0.619. Loss: 1.5553792715072632\n",
      "training 25.98%: 0.618. Loss: 1.5896254777908325\n",
      "training 26.04%: 0.618. Loss: 1.6264640092849731\n",
      "training 26.10%: 0.618. Loss: 1.9367949962615967\n",
      "training 26.17%: 0.618. Loss: 1.9821568727493286\n",
      "training 26.23%: 0.618. Loss: 1.7303966283798218\n",
      "training 26.30%: 0.618. Loss: 1.711477279663086\n",
      "training 26.36%: 0.618. Loss: 1.3032439947128296\n",
      "training 26.42%: 0.618. Loss: 1.6450810432434082\n",
      "training 26.49%: 0.618. Loss: 1.4388870000839233\n",
      "training 26.55%: 0.618. Loss: 1.8531545400619507\n",
      "training 26.62%: 0.618. Loss: 1.7468063831329346\n",
      "training 26.68%: 0.618. Loss: 1.6712110042572021\n",
      "training 26.74%: 0.618. Loss: 1.6813485622406006\n",
      "training 26.81%: 0.618. Loss: 1.4742738008499146\n",
      "training 26.87%: 0.618. Loss: 1.6671159267425537\n",
      "training 26.94%: 0.618. Loss: 1.909169316291809\n",
      "training 27.00%: 0.617. Loss: 1.4992845058441162\n",
      "training 27.06%: 0.617. Loss: 1.5356539487838745\n",
      "training 27.13%: 0.617. Loss: 1.4363373517990112\n",
      "training 27.19%: 0.617. Loss: 1.510648250579834\n",
      "training 27.26%: 0.617. Loss: 1.406820297241211\n",
      "training 27.32%: 0.617. Loss: 1.5254757404327393\n",
      "training 27.38%: 0.617. Loss: 1.2639206647872925\n",
      "training 27.45%: 0.617. Loss: 1.4320292472839355\n",
      "training 27.51%: 0.617. Loss: 1.675750970840454\n",
      "training 27.58%: 0.617. Loss: 1.6808404922485352\n",
      "training 27.64%: 0.617. Loss: 1.5125632286071777\n",
      "training 27.70%: 0.617. Loss: 1.8016979694366455\n",
      "training 27.77%: 0.617. Loss: 1.6788227558135986\n",
      "training 27.83%: 0.617. Loss: 1.2336093187332153\n",
      "training 27.90%: 0.617. Loss: 1.5076205730438232\n",
      "training 27.96%: 0.617. Loss: 1.9385722875595093\n",
      "training 28.02%: 0.617. Loss: 1.395632028579712\n",
      "training 28.09%: 0.617. Loss: 0.967117428779602\n",
      "training 28.15%: 0.617. Loss: 2.072227954864502\n",
      "training 28.21%: 0.617. Loss: 1.7786293029785156\n",
      "training 28.28%: 0.617. Loss: 1.535521149635315\n",
      "training 28.34%: 0.618. Loss: 1.603806495666504\n",
      "training 28.41%: 0.618. Loss: 1.389477014541626\n",
      "training 28.47%: 0.618. Loss: 1.4994375705718994\n",
      "training 28.53%: 0.618. Loss: 1.8865556716918945\n",
      "training 28.60%: 0.618. Loss: 1.4139906167984009\n",
      "training 28.66%: 0.618. Loss: 1.8236452341079712\n",
      "training 28.73%: 0.618. Loss: 1.426991581916809\n",
      "training 28.79%: 0.618. Loss: 1.4919734001159668\n",
      "training 28.85%: 0.618. Loss: 1.6781941652297974\n",
      "training 28.92%: 0.618. Loss: 1.6611135005950928\n",
      "training 28.98%: 0.618. Loss: 1.5848599672317505\n",
      "training 29.05%: 0.618. Loss: 1.4167338609695435\n",
      "training 29.11%: 0.618. Loss: 1.7421073913574219\n",
      "training 29.17%: 0.618. Loss: 1.2703757286071777\n",
      "training 29.24%: 0.617. Loss: 1.6302274465560913\n",
      "training 29.30%: 0.617. Loss: 1.4165139198303223\n",
      "training 29.37%: 0.618. Loss: 0.9859542846679688\n",
      "training 29.43%: 0.618. Loss: 1.3731142282485962\n",
      "training 29.49%: 0.618. Loss: 1.2997758388519287\n",
      "training 29.56%: 0.618. Loss: 1.9026106595993042\n",
      "training 29.62%: 0.618. Loss: 1.5032784938812256\n",
      "training 29.69%: 0.618. Loss: 0.8420956134796143\n",
      "training 29.75%: 0.618. Loss: 1.265951156616211\n",
      "training 29.81%: 0.618. Loss: 1.5810515880584717\n",
      "training 29.88%: 0.618. Loss: 1.5865635871887207\n",
      "training 29.94%: 0.618. Loss: 1.518619179725647\n",
      "training 30.01%: 0.618. Loss: 1.588067889213562\n",
      "training 30.07%: 0.618. Loss: 1.8943850994110107\n",
      "training 30.13%: 0.618. Loss: 1.8682690858840942\n",
      "training 30.20%: 0.618. Loss: 1.601148247718811\n",
      "training 30.26%: 0.618. Loss: 1.2136144638061523\n",
      "training 30.33%: 0.618. Loss: 1.7372779846191406\n",
      "training 30.39%: 0.618. Loss: 1.4966785907745361\n",
      "training 30.45%: 0.618. Loss: 1.7029532194137573\n",
      "training 30.52%: 0.618. Loss: 1.1333082914352417\n",
      "training 30.58%: 0.618. Loss: 1.056174397468567\n",
      "training 30.65%: 0.618. Loss: 1.5444310903549194\n",
      "training 30.71%: 0.618. Loss: 1.4395523071289062\n",
      "training 30.77%: 0.618. Loss: 1.4742035865783691\n",
      "training 30.84%: 0.618. Loss: 1.4804697036743164\n",
      "training 30.90%: 0.618. Loss: 1.9027125835418701\n",
      "training 30.97%: 0.618. Loss: 1.2859221696853638\n",
      "training 31.03%: 0.618. Loss: 1.4360120296478271\n",
      "training 31.09%: 0.618. Loss: 1.2345166206359863\n",
      "training 31.16%: 0.618. Loss: 1.3538711071014404\n",
      "training 31.22%: 0.618. Loss: 1.3532415628433228\n",
      "training 31.29%: 0.618. Loss: 1.85380220413208\n",
      "training 31.35%: 0.618. Loss: 1.7188318967819214\n",
      "training 31.41%: 0.618. Loss: 1.74244225025177\n",
      "training 31.48%: 0.618. Loss: 1.2565807104110718\n",
      "training 31.54%: 0.618. Loss: 1.7839739322662354\n",
      "training 31.61%: 0.618. Loss: 1.3721842765808105\n",
      "training 31.67%: 0.618. Loss: 1.5500833988189697\n",
      "training 31.73%: 0.618. Loss: 1.5211577415466309\n",
      "training 31.80%: 0.618. Loss: 1.8396211862564087\n",
      "training 31.86%: 0.618. Loss: 1.6464401483535767\n",
      "training 31.93%: 0.618. Loss: 1.2204911708831787\n",
      "training 31.99%: 0.618. Loss: 1.4811346530914307\n",
      "training 32.05%: 0.618. Loss: 1.5344706773757935\n",
      "training 32.12%: 0.618. Loss: 1.3194648027420044\n",
      "training 32.18%: 0.618. Loss: 1.2126100063323975\n",
      "training 32.25%: 0.618. Loss: 1.2108982801437378\n",
      "training 32.31%: 0.618. Loss: 1.5886690616607666\n",
      "training 32.37%: 0.618. Loss: 1.8817377090454102\n",
      "training 32.44%: 0.618. Loss: 1.487304449081421\n",
      "training 32.50%: 0.618. Loss: 1.4815279245376587\n",
      "training 32.57%: 0.618. Loss: 1.343680739402771\n",
      "training 32.63%: 0.618. Loss: 1.5357357263565063\n",
      "training 32.69%: 0.618. Loss: 1.7789210081100464\n",
      "training 32.76%: 0.618. Loss: 1.4190537929534912\n",
      "training 32.82%: 0.618. Loss: 1.409974455833435\n",
      "training 32.89%: 0.618. Loss: 1.7894052267074585\n",
      "training 32.95%: 0.618. Loss: 1.360032081604004\n",
      "training 33.01%: 0.618. Loss: 1.8126198053359985\n",
      "training 33.08%: 0.618. Loss: 1.3589050769805908\n",
      "training 33.14%: 0.618. Loss: 1.4180119037628174\n",
      "training 33.21%: 0.618. Loss: 1.6088956594467163\n",
      "training 33.27%: 0.618. Loss: 1.9615801572799683\n",
      "training 33.33%: 0.618. Loss: 1.52108895778656\n",
      "training 33.40%: 0.618. Loss: 1.4449589252471924\n",
      "training 33.46%: 0.618. Loss: 1.7053159475326538\n",
      "training 33.53%: 0.618. Loss: 1.4565101861953735\n",
      "training 33.59%: 0.618. Loss: 1.584031105041504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 33.65%: 0.618. Loss: 1.3039594888687134\n",
      "training 33.72%: 0.618. Loss: 1.5266352891921997\n",
      "training 33.78%: 0.618. Loss: 1.3932685852050781\n",
      "training 33.85%: 0.618. Loss: 1.6747242212295532\n",
      "training 33.91%: 0.618. Loss: 1.6538257598876953\n",
      "training 33.97%: 0.618. Loss: 1.90138840675354\n",
      "training 34.04%: 0.618. Loss: 1.3993655443191528\n",
      "training 34.10%: 0.618. Loss: 1.64980947971344\n",
      "training 34.17%: 0.618. Loss: 1.6772828102111816\n",
      "training 34.23%: 0.618. Loss: 1.744947910308838\n",
      "training 34.29%: 0.618. Loss: 1.3589524030685425\n",
      "training 34.36%: 0.618. Loss: 1.281091332435608\n",
      "training 34.42%: 0.618. Loss: 1.541690468788147\n",
      "training 34.48%: 0.618. Loss: 1.8156181573867798\n",
      "training 34.55%: 0.618. Loss: 1.006076693534851\n",
      "training 34.61%: 0.618. Loss: 1.9429022073745728\n",
      "training 34.68%: 0.618. Loss: 1.145554542541504\n",
      "training 34.74%: 0.618. Loss: 1.4354462623596191\n",
      "training 34.80%: 0.618. Loss: 1.691536784172058\n",
      "training 34.87%: 0.618. Loss: 1.6478066444396973\n",
      "training 34.93%: 0.618. Loss: 1.688480257987976\n",
      "training 35.00%: 0.618. Loss: 1.4304777383804321\n",
      "training 35.06%: 0.618. Loss: 1.2912143468856812\n",
      "training 35.12%: 0.618. Loss: 1.4419211149215698\n",
      "training 35.19%: 0.618. Loss: 1.0175906419754028\n",
      "training 35.25%: 0.618. Loss: 1.8993489742279053\n",
      "training 35.32%: 0.618. Loss: 1.5590384006500244\n",
      "training 35.38%: 0.618. Loss: 2.3212532997131348\n",
      "training 35.44%: 0.618. Loss: 1.5900318622589111\n",
      "training 35.51%: 0.618. Loss: 1.3866888284683228\n",
      "training 35.57%: 0.617. Loss: 1.7427903413772583\n",
      "training 35.64%: 0.617. Loss: 1.7472463846206665\n",
      "training 35.70%: 0.617. Loss: 1.6148953437805176\n",
      "training 35.76%: 0.617. Loss: 1.5316869020462036\n",
      "training 35.83%: 0.617. Loss: 1.468126654624939\n",
      "training 35.89%: 0.617. Loss: 1.6782714128494263\n",
      "training 35.96%: 0.617. Loss: 1.2875699996948242\n",
      "training 36.02%: 0.617. Loss: 1.6527190208435059\n",
      "training 36.08%: 0.617. Loss: 1.507830023765564\n",
      "training 36.15%: 0.617. Loss: 1.4242963790893555\n",
      "training 36.21%: 0.617. Loss: 1.1081587076187134\n",
      "training 36.28%: 0.617. Loss: 1.7093875408172607\n",
      "training 36.34%: 0.617. Loss: 1.65437650680542\n",
      "training 36.40%: 0.617. Loss: 1.3057398796081543\n",
      "training 36.47%: 0.617. Loss: 1.4472774267196655\n",
      "training 36.53%: 0.617. Loss: 1.3892862796783447\n",
      "training 36.60%: 0.617. Loss: 1.5435562133789062\n",
      "training 36.66%: 0.617. Loss: 1.6701161861419678\n",
      "training 36.72%: 0.617. Loss: 1.876875638961792\n",
      "training 36.79%: 0.617. Loss: 1.3925292491912842\n",
      "training 36.85%: 0.617. Loss: 1.4555751085281372\n",
      "training 36.92%: 0.617. Loss: 1.4375693798065186\n",
      "training 36.98%: 0.617. Loss: 1.5576890707015991\n",
      "training 37.04%: 0.617. Loss: 1.3178119659423828\n",
      "training 37.11%: 0.617. Loss: 1.6976656913757324\n",
      "training 37.17%: 0.617. Loss: 1.637143850326538\n",
      "training 37.24%: 0.617. Loss: 1.4225996732711792\n",
      "training 37.30%: 0.617. Loss: 1.4480334520339966\n",
      "training 37.36%: 0.617. Loss: 1.7730005979537964\n",
      "training 37.43%: 0.617. Loss: 1.5565472841262817\n",
      "training 37.49%: 0.617. Loss: 1.3848425149917603\n",
      "training 37.56%: 0.617. Loss: 1.853039026260376\n",
      "training 37.62%: 0.617. Loss: 1.6351819038391113\n",
      "training 37.68%: 0.617. Loss: 1.7825688123703003\n",
      "training 37.75%: 0.617. Loss: 1.7011241912841797\n",
      "training 37.81%: 0.617. Loss: 1.5867842435836792\n",
      "training 37.88%: 0.617. Loss: 1.892548680305481\n",
      "training 37.94%: 0.617. Loss: 1.5991384983062744\n",
      "training 38.00%: 0.617. Loss: 1.6399232149124146\n",
      "training 38.07%: 0.616. Loss: 1.9616127014160156\n",
      "training 38.13%: 0.616. Loss: 1.9384393692016602\n",
      "training 38.20%: 0.616. Loss: 1.5791857242584229\n",
      "training 38.26%: 0.616. Loss: 1.5667109489440918\n",
      "training 38.32%: 0.616. Loss: 1.4845200777053833\n",
      "training 38.39%: 0.616. Loss: 1.5874364376068115\n",
      "training 38.45%: 0.616. Loss: 1.6313413381576538\n",
      "training 38.52%: 0.616. Loss: 1.402625322341919\n",
      "training 38.58%: 0.616. Loss: 1.4693577289581299\n",
      "training 38.64%: 0.616. Loss: 1.3932676315307617\n",
      "training 38.71%: 0.617. Loss: 1.3281620740890503\n",
      "training 38.77%: 0.617. Loss: 1.252168893814087\n",
      "training 38.84%: 0.616. Loss: 1.7744743824005127\n",
      "training 38.90%: 0.616. Loss: 1.9647711515426636\n",
      "training 38.96%: 0.617. Loss: 0.7710505127906799\n",
      "training 39.03%: 0.617. Loss: 1.3593004941940308\n",
      "training 39.09%: 0.617. Loss: 1.556080937385559\n",
      "training 39.16%: 0.617. Loss: 1.7394177913665771\n",
      "training 39.22%: 0.617. Loss: 2.118875741958618\n",
      "training 39.28%: 0.617. Loss: 1.3953440189361572\n",
      "training 39.35%: 0.617. Loss: 1.5193560123443604\n",
      "training 39.41%: 0.617. Loss: 1.3986810445785522\n",
      "training 39.48%: 0.617. Loss: 2.3014416694641113\n",
      "training 39.54%: 0.617. Loss: 1.5394765138626099\n",
      "training 39.60%: 0.616. Loss: 2.159393787384033\n",
      "training 39.67%: 0.616. Loss: 1.943246603012085\n",
      "training 39.73%: 0.616. Loss: 1.9288697242736816\n",
      "training 39.80%: 0.616. Loss: 1.3043769598007202\n",
      "training 39.86%: 0.616. Loss: 1.8796069622039795\n",
      "training 39.92%: 0.616. Loss: 1.9656305313110352\n",
      "training 39.99%: 0.616. Loss: 1.5299036502838135\n",
      "training 40.05%: 0.616. Loss: 1.3009963035583496\n",
      "training 40.12%: 0.616. Loss: 1.4629007577896118\n",
      "training 40.18%: 0.616. Loss: 1.937896728515625\n",
      "training 40.24%: 0.616. Loss: 1.2106826305389404\n",
      "training 40.31%: 0.616. Loss: 1.4513838291168213\n",
      "training 40.37%: 0.616. Loss: 1.1444673538208008\n",
      "training 40.44%: 0.616. Loss: 1.8876644372940063\n",
      "training 40.50%: 0.616. Loss: 1.2010419368743896\n",
      "training 40.56%: 0.616. Loss: 1.3580515384674072\n",
      "training 40.63%: 0.616. Loss: 1.401940941810608\n",
      "training 40.69%: 0.616. Loss: 1.5669877529144287\n",
      "training 40.75%: 0.616. Loss: 1.83024263381958\n",
      "training 40.82%: 0.616. Loss: 1.6447607278823853\n",
      "training 40.88%: 0.616. Loss: 1.5424187183380127\n",
      "training 40.95%: 0.616. Loss: 1.2206465005874634\n",
      "training 41.01%: 0.617. Loss: 1.5262619256973267\n",
      "training 41.07%: 0.617. Loss: 1.3397867679595947\n",
      "training 41.14%: 0.617. Loss: 1.1847195625305176\n",
      "training 41.20%: 0.617. Loss: 1.9439795017242432\n",
      "training 41.27%: 0.616. Loss: 1.809018850326538\n",
      "training 41.33%: 0.617. Loss: 1.3313541412353516\n",
      "training 41.39%: 0.617. Loss: 1.5142878293991089\n",
      "training 41.46%: 0.617. Loss: 1.2136400938034058\n",
      "training 41.52%: 0.617. Loss: 1.4736722707748413\n",
      "training 41.59%: 0.617. Loss: 1.2714842557907104\n",
      "training 41.65%: 0.617. Loss: 1.7796820402145386\n",
      "training 41.71%: 0.617. Loss: 1.4765045642852783\n",
      "training 41.78%: 0.617. Loss: 1.7637567520141602\n",
      "training 41.84%: 0.617. Loss: 1.9157912731170654\n",
      "training 41.91%: 0.617. Loss: 1.6458687782287598\n",
      "training 41.97%: 0.617. Loss: 1.6522526741027832\n",
      "training 42.03%: 0.617. Loss: 1.658634066581726\n",
      "training 42.10%: 0.617. Loss: 1.1432547569274902\n",
      "training 42.16%: 0.617. Loss: 1.4052292108535767\n",
      "training 42.23%: 0.617. Loss: 1.6261242628097534\n",
      "training 42.29%: 0.617. Loss: 1.1311132907867432\n",
      "training 42.35%: 0.616. Loss: 1.6892430782318115\n",
      "training 42.42%: 0.617. Loss: 1.398973822593689\n",
      "training 42.48%: 0.616. Loss: 2.1011669635772705\n",
      "training 42.55%: 0.616. Loss: 1.4444345235824585\n",
      "training 42.61%: 0.616. Loss: 1.4863944053649902\n",
      "training 42.67%: 0.616. Loss: 1.8163255453109741\n",
      "training 42.74%: 0.616. Loss: 1.0993833541870117\n",
      "training 42.80%: 0.616. Loss: 1.971758484840393\n",
      "training 42.87%: 0.616. Loss: 1.5707882642745972\n",
      "training 42.93%: 0.616. Loss: 1.2643389701843262\n",
      "training 42.99%: 0.616. Loss: 1.7057534456253052\n",
      "training 43.06%: 0.616. Loss: 0.958285927772522\n",
      "training 43.12%: 0.617. Loss: 1.1786211729049683\n",
      "training 43.19%: 0.617. Loss: 1.5222992897033691\n",
      "training 43.25%: 0.617. Loss: 1.4191910028457642\n",
      "training 43.31%: 0.617. Loss: 1.4430018663406372\n",
      "training 43.38%: 0.617. Loss: 1.7119613885879517\n",
      "training 43.44%: 0.617. Loss: 1.3257170915603638\n",
      "training 43.51%: 0.617. Loss: 1.7324495315551758\n",
      "training 43.57%: 0.617. Loss: 1.4338325262069702\n",
      "training 43.63%: 0.617. Loss: 1.4871336221694946\n",
      "training 43.70%: 0.617. Loss: 1.3201251029968262\n",
      "training 43.76%: 0.617. Loss: 1.2630610466003418\n",
      "training 43.83%: 0.617. Loss: 2.101494789123535\n",
      "training 43.89%: 0.616. Loss: 1.728774905204773\n",
      "training 43.95%: 0.616. Loss: 1.5207048654556274\n",
      "training 44.02%: 0.616. Loss: 1.4207448959350586\n",
      "training 44.08%: 0.616. Loss: 1.8217964172363281\n",
      "training 44.15%: 0.616. Loss: 1.5131031274795532\n",
      "training 44.21%: 0.616. Loss: 1.5214555263519287\n",
      "training 44.27%: 0.616. Loss: 1.3736437559127808\n",
      "training 44.34%: 0.616. Loss: 1.84550940990448\n",
      "training 44.40%: 0.616. Loss: 1.5142271518707275\n",
      "training 44.47%: 0.616. Loss: 1.4842181205749512\n",
      "training 44.53%: 0.616. Loss: 1.286106824874878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 44.59%: 0.616. Loss: 2.317777395248413\n",
      "training 44.66%: 0.616. Loss: 1.0757529735565186\n",
      "training 44.72%: 0.616. Loss: 1.7774020433425903\n",
      "training 44.79%: 0.616. Loss: 1.241099238395691\n",
      "training 44.85%: 0.616. Loss: 1.6678400039672852\n",
      "training 44.91%: 0.616. Loss: 2.0188162326812744\n",
      "training 44.98%: 0.616. Loss: 1.3175055980682373\n",
      "training 45.04%: 0.616. Loss: 1.8155784606933594\n",
      "training 45.11%: 0.616. Loss: 1.462782382965088\n",
      "training 45.17%: 0.616. Loss: 1.584275484085083\n",
      "training 45.23%: 0.616. Loss: 1.8299407958984375\n",
      "training 45.30%: 0.616. Loss: 1.8566676378250122\n",
      "training 45.36%: 0.616. Loss: 1.4027732610702515\n",
      "training 45.43%: 0.616. Loss: 1.9409632682800293\n",
      "training 45.49%: 0.616. Loss: 1.4830286502838135\n",
      "training 45.55%: 0.616. Loss: 1.4013183116912842\n",
      "training 45.62%: 0.616. Loss: 1.4431917667388916\n",
      "training 45.68%: 0.616. Loss: 1.5084689855575562\n",
      "training 45.75%: 0.616. Loss: 1.3214423656463623\n",
      "training 45.81%: 0.616. Loss: 1.5958529710769653\n",
      "training 45.87%: 0.616. Loss: 1.23511803150177\n",
      "training 45.94%: 0.616. Loss: 1.4879225492477417\n",
      "training 46.00%: 0.616. Loss: 1.5244140625\n",
      "training 46.07%: 0.616. Loss: 1.9563486576080322\n",
      "training 46.13%: 0.616. Loss: 1.050891399383545\n",
      "training 46.19%: 0.616. Loss: 1.8629626035690308\n",
      "training 46.26%: 0.616. Loss: 1.5108954906463623\n",
      "training 46.32%: 0.616. Loss: 1.3213728666305542\n",
      "training 46.39%: 0.616. Loss: 1.7344141006469727\n",
      "training 46.45%: 0.616. Loss: 1.701481819152832\n",
      "training 46.51%: 0.616. Loss: 1.631821632385254\n",
      "training 46.58%: 0.616. Loss: 1.3843005895614624\n",
      "training 46.64%: 0.616. Loss: 1.4512885808944702\n",
      "training 46.71%: 0.616. Loss: 1.9024763107299805\n",
      "training 46.77%: 0.616. Loss: 1.802096962928772\n",
      "training 46.83%: 0.616. Loss: 1.5564157962799072\n",
      "training 46.90%: 0.616. Loss: 1.694270372390747\n",
      "training 46.96%: 0.616. Loss: 1.2558372020721436\n",
      "training 47.02%: 0.616. Loss: 1.559056282043457\n",
      "training 47.09%: 0.616. Loss: 1.6365357637405396\n",
      "training 47.15%: 0.616. Loss: 1.6584689617156982\n",
      "training 47.22%: 0.616. Loss: 1.5842559337615967\n",
      "training 47.28%: 0.616. Loss: 1.6021790504455566\n",
      "training 47.34%: 0.616. Loss: 1.723146915435791\n",
      "training 47.41%: 0.616. Loss: 1.3753705024719238\n",
      "training 47.47%: 0.616. Loss: 1.5620213747024536\n",
      "training 47.54%: 0.616. Loss: 1.767820119857788\n",
      "training 47.60%: 0.616. Loss: 1.5677070617675781\n",
      "training 47.66%: 0.616. Loss: 1.3721932172775269\n",
      "training 47.73%: 0.615. Loss: 2.1953415870666504\n",
      "training 47.79%: 0.615. Loss: 1.6747431755065918\n",
      "training 47.86%: 0.615. Loss: 1.819749116897583\n",
      "training 47.92%: 0.615. Loss: 1.2674223184585571\n",
      "training 47.98%: 0.615. Loss: 1.3436886072158813\n",
      "training 48.05%: 0.615. Loss: 2.1191015243530273\n",
      "training 48.11%: 0.615. Loss: 1.9610073566436768\n",
      "training 48.18%: 0.615. Loss: 1.9784857034683228\n",
      "training 48.24%: 0.615. Loss: 1.6331136226654053\n",
      "training 48.30%: 0.615. Loss: 1.8532016277313232\n",
      "training 48.37%: 0.615. Loss: 1.415906310081482\n",
      "training 48.43%: 0.615. Loss: 1.6661665439605713\n",
      "training 48.50%: 0.615. Loss: 1.2117193937301636\n",
      "training 48.56%: 0.615. Loss: 1.384878158569336\n",
      "training 48.62%: 0.615. Loss: 1.6125714778900146\n",
      "training 48.69%: 0.615. Loss: 1.234060525894165\n",
      "training 48.75%: 0.615. Loss: 1.4880218505859375\n",
      "training 48.82%: 0.615. Loss: 1.6918178796768188\n",
      "training 48.88%: 0.615. Loss: 1.6132917404174805\n",
      "training 48.94%: 0.615. Loss: 1.7178583145141602\n",
      "training 49.01%: 0.615. Loss: 1.960402488708496\n",
      "training 49.07%: 0.615. Loss: 1.4406507015228271\n",
      "training 49.14%: 0.615. Loss: 1.4372998476028442\n",
      "training 49.20%: 0.615. Loss: 1.6687697172164917\n",
      "training 49.26%: 0.615. Loss: 1.3216745853424072\n",
      "training 49.33%: 0.615. Loss: 1.9015378952026367\n",
      "training 49.39%: 0.615. Loss: 1.7170780897140503\n",
      "training 49.46%: 0.614. Loss: 1.7406489849090576\n",
      "training 49.52%: 0.615. Loss: 1.4043270349502563\n",
      "training 49.58%: 0.614. Loss: 2.211247205734253\n",
      "training 49.65%: 0.614. Loss: 1.786481261253357\n",
      "training 49.71%: 0.614. Loss: 1.6090071201324463\n",
      "training 49.78%: 0.614. Loss: 1.8904967308044434\n",
      "training 49.84%: 0.614. Loss: 1.23362135887146\n",
      "training 49.90%: 0.614. Loss: 1.0648117065429688\n",
      "training 49.97%: 0.614. Loss: 1.6537038087844849\n",
      "training 50.03%: 0.614. Loss: 1.5975606441497803\n",
      "training 50.10%: 0.614. Loss: 1.5251795053482056\n",
      "training 50.16%: 0.614. Loss: 1.3511332273483276\n",
      "training 50.22%: 0.614. Loss: 1.4402745962142944\n",
      "training 50.29%: 0.614. Loss: 1.6120299100875854\n",
      "training 50.35%: 0.614. Loss: 1.679004192352295\n",
      "training 50.42%: 0.614. Loss: 1.4543737173080444\n",
      "training 50.48%: 0.614. Loss: 1.473868489265442\n",
      "training 50.54%: 0.614. Loss: 2.0512313842773438\n",
      "training 50.61%: 0.614. Loss: 1.5678550004959106\n",
      "training 50.67%: 0.614. Loss: 1.9696844816207886\n",
      "training 50.74%: 0.614. Loss: 1.3988521099090576\n",
      "training 50.80%: 0.614. Loss: 1.444242000579834\n",
      "training 50.86%: 0.614. Loss: 1.4286582469940186\n",
      "training 50.93%: 0.614. Loss: 1.567914605140686\n",
      "training 50.99%: 0.614. Loss: 1.499659538269043\n",
      "training 51.06%: 0.614. Loss: 1.4344860315322876\n",
      "training 51.12%: 0.614. Loss: 1.6715790033340454\n",
      "training 51.18%: 0.614. Loss: 1.6942596435546875\n",
      "training 51.25%: 0.614. Loss: 1.6722184419631958\n",
      "training 51.31%: 0.614. Loss: 1.202620506286621\n",
      "training 51.38%: 0.614. Loss: 1.6376900672912598\n",
      "training 51.44%: 0.614. Loss: 1.6031556129455566\n",
      "training 51.50%: 0.614. Loss: 1.400524616241455\n",
      "training 51.57%: 0.614. Loss: 1.4558587074279785\n",
      "training 51.63%: 0.614. Loss: 1.3349061012268066\n",
      "training 51.70%: 0.614. Loss: 1.5437556505203247\n",
      "training 51.76%: 0.614. Loss: 1.2876002788543701\n",
      "training 51.82%: 0.614. Loss: 1.4027202129364014\n",
      "training 51.89%: 0.614. Loss: 1.6428436040878296\n",
      "training 51.95%: 0.614. Loss: 1.2207939624786377\n",
      "training 52.02%: 0.614. Loss: 2.0062050819396973\n",
      "training 52.08%: 0.614. Loss: 2.0521061420440674\n",
      "training 52.14%: 0.614. Loss: 1.452931523323059\n",
      "training 52.21%: 0.614. Loss: 1.5121594667434692\n",
      "training 52.27%: 0.614. Loss: 1.4448862075805664\n",
      "training 52.34%: 0.614. Loss: 1.2408872842788696\n",
      "training 52.40%: 0.614. Loss: 1.6781773567199707\n",
      "training 52.46%: 0.614. Loss: 0.9104121327400208\n",
      "training 52.53%: 0.614. Loss: 1.8804312944412231\n",
      "training 52.59%: 0.614. Loss: 1.5773200988769531\n",
      "training 52.66%: 0.614. Loss: 1.6490832567214966\n",
      "training 52.72%: 0.614. Loss: 1.3144296407699585\n",
      "training 52.78%: 0.614. Loss: 1.2907389402389526\n",
      "training 52.85%: 0.614. Loss: 1.3624303340911865\n",
      "training 52.91%: 0.614. Loss: 1.4419443607330322\n",
      "training 52.98%: 0.614. Loss: 1.2561979293823242\n",
      "training 53.04%: 0.614. Loss: 1.415504813194275\n",
      "training 53.10%: 0.614. Loss: 1.5092778205871582\n",
      "training 53.17%: 0.614. Loss: 2.31532883644104\n",
      "training 53.23%: 0.614. Loss: 1.6225732564926147\n",
      "training 53.29%: 0.614. Loss: 1.7110427618026733\n",
      "training 53.36%: 0.614. Loss: 1.4213027954101562\n",
      "training 53.42%: 0.614. Loss: 1.6116501092910767\n",
      "training 53.49%: 0.614. Loss: 1.3243470191955566\n",
      "training 53.55%: 0.614. Loss: 2.0017967224121094\n",
      "training 53.61%: 0.614. Loss: 1.2775115966796875\n",
      "training 53.68%: 0.614. Loss: 1.1840487718582153\n",
      "training 53.74%: 0.614. Loss: 1.3999041318893433\n",
      "training 53.81%: 0.614. Loss: 1.7864106893539429\n",
      "training 53.87%: 0.614. Loss: 1.5393441915512085\n",
      "training 53.93%: 0.614. Loss: 1.43073570728302\n",
      "training 54.00%: 0.614. Loss: 1.9070090055465698\n",
      "training 54.06%: 0.614. Loss: 2.023986339569092\n",
      "training 54.13%: 0.614. Loss: 1.2219566106796265\n",
      "training 54.19%: 0.614. Loss: 1.809775948524475\n",
      "training 54.25%: 0.614. Loss: 1.944400668144226\n",
      "training 54.32%: 0.614. Loss: 1.345097541809082\n",
      "training 54.38%: 0.614. Loss: 2.0530505180358887\n",
      "training 54.45%: 0.614. Loss: 1.625623345375061\n",
      "training 54.51%: 0.614. Loss: 1.6534513235092163\n",
      "training 54.57%: 0.614. Loss: 1.5303090810775757\n",
      "training 54.64%: 0.614. Loss: 1.2942373752593994\n",
      "training 54.70%: 0.614. Loss: 1.870758056640625\n",
      "training 54.77%: 0.614. Loss: 1.6026699542999268\n",
      "training 54.83%: 0.614. Loss: 1.2063692808151245\n",
      "training 54.89%: 0.614. Loss: 1.6885952949523926\n",
      "training 54.96%: 0.614. Loss: 2.273651361465454\n",
      "training 55.02%: 0.614. Loss: 2.038527488708496\n",
      "training 55.09%: 0.614. Loss: 1.3069719076156616\n",
      "training 55.15%: 0.614. Loss: 1.4999494552612305\n",
      "training 55.21%: 0.614. Loss: 1.7962650060653687\n",
      "training 55.28%: 0.614. Loss: 1.7739595174789429\n",
      "training 55.34%: 0.614. Loss: 1.6070165634155273\n",
      "training 55.41%: 0.614. Loss: 1.580653429031372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 55.47%: 0.614. Loss: 1.446872591972351\n",
      "training 55.53%: 0.614. Loss: 1.6619240045547485\n",
      "training 55.60%: 0.614. Loss: 1.2858340740203857\n",
      "training 55.66%: 0.614. Loss: 1.5435022115707397\n",
      "training 55.73%: 0.614. Loss: 1.2826871871948242\n",
      "training 55.79%: 0.614. Loss: 2.0310230255126953\n",
      "training 55.85%: 0.614. Loss: 1.7352505922317505\n",
      "training 55.92%: 0.614. Loss: 1.4349498748779297\n",
      "training 55.98%: 0.614. Loss: 1.5494766235351562\n",
      "training 56.05%: 0.613. Loss: 1.5167690515518188\n",
      "training 56.11%: 0.613. Loss: 1.6550474166870117\n",
      "training 56.17%: 0.613. Loss: 1.498162865638733\n",
      "training 56.24%: 0.614. Loss: 1.263780117034912\n",
      "training 56.30%: 0.613. Loss: 1.8719748258590698\n",
      "training 56.37%: 0.613. Loss: 1.5478100776672363\n",
      "training 56.43%: 0.613. Loss: 1.4948941469192505\n",
      "training 56.49%: 0.613. Loss: 1.3625075817108154\n",
      "training 56.56%: 0.613. Loss: 2.140620708465576\n",
      "training 56.62%: 0.613. Loss: 1.7237348556518555\n",
      "training 56.69%: 0.613. Loss: 1.5159330368041992\n",
      "training 56.75%: 0.613. Loss: 1.6741291284561157\n",
      "training 56.81%: 0.613. Loss: 1.5438214540481567\n",
      "training 56.88%: 0.613. Loss: 1.8404508829116821\n",
      "training 56.94%: 0.613. Loss: 1.7567908763885498\n",
      "training 57.01%: 0.613. Loss: 1.0152292251586914\n",
      "training 57.07%: 0.613. Loss: 2.061317205429077\n",
      "training 57.13%: 0.613. Loss: 1.9820570945739746\n",
      "training 57.20%: 0.613. Loss: 1.5473979711532593\n",
      "training 57.26%: 0.613. Loss: 1.399856686592102\n",
      "training 57.33%: 0.613. Loss: 1.6223973035812378\n",
      "training 57.39%: 0.613. Loss: 1.6449520587921143\n",
      "training 57.45%: 0.613. Loss: 1.208755612373352\n",
      "training 57.52%: 0.613. Loss: 1.918877124786377\n",
      "training 57.58%: 0.613. Loss: 2.011819839477539\n",
      "training 57.65%: 0.613. Loss: 1.5549805164337158\n",
      "training 57.71%: 0.613. Loss: 1.1543840169906616\n",
      "training 57.77%: 0.613. Loss: 1.370356559753418\n",
      "training 57.84%: 0.613. Loss: 1.454440951347351\n",
      "training 57.90%: 0.613. Loss: 1.3191767930984497\n",
      "training 57.97%: 0.613. Loss: 1.8091403245925903\n",
      "training 58.03%: 0.613. Loss: 1.342085361480713\n",
      "training 58.09%: 0.613. Loss: 1.3523766994476318\n",
      "training 58.16%: 0.613. Loss: 1.2656400203704834\n",
      "training 58.22%: 0.613. Loss: 1.5558286905288696\n",
      "training 58.29%: 0.613. Loss: 1.866439938545227\n",
      "training 58.35%: 0.613. Loss: 1.5734347105026245\n",
      "training 58.41%: 0.613. Loss: 1.5892447233200073\n",
      "training 58.48%: 0.613. Loss: 0.977898895740509\n",
      "training 58.54%: 0.613. Loss: 1.2410595417022705\n",
      "training 58.61%: 0.613. Loss: 1.2388629913330078\n",
      "training 58.67%: 0.613. Loss: 1.442176103591919\n",
      "training 58.73%: 0.613. Loss: 1.963220238685608\n",
      "training 58.80%: 0.613. Loss: 1.117096185684204\n",
      "training 58.86%: 0.613. Loss: 1.258616328239441\n",
      "training 58.93%: 0.613. Loss: 1.6776984930038452\n",
      "training 58.99%: 0.613. Loss: 1.447420358657837\n",
      "training 59.05%: 0.613. Loss: 1.6964341402053833\n",
      "training 59.12%: 0.613. Loss: 1.4338151216506958\n",
      "training 59.18%: 0.613. Loss: 1.5188956260681152\n",
      "training 59.25%: 0.613. Loss: 1.3282440900802612\n",
      "training 59.31%: 0.613. Loss: 1.6450936794281006\n",
      "training 59.37%: 0.613. Loss: 1.5891664028167725\n",
      "training 59.44%: 0.613. Loss: 2.00715970993042\n",
      "training 59.50%: 0.613. Loss: 1.445528268814087\n",
      "training 59.56%: 0.613. Loss: 1.496868371963501\n",
      "training 59.63%: 0.613. Loss: 1.4895579814910889\n",
      "training 59.69%: 0.613. Loss: 1.1051855087280273\n",
      "training 59.76%: 0.613. Loss: 1.5168343782424927\n",
      "training 59.82%: 0.613. Loss: 1.6271060705184937\n",
      "training 59.88%: 0.613. Loss: 1.4220165014266968\n",
      "training 59.95%: 0.613. Loss: 1.4835199117660522\n",
      "training 60.01%: 0.613. Loss: 1.8143160343170166\n",
      "training 60.08%: 0.613. Loss: 1.43202805519104\n",
      "training 60.14%: 0.613. Loss: 1.260694980621338\n",
      "training 60.20%: 0.613. Loss: 1.8113023042678833\n",
      "training 60.27%: 0.613. Loss: 1.744268774986267\n",
      "training 60.33%: 0.613. Loss: 1.0380865335464478\n",
      "training 60.40%: 0.613. Loss: 1.1739460229873657\n",
      "training 60.46%: 0.613. Loss: 1.9126429557800293\n",
      "training 60.52%: 0.613. Loss: 1.754119634628296\n",
      "training 60.59%: 0.613. Loss: 1.4049782752990723\n",
      "training 60.65%: 0.613. Loss: 2.1482043266296387\n",
      "training 60.72%: 0.613. Loss: 2.026597261428833\n",
      "training 60.78%: 0.613. Loss: 1.8472636938095093\n",
      "training 60.84%: 0.613. Loss: 1.083174228668213\n",
      "training 60.91%: 0.613. Loss: 1.5758146047592163\n",
      "training 60.97%: 0.613. Loss: 1.8653738498687744\n",
      "training 61.04%: 0.613. Loss: 2.0424909591674805\n",
      "training 61.10%: 0.613. Loss: 1.7475687265396118\n",
      "training 61.16%: 0.613. Loss: 1.5682486295700073\n",
      "training 61.23%: 0.613. Loss: 1.5421122312545776\n",
      "training 61.29%: 0.613. Loss: 1.884106993675232\n",
      "training 61.36%: 0.613. Loss: 1.44927179813385\n",
      "training 61.42%: 0.613. Loss: 1.3807839155197144\n",
      "training 61.48%: 0.613. Loss: 1.8309482336044312\n",
      "training 61.55%: 0.613. Loss: 1.6337060928344727\n",
      "training 61.61%: 0.613. Loss: 1.247519612312317\n",
      "training 61.68%: 0.613. Loss: 1.8094621896743774\n",
      "training 61.74%: 0.613. Loss: 1.5793489217758179\n",
      "training 61.80%: 0.612. Loss: 1.692107915878296\n",
      "training 61.87%: 0.612. Loss: 1.9059123992919922\n",
      "training 61.93%: 0.612. Loss: 1.6478376388549805\n",
      "training 62.00%: 0.612. Loss: 1.5581930875778198\n",
      "training 62.06%: 0.612. Loss: 2.0543997287750244\n",
      "training 62.12%: 0.612. Loss: 1.6536939144134521\n",
      "training 62.19%: 0.612. Loss: 1.660764217376709\n",
      "training 62.25%: 0.612. Loss: 1.9157897233963013\n",
      "training 62.32%: 0.612. Loss: 1.66610586643219\n",
      "training 62.38%: 0.612. Loss: 1.4725221395492554\n",
      "training 62.44%: 0.612. Loss: 1.0421711206436157\n",
      "training 62.51%: 0.612. Loss: 1.539448857307434\n",
      "training 62.57%: 0.612. Loss: 1.750290036201477\n",
      "training 62.64%: 0.612. Loss: 1.5961124897003174\n",
      "training 62.70%: 0.612. Loss: 1.8638782501220703\n",
      "training 62.76%: 0.612. Loss: 1.763744592666626\n",
      "training 62.83%: 0.612. Loss: 1.9131319522857666\n",
      "training 62.89%: 0.612. Loss: 1.4597574472427368\n",
      "training 62.96%: 0.612. Loss: 1.8739951848983765\n",
      "training 63.02%: 0.612. Loss: 1.4582933187484741\n",
      "training 63.08%: 0.612. Loss: 1.7049342393875122\n",
      "training 63.15%: 0.612. Loss: 1.812191367149353\n",
      "training 63.21%: 0.612. Loss: 1.938137173652649\n",
      "training 63.28%: 0.612. Loss: 1.5415313243865967\n",
      "training 63.34%: 0.612. Loss: 1.4694998264312744\n",
      "training 63.40%: 0.612. Loss: 1.5883808135986328\n",
      "training 63.47%: 0.612. Loss: 1.7837131023406982\n",
      "training 63.53%: 0.612. Loss: 1.3238639831542969\n",
      "training 63.60%: 0.612. Loss: 1.1930063962936401\n",
      "training 63.66%: 0.612. Loss: 1.046586513519287\n",
      "training 63.72%: 0.612. Loss: 1.5071038007736206\n",
      "training 63.79%: 0.612. Loss: 1.9135980606079102\n",
      "training 63.85%: 0.612. Loss: 1.5331380367279053\n",
      "training 63.92%: 0.612. Loss: 1.496296763420105\n",
      "training 63.98%: 0.612. Loss: 1.782407522201538\n",
      "training 64.04%: 0.612. Loss: 1.7113304138183594\n",
      "training 64.11%: 0.612. Loss: 1.3444011211395264\n",
      "training 64.17%: 0.612. Loss: 1.4643536806106567\n",
      "training 64.24%: 0.612. Loss: 1.5657708644866943\n",
      "training 64.30%: 0.612. Loss: 1.6212118864059448\n",
      "training 64.36%: 0.612. Loss: 1.402695894241333\n",
      "training 64.43%: 0.612. Loss: 1.682187557220459\n",
      "training 64.49%: 0.612. Loss: 1.935782790184021\n",
      "training 64.56%: 0.612. Loss: 1.657486915588379\n",
      "training 64.62%: 0.612. Loss: 1.670243263244629\n",
      "training 64.68%: 0.612. Loss: 1.2185556888580322\n",
      "training 64.75%: 0.612. Loss: 1.275618314743042\n",
      "training 64.81%: 0.612. Loss: 1.7548503875732422\n",
      "training 64.88%: 0.612. Loss: 1.4579931497573853\n",
      "training 64.94%: 0.612. Loss: 1.486154556274414\n",
      "training 65.00%: 0.612. Loss: 1.4273841381072998\n",
      "training 65.07%: 0.612. Loss: 1.719917893409729\n",
      "training 65.13%: 0.612. Loss: 1.3259896039962769\n",
      "training 65.20%: 0.612. Loss: 1.5624566078186035\n",
      "training 65.26%: 0.612. Loss: 1.3059512376785278\n",
      "training 65.32%: 0.612. Loss: 1.4644197225570679\n",
      "training 65.39%: 0.612. Loss: 1.6925055980682373\n",
      "training 65.45%: 0.612. Loss: 2.0455455780029297\n",
      "training 65.52%: 0.612. Loss: 1.7448581457138062\n",
      "training 65.58%: 0.612. Loss: 1.3175231218338013\n",
      "training 65.64%: 0.612. Loss: 1.787821888923645\n",
      "training 65.71%: 0.612. Loss: 1.5282198190689087\n",
      "training 65.77%: 0.612. Loss: 1.9523375034332275\n",
      "training 65.83%: 0.612. Loss: 1.865317940711975\n",
      "training 65.90%: 0.612. Loss: 1.5729900598526\n",
      "training 65.96%: 0.612. Loss: 1.6595689058303833\n",
      "training 66.03%: 0.612. Loss: 1.6864992380142212\n",
      "training 66.09%: 0.612. Loss: 1.4001286029815674\n",
      "training 66.15%: 0.612. Loss: 1.7368894815444946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 66.22%: 0.612. Loss: 1.373365044593811\n",
      "training 66.28%: 0.612. Loss: 1.4075977802276611\n",
      "training 66.35%: 0.612. Loss: 1.2443290948867798\n",
      "training 66.41%: 0.612. Loss: 1.8556760549545288\n",
      "training 66.47%: 0.612. Loss: 1.6394978761672974\n",
      "training 66.54%: 0.612. Loss: 1.6176342964172363\n",
      "training 66.60%: 0.612. Loss: 1.4947837591171265\n",
      "training 66.67%: 0.612. Loss: 1.6004737615585327\n",
      "training 66.73%: 0.611. Loss: 1.7835016250610352\n",
      "training 66.79%: 0.611. Loss: 1.607103943824768\n",
      "training 66.86%: 0.611. Loss: 1.4760349988937378\n",
      "training 66.92%: 0.611. Loss: 1.7032032012939453\n",
      "training 66.99%: 0.611. Loss: 1.9587163925170898\n",
      "training 67.05%: 0.611. Loss: 1.3829410076141357\n",
      "training 67.11%: 0.611. Loss: 1.538759469985962\n",
      "training 67.18%: 0.611. Loss: 1.279873251914978\n",
      "training 67.24%: 0.611. Loss: 1.3426415920257568\n",
      "training 67.31%: 0.612. Loss: 1.7080543041229248\n",
      "training 67.37%: 0.611. Loss: 1.6084486246109009\n",
      "training 67.43%: 0.611. Loss: 1.7491053342819214\n",
      "training 67.50%: 0.611. Loss: 1.7158030271530151\n",
      "training 67.56%: 0.611. Loss: 1.6494286060333252\n",
      "training 67.63%: 0.611. Loss: 1.517498254776001\n",
      "training 67.69%: 0.611. Loss: 1.8126214742660522\n",
      "training 67.75%: 0.611. Loss: 1.7853318452835083\n",
      "training 67.82%: 0.611. Loss: 1.998328447341919\n",
      "training 67.88%: 0.611. Loss: 1.9851462841033936\n",
      "training 67.95%: 0.611. Loss: 1.7746816873550415\n",
      "training 68.01%: 0.611. Loss: 1.383520245552063\n",
      "training 68.07%: 0.611. Loss: 1.1342599391937256\n",
      "training 68.14%: 0.611. Loss: 1.4555410146713257\n",
      "training 68.20%: 0.611. Loss: 1.434096336364746\n",
      "training 68.27%: 0.611. Loss: 1.4425655603408813\n",
      "training 68.33%: 0.611. Loss: 1.4800658226013184\n",
      "training 68.39%: 0.611. Loss: 1.7340023517608643\n",
      "training 68.46%: 0.611. Loss: 1.7407870292663574\n",
      "training 68.52%: 0.611. Loss: 1.276145339012146\n",
      "training 68.59%: 0.611. Loss: 1.9604228734970093\n",
      "training 68.65%: 0.611. Loss: 1.5376861095428467\n",
      "training 68.71%: 0.611. Loss: 1.1196982860565186\n",
      "training 68.78%: 0.611. Loss: 1.4406590461730957\n",
      "training 68.84%: 0.611. Loss: 1.040291428565979\n",
      "training 68.91%: 0.611. Loss: 1.128913164138794\n",
      "training 68.97%: 0.611. Loss: 1.5796983242034912\n",
      "training 69.03%: 0.611. Loss: 1.6921894550323486\n",
      "training 69.10%: 0.611. Loss: 2.0986766815185547\n",
      "training 69.16%: 0.611. Loss: 1.3833030462265015\n",
      "training 69.23%: 0.611. Loss: 1.496170997619629\n",
      "training 69.29%: 0.611. Loss: 2.1432759761810303\n",
      "training 69.35%: 0.611. Loss: 1.506442666053772\n",
      "training 69.42%: 0.611. Loss: 1.5739624500274658\n",
      "training 69.48%: 0.611. Loss: 1.5269562005996704\n",
      "training 69.55%: 0.611. Loss: 1.3601230382919312\n",
      "training 69.61%: 0.611. Loss: 1.7604702711105347\n",
      "training 69.67%: 0.611. Loss: 1.646094560623169\n",
      "training 69.74%: 0.611. Loss: 1.4444692134857178\n",
      "training 69.80%: 0.611. Loss: 1.8158714771270752\n",
      "training 69.87%: 0.611. Loss: 1.6190547943115234\n",
      "training 69.93%: 0.611. Loss: 1.9711480140686035\n",
      "training 69.99%: 0.611. Loss: 1.522254467010498\n",
      "training 70.06%: 0.611. Loss: 1.583275318145752\n",
      "training 70.12%: 0.611. Loss: 1.1421895027160645\n",
      "training 70.19%: 0.611. Loss: 1.4403204917907715\n",
      "training 70.25%: 0.611. Loss: 1.5769339799880981\n",
      "training 70.31%: 0.611. Loss: 1.4268512725830078\n",
      "training 70.38%: 0.611. Loss: 1.3684223890304565\n",
      "training 70.44%: 0.611. Loss: 1.5591706037521362\n",
      "training 70.51%: 0.611. Loss: 1.6586098670959473\n",
      "training 70.57%: 0.611. Loss: 1.395598292350769\n",
      "training 70.63%: 0.611. Loss: 1.6051864624023438\n",
      "training 70.70%: 0.611. Loss: 1.2301568984985352\n",
      "training 70.76%: 0.611. Loss: 2.1331188678741455\n",
      "training 70.83%: 0.611. Loss: 2.21474289894104\n",
      "training 70.89%: 0.611. Loss: 1.4572057723999023\n",
      "training 70.95%: 0.611. Loss: 1.8074398040771484\n",
      "training 71.02%: 0.611. Loss: 1.9362040758132935\n",
      "training 71.08%: 0.611. Loss: 1.6526061296463013\n",
      "training 71.15%: 0.611. Loss: 1.6272239685058594\n",
      "training 71.21%: 0.611. Loss: 1.115993618965149\n",
      "training 71.27%: 0.611. Loss: 1.4222066402435303\n",
      "training 71.34%: 0.611. Loss: 1.5338287353515625\n",
      "training 71.40%: 0.611. Loss: 1.5404417514801025\n",
      "training 71.47%: 0.611. Loss: 1.5892523527145386\n",
      "training 71.53%: 0.611. Loss: 1.7835935354232788\n",
      "training 71.59%: 0.611. Loss: 1.8046238422393799\n",
      "training 71.66%: 0.611. Loss: 1.3805346488952637\n",
      "training 71.72%: 0.611. Loss: 1.512209415435791\n",
      "training 71.79%: 0.611. Loss: 1.6430139541625977\n",
      "training 71.85%: 0.611. Loss: 1.3907766342163086\n",
      "training 71.91%: 0.611. Loss: 1.6041545867919922\n",
      "training 71.98%: 0.611. Loss: 1.755505084991455\n",
      "training 72.04%: 0.611. Loss: 1.1516859531402588\n",
      "training 72.10%: 0.611. Loss: 1.6136866807937622\n",
      "training 72.17%: 0.611. Loss: 1.3754016160964966\n",
      "training 72.23%: 0.611. Loss: 1.7162100076675415\n",
      "training 72.30%: 0.611. Loss: 2.2759273052215576\n",
      "training 72.36%: 0.611. Loss: 1.484723687171936\n",
      "training 72.42%: 0.611. Loss: 1.7279812097549438\n",
      "training 72.49%: 0.611. Loss: 1.615493893623352\n",
      "training 72.55%: 0.611. Loss: 1.3145759105682373\n",
      "training 72.62%: 0.611. Loss: 1.907096266746521\n",
      "training 72.68%: 0.611. Loss: 1.3427222967147827\n",
      "training 72.74%: 0.611. Loss: 1.8324065208435059\n",
      "training 72.81%: 0.611. Loss: 1.6101614236831665\n",
      "training 72.87%: 0.611. Loss: 1.2944496870040894\n",
      "training 72.94%: 0.611. Loss: 1.6797137260437012\n",
      "training 73.00%: 0.611. Loss: 1.8468430042266846\n",
      "training 73.06%: 0.611. Loss: 1.5715147256851196\n",
      "training 73.13%: 0.610. Loss: 1.7401171922683716\n",
      "training 73.19%: 0.611. Loss: 1.3238520622253418\n",
      "training 73.26%: 0.611. Loss: 1.3941926956176758\n",
      "training 73.32%: 0.610. Loss: 1.3151510953903198\n",
      "training 73.38%: 0.611. Loss: 1.210422158241272\n",
      "training 73.45%: 0.611. Loss: 1.4645761251449585\n",
      "training 73.51%: 0.610. Loss: 1.4838547706604004\n",
      "training 73.58%: 0.610. Loss: 1.8427101373672485\n",
      "training 73.64%: 0.610. Loss: 1.4949700832366943\n",
      "training 73.70%: 0.610. Loss: 1.293416142463684\n",
      "training 73.77%: 0.610. Loss: 1.6871143579483032\n",
      "training 73.83%: 0.610. Loss: 1.5656403303146362\n",
      "training 73.90%: 0.610. Loss: 1.7857149839401245\n",
      "training 73.96%: 0.610. Loss: 1.3546210527420044\n",
      "training 74.02%: 0.610. Loss: 1.5742411613464355\n",
      "training 74.09%: 0.610. Loss: 1.6458873748779297\n",
      "training 74.15%: 0.610. Loss: 1.5668425559997559\n",
      "training 74.22%: 0.610. Loss: 1.313217043876648\n",
      "training 74.28%: 0.610. Loss: 1.6622720956802368\n",
      "training 74.34%: 0.610. Loss: 1.432724118232727\n",
      "training 74.41%: 0.610. Loss: 1.879030466079712\n",
      "training 74.47%: 0.610. Loss: 1.5037646293640137\n",
      "training 74.54%: 0.610. Loss: 1.5006558895111084\n",
      "training 74.60%: 0.610. Loss: 1.6647435426712036\n",
      "training 74.66%: 0.610. Loss: 1.2773468494415283\n",
      "training 74.73%: 0.610. Loss: 1.2226128578186035\n",
      "training 74.79%: 0.610. Loss: 1.7233288288116455\n",
      "training 74.86%: 0.610. Loss: 1.5959446430206299\n",
      "training 74.92%: 0.610. Loss: 1.484666109085083\n",
      "training 74.98%: 0.610. Loss: 1.260873794555664\n",
      "training 75.05%: 0.610. Loss: 1.4899321794509888\n",
      "training 75.11%: 0.610. Loss: 1.2584558725357056\n",
      "training 75.18%: 0.610. Loss: 2.0463273525238037\n",
      "training 75.24%: 0.610. Loss: 1.6050111055374146\n",
      "training 75.30%: 0.610. Loss: 1.5870481729507446\n",
      "training 75.37%: 0.610. Loss: 1.3914692401885986\n",
      "training 75.43%: 0.610. Loss: 1.6499428749084473\n",
      "training 75.50%: 0.610. Loss: 1.731330156326294\n",
      "training 75.56%: 0.610. Loss: 1.4745339155197144\n",
      "training 75.62%: 0.610. Loss: 1.5823222398757935\n",
      "training 75.69%: 0.610. Loss: 1.9417667388916016\n",
      "training 75.75%: 0.610. Loss: 1.3705661296844482\n",
      "training 75.82%: 0.610. Loss: 1.3311433792114258\n",
      "training 75.88%: 0.610. Loss: 1.4479833841323853\n",
      "training 75.94%: 0.610. Loss: 1.7044142484664917\n",
      "training 76.01%: 0.610. Loss: 1.7881232500076294\n",
      "training 76.07%: 0.610. Loss: 1.3750767707824707\n",
      "training 76.14%: 0.610. Loss: 1.93023681640625\n",
      "training 76.20%: 0.610. Loss: 1.307119369506836\n",
      "training 76.26%: 0.610. Loss: 1.9224683046340942\n",
      "training 76.33%: 0.610. Loss: 1.293955683708191\n",
      "training 76.39%: 0.610. Loss: 1.6560909748077393\n",
      "training 76.46%: 0.610. Loss: 1.9130847454071045\n",
      "training 76.52%: 0.610. Loss: 1.7821110486984253\n",
      "training 76.58%: 0.610. Loss: 2.024282217025757\n",
      "training 76.65%: 0.610. Loss: 1.807260274887085\n",
      "training 76.71%: 0.610. Loss: 1.6493158340454102\n",
      "training 76.78%: 0.610. Loss: 1.4583262205123901\n",
      "training 76.84%: 0.610. Loss: 1.8420400619506836\n",
      "training 76.90%: 0.610. Loss: 1.561188817024231\n",
      "training 76.97%: 0.610. Loss: 1.8532181978225708\n",
      "training 77.03%: 0.610. Loss: 1.5567922592163086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 77.10%: 0.610. Loss: 1.574661135673523\n",
      "training 77.16%: 0.610. Loss: 1.6285817623138428\n",
      "training 77.22%: 0.610. Loss: 1.5087913274765015\n",
      "training 77.29%: 0.610. Loss: 1.5672762393951416\n",
      "training 77.35%: 0.610. Loss: 1.3285390138626099\n",
      "training 77.42%: 0.610. Loss: 1.4705836772918701\n",
      "training 77.48%: 0.610. Loss: 1.5897160768508911\n",
      "training 77.54%: 0.610. Loss: 1.4069709777832031\n",
      "training 77.61%: 0.610. Loss: 1.7463452816009521\n",
      "training 77.67%: 0.610. Loss: 1.7524967193603516\n",
      "training 77.74%: 0.610. Loss: 1.8832966089248657\n",
      "training 77.80%: 0.610. Loss: 1.641631007194519\n",
      "training 77.86%: 0.610. Loss: 1.3492645025253296\n",
      "training 77.93%: 0.610. Loss: 1.5712202787399292\n",
      "training 77.99%: 0.610. Loss: 1.5866719484329224\n",
      "training 78.06%: 0.610. Loss: 1.2134997844696045\n",
      "training 78.12%: 0.610. Loss: 1.557664155960083\n",
      "training 78.18%: 0.610. Loss: 1.6064956188201904\n",
      "training 78.25%: 0.610. Loss: 1.407062292098999\n",
      "training 78.31%: 0.610. Loss: 1.5294444561004639\n",
      "training 78.37%: 0.610. Loss: 1.7390861511230469\n",
      "training 78.44%: 0.610. Loss: 1.2538901567459106\n",
      "training 78.50%: 0.610. Loss: 1.5536288022994995\n",
      "training 78.57%: 0.610. Loss: 1.2296000719070435\n",
      "training 78.63%: 0.610. Loss: 1.9912668466567993\n",
      "training 78.69%: 0.610. Loss: 1.3595833778381348\n",
      "training 78.76%: 0.610. Loss: 1.8505836725234985\n",
      "training 78.82%: 0.610. Loss: 1.2892464399337769\n",
      "training 78.89%: 0.610. Loss: 1.5291863679885864\n",
      "training 78.95%: 0.610. Loss: 1.4047749042510986\n",
      "training 79.01%: 0.610. Loss: 1.5193507671356201\n",
      "training 79.08%: 0.610. Loss: 1.6207749843597412\n",
      "training 79.14%: 0.610. Loss: 1.2893092632293701\n",
      "training 79.21%: 0.610. Loss: 1.1846249103546143\n",
      "training 79.27%: 0.610. Loss: 1.742429494857788\n",
      "training 79.33%: 0.610. Loss: 1.4722820520401\n",
      "training 79.40%: 0.610. Loss: 1.6955212354660034\n",
      "training 79.46%: 0.610. Loss: 1.9992996454238892\n",
      "training 79.53%: 0.610. Loss: 1.697609782218933\n",
      "training 79.59%: 0.610. Loss: 1.4542878866195679\n",
      "training 79.65%: 0.610. Loss: 1.2140384912490845\n",
      "training 79.72%: 0.610. Loss: 1.6843388080596924\n",
      "training 79.78%: 0.610. Loss: 1.3290058374404907\n",
      "training 79.85%: 0.610. Loss: 1.548633098602295\n",
      "training 79.91%: 0.610. Loss: 1.4675148725509644\n",
      "training 79.97%: 0.610. Loss: 1.471877098083496\n",
      "training 80.04%: 0.610. Loss: 1.5822161436080933\n",
      "training 80.10%: 0.610. Loss: 1.5746614933013916\n",
      "training 80.17%: 0.610. Loss: 1.3530833721160889\n",
      "training 80.23%: 0.610. Loss: 1.6644725799560547\n",
      "training 80.29%: 0.610. Loss: 1.7017990350723267\n",
      "training 80.36%: 0.610. Loss: 1.6853573322296143\n",
      "training 80.42%: 0.610. Loss: 2.0173888206481934\n",
      "training 80.49%: 0.610. Loss: 1.555601716041565\n",
      "training 80.55%: 0.610. Loss: 1.279495120048523\n",
      "training 80.61%: 0.610. Loss: 1.5909767150878906\n",
      "training 80.68%: 0.610. Loss: 1.2580962181091309\n",
      "training 80.74%: 0.610. Loss: 1.5590342283248901\n",
      "training 80.81%: 0.610. Loss: 1.623654842376709\n",
      "training 80.87%: 0.610. Loss: 1.7226260900497437\n",
      "training 80.93%: 0.610. Loss: 1.5518577098846436\n",
      "training 81.00%: 0.610. Loss: 1.4945533275604248\n",
      "training 81.06%: 0.610. Loss: 1.5766130685806274\n",
      "training 81.13%: 0.610. Loss: 1.7432416677474976\n",
      "training 81.19%: 0.610. Loss: 1.7992465496063232\n",
      "training 81.25%: 0.610. Loss: 0.9667513966560364\n",
      "training 81.32%: 0.610. Loss: 1.5693281888961792\n",
      "training 81.38%: 0.610. Loss: 1.7851440906524658\n",
      "training 81.45%: 0.610. Loss: 1.6819045543670654\n",
      "training 81.51%: 0.610. Loss: 1.652549386024475\n",
      "training 81.57%: 0.610. Loss: 1.2890820503234863\n",
      "training 81.64%: 0.610. Loss: 1.5736544132232666\n",
      "training 81.70%: 0.610. Loss: 1.459534764289856\n",
      "training 81.77%: 0.610. Loss: 1.7775729894638062\n",
      "training 81.83%: 0.610. Loss: 1.8039696216583252\n",
      "training 81.89%: 0.610. Loss: 1.6962155103683472\n",
      "training 81.96%: 0.610. Loss: 1.5094070434570312\n",
      "training 82.02%: 0.610. Loss: 1.5923712253570557\n",
      "training 82.09%: 0.610. Loss: 1.0841233730316162\n",
      "training 82.15%: 0.610. Loss: 1.446975588798523\n",
      "training 82.21%: 0.610. Loss: 1.8221464157104492\n",
      "training 82.28%: 0.610. Loss: 0.8455031514167786\n",
      "training 82.34%: 0.610. Loss: 1.6655620336532593\n",
      "training 82.41%: 0.610. Loss: 1.415731430053711\n",
      "training 82.47%: 0.610. Loss: 1.5617161989212036\n",
      "training 82.53%: 0.610. Loss: 1.6605827808380127\n",
      "training 82.60%: 0.610. Loss: 1.2479690313339233\n",
      "training 82.66%: 0.610. Loss: 1.5447945594787598\n",
      "training 82.73%: 0.610. Loss: 1.4338123798370361\n",
      "training 82.79%: 0.610. Loss: 1.5875149965286255\n",
      "training 82.85%: 0.610. Loss: 1.7371517419815063\n",
      "training 82.92%: 0.610. Loss: 1.5771948099136353\n",
      "training 82.98%: 0.610. Loss: 1.6554267406463623\n",
      "training 83.05%: 0.610. Loss: 1.9745017290115356\n",
      "training 83.11%: 0.610. Loss: 1.2932738065719604\n",
      "training 83.17%: 0.610. Loss: 1.6860177516937256\n",
      "training 83.24%: 0.610. Loss: 1.902407169342041\n",
      "training 83.30%: 0.610. Loss: 1.6017892360687256\n",
      "training 83.37%: 0.610. Loss: 1.799213171005249\n",
      "training 83.43%: 0.610. Loss: 1.4988410472869873\n",
      "training 83.49%: 0.610. Loss: 1.7765867710113525\n",
      "training 83.56%: 0.610. Loss: 1.8104281425476074\n",
      "training 83.62%: 0.610. Loss: 1.2932909727096558\n",
      "training 83.69%: 0.610. Loss: 1.4739364385604858\n",
      "training 83.75%: 0.610. Loss: 1.6918374300003052\n",
      "training 83.81%: 0.610. Loss: 1.6640489101409912\n",
      "training 83.88%: 0.610. Loss: 1.58796226978302\n",
      "training 83.94%: 0.610. Loss: 1.2458423376083374\n",
      "training 84.01%: 0.610. Loss: 1.9477897882461548\n",
      "training 84.07%: 0.610. Loss: 1.8028570413589478\n",
      "training 84.13%: 0.610. Loss: 1.5988857746124268\n",
      "training 84.20%: 0.610. Loss: 1.5363422632217407\n",
      "training 84.26%: 0.610. Loss: 1.5690207481384277\n",
      "training 84.33%: 0.609. Loss: 1.5630724430084229\n",
      "training 84.39%: 0.609. Loss: 1.7880085706710815\n",
      "training 84.45%: 0.609. Loss: 1.7147464752197266\n",
      "training 84.52%: 0.609. Loss: 1.5056579113006592\n",
      "training 84.58%: 0.609. Loss: 1.4900017976760864\n",
      "training 84.64%: 0.609. Loss: 1.7514092922210693\n",
      "training 84.71%: 0.609. Loss: 1.4737051725387573\n",
      "training 84.77%: 0.609. Loss: 1.7641355991363525\n",
      "training 84.84%: 0.609. Loss: 1.7369052171707153\n",
      "training 84.90%: 0.609. Loss: 1.7456183433532715\n",
      "training 84.96%: 0.609. Loss: 1.4673612117767334\n",
      "training 85.03%: 0.609. Loss: 1.6904008388519287\n",
      "training 85.09%: 0.609. Loss: 1.7309954166412354\n",
      "training 85.16%: 0.609. Loss: 2.0036275386810303\n",
      "training 85.22%: 0.609. Loss: 1.8291631937026978\n",
      "training 85.28%: 0.609. Loss: 1.9387608766555786\n",
      "training 85.35%: 0.609. Loss: 1.5730496644973755\n",
      "training 85.41%: 0.609. Loss: 1.3886020183563232\n",
      "training 85.48%: 0.609. Loss: 1.823150873184204\n",
      "training 85.54%: 0.609. Loss: 1.54094660282135\n",
      "training 85.60%: 0.609. Loss: 1.542236566543579\n",
      "training 85.67%: 0.609. Loss: 1.2145767211914062\n",
      "training 85.73%: 0.609. Loss: 1.7930136919021606\n",
      "training 85.80%: 0.609. Loss: 1.7440952062606812\n",
      "training 85.86%: 0.609. Loss: 1.174573302268982\n",
      "training 85.92%: 0.609. Loss: 1.5047404766082764\n",
      "training 85.99%: 0.609. Loss: 1.4305692911148071\n",
      "training 86.05%: 0.609. Loss: 1.5203877687454224\n",
      "training 86.12%: 0.609. Loss: 1.7496625185012817\n",
      "training 86.18%: 0.609. Loss: 1.0159900188446045\n",
      "training 86.24%: 0.609. Loss: 1.297182559967041\n",
      "training 86.31%: 0.609. Loss: 1.7102526426315308\n",
      "training 86.37%: 0.609. Loss: 1.7202287912368774\n",
      "training 86.44%: 0.609. Loss: 1.865639090538025\n",
      "training 86.50%: 0.609. Loss: 1.2567530870437622\n",
      "training 86.56%: 0.609. Loss: 1.8223857879638672\n",
      "training 86.63%: 0.609. Loss: 1.1541597843170166\n",
      "training 86.69%: 0.609. Loss: 1.5981934070587158\n",
      "training 86.76%: 0.609. Loss: 2.133474111557007\n",
      "training 86.82%: 0.609. Loss: 1.3078560829162598\n",
      "training 86.88%: 0.609. Loss: 1.6793068647384644\n",
      "training 86.95%: 0.609. Loss: 1.9629794359207153\n",
      "training 87.01%: 0.609. Loss: 1.1568711996078491\n",
      "training 87.08%: 0.609. Loss: 0.8284912705421448\n",
      "training 87.14%: 0.609. Loss: 1.5263516902923584\n",
      "training 87.20%: 0.609. Loss: 1.4601722955703735\n",
      "training 87.27%: 0.609. Loss: 1.8108564615249634\n",
      "training 87.33%: 0.609. Loss: 1.7275636196136475\n",
      "training 87.40%: 0.609. Loss: 1.4443179368972778\n",
      "training 87.46%: 0.609. Loss: 1.5848057270050049\n",
      "training 87.52%: 0.609. Loss: 1.3251323699951172\n",
      "training 87.59%: 0.609. Loss: 1.8594144582748413\n",
      "training 87.65%: 0.609. Loss: 1.4436362981796265\n",
      "training 87.72%: 0.609. Loss: 1.5528637170791626\n",
      "training 87.78%: 0.609. Loss: 1.9536783695220947\n",
      "training 87.84%: 0.609. Loss: 1.4372164011001587\n",
      "training 87.91%: 0.609. Loss: 1.356851577758789\n",
      "training 87.97%: 0.609. Loss: 1.350536584854126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 88.04%: 0.610. Loss: 1.1796529293060303\n",
      "training 88.10%: 0.610. Loss: 1.5374387502670288\n",
      "training 88.16%: 0.610. Loss: 1.5224692821502686\n",
      "training 88.23%: 0.610. Loss: 1.8110941648483276\n",
      "training 88.29%: 0.610. Loss: 1.306856632232666\n",
      "training 88.36%: 0.609. Loss: 2.026590347290039\n",
      "training 88.42%: 0.610. Loss: 1.9436231851577759\n",
      "training 88.48%: 0.609. Loss: 1.6520905494689941\n",
      "training 88.55%: 0.610. Loss: 1.656808853149414\n",
      "training 88.61%: 0.609. Loss: 1.9824165105819702\n",
      "training 88.68%: 0.609. Loss: 1.4273364543914795\n",
      "training 88.74%: 0.609. Loss: 1.1507489681243896\n",
      "training 88.80%: 0.609. Loss: 1.653591275215149\n",
      "training 88.87%: 0.609. Loss: 1.4369382858276367\n",
      "training 88.93%: 0.609. Loss: 1.684952735900879\n",
      "training 89.00%: 0.609. Loss: 1.8279094696044922\n",
      "training 89.06%: 0.609. Loss: 1.554703950881958\n",
      "training 89.12%: 0.609. Loss: 1.3896300792694092\n",
      "training 89.19%: 0.609. Loss: 1.1373374462127686\n",
      "training 89.25%: 0.609. Loss: 1.5361381769180298\n",
      "training 89.32%: 0.609. Loss: 1.8563599586486816\n",
      "training 89.38%: 0.609. Loss: 1.6725844144821167\n",
      "training 89.44%: 0.609. Loss: 2.0344765186309814\n",
      "training 89.51%: 0.609. Loss: 2.0375916957855225\n",
      "training 89.57%: 0.609. Loss: 1.3126341104507446\n",
      "training 89.64%: 0.609. Loss: 1.9190261363983154\n",
      "training 89.70%: 0.609. Loss: 1.2710047960281372\n",
      "training 89.76%: 0.609. Loss: 1.4920309782028198\n",
      "training 89.83%: 0.609. Loss: 1.1838029623031616\n",
      "training 89.89%: 0.609. Loss: 1.4650593996047974\n",
      "training 89.96%: 0.609. Loss: 1.724945306777954\n",
      "training 90.02%: 0.609. Loss: 1.8319294452667236\n",
      "training 90.08%: 0.609. Loss: 1.579817295074463\n",
      "training 90.15%: 0.609. Loss: 1.4646415710449219\n",
      "training 90.21%: 0.609. Loss: 1.8107192516326904\n",
      "training 90.28%: 0.609. Loss: 1.0932687520980835\n",
      "training 90.34%: 0.609. Loss: 1.1966283321380615\n",
      "training 90.40%: 0.609. Loss: 2.023512363433838\n",
      "training 90.47%: 0.609. Loss: 1.4528698921203613\n",
      "training 90.53%: 0.609. Loss: 1.968016266822815\n",
      "training 90.60%: 0.609. Loss: 2.246943950653076\n",
      "training 90.66%: 0.609. Loss: 1.572104573249817\n",
      "training 90.72%: 0.609. Loss: 1.6367332935333252\n",
      "training 90.79%: 0.609. Loss: 2.1211109161376953\n",
      "training 90.85%: 0.609. Loss: 1.4388115406036377\n",
      "training 90.91%: 0.609. Loss: 1.687896728515625\n",
      "training 90.98%: 0.609. Loss: 1.3907419443130493\n",
      "training 91.04%: 0.609. Loss: 1.2194552421569824\n",
      "training 91.11%: 0.609. Loss: 1.5203803777694702\n",
      "training 91.17%: 0.609. Loss: 1.7468934059143066\n",
      "training 91.23%: 0.609. Loss: 1.716083288192749\n",
      "training 91.30%: 0.609. Loss: 1.2242282629013062\n",
      "training 91.36%: 0.609. Loss: 2.110405445098877\n",
      "training 91.43%: 0.609. Loss: 1.6023330688476562\n",
      "training 91.49%: 0.609. Loss: 1.5305391550064087\n",
      "training 91.55%: 0.609. Loss: 1.250659465789795\n",
      "training 91.62%: 0.609. Loss: 1.9610133171081543\n",
      "training 91.68%: 0.609. Loss: 1.7681853771209717\n",
      "training 91.75%: 0.609. Loss: 1.9514412879943848\n",
      "training 91.81%: 0.609. Loss: 2.0284862518310547\n",
      "training 91.87%: 0.609. Loss: 1.7690566778182983\n",
      "training 91.94%: 0.609. Loss: 1.6657856702804565\n",
      "training 92.00%: 0.608. Loss: 1.820761799812317\n",
      "training 92.07%: 0.608. Loss: 1.699015498161316\n",
      "training 92.13%: 0.609. Loss: 1.3290588855743408\n",
      "training 92.19%: 0.608. Loss: 1.6071979999542236\n",
      "training 92.26%: 0.608. Loss: 1.7170329093933105\n",
      "training 92.32%: 0.608. Loss: 1.6739346981048584\n",
      "training 92.39%: 0.608. Loss: 1.8457810878753662\n",
      "training 92.45%: 0.608. Loss: 1.41654372215271\n",
      "training 92.51%: 0.608. Loss: 1.895670771598816\n",
      "training 92.58%: 0.608. Loss: 1.64618980884552\n",
      "training 92.64%: 0.608. Loss: 1.6913373470306396\n",
      "training 92.71%: 0.608. Loss: 1.4928131103515625\n",
      "training 92.77%: 0.608. Loss: 1.3892797231674194\n",
      "training 92.83%: 0.608. Loss: 1.7929515838623047\n",
      "training 92.90%: 0.608. Loss: 1.8648396730422974\n",
      "training 92.96%: 0.608. Loss: 1.7398219108581543\n",
      "training 93.03%: 0.608. Loss: 1.5148636102676392\n",
      "training 93.09%: 0.608. Loss: 1.364685297012329\n",
      "training 93.15%: 0.608. Loss: 1.6952099800109863\n",
      "training 93.22%: 0.608. Loss: 1.3561580181121826\n",
      "training 93.28%: 0.608. Loss: 1.2286491394042969\n",
      "training 93.35%: 0.608. Loss: 1.6965713500976562\n",
      "training 93.41%: 0.608. Loss: 1.3187659978866577\n",
      "training 93.47%: 0.608. Loss: 1.3222324848175049\n",
      "training 93.54%: 0.608. Loss: 1.8079012632369995\n",
      "training 93.60%: 0.608. Loss: 1.9294480085372925\n",
      "training 93.67%: 0.608. Loss: 1.6295610666275024\n",
      "training 93.73%: 0.608. Loss: 1.6175228357315063\n",
      "training 93.79%: 0.608. Loss: 1.5438361167907715\n",
      "training 93.86%: 0.608. Loss: 2.1419506072998047\n",
      "training 93.92%: 0.608. Loss: 1.2901793718338013\n",
      "training 93.99%: 0.608. Loss: 1.648471474647522\n",
      "training 94.05%: 0.608. Loss: 2.0486466884613037\n",
      "training 94.11%: 0.608. Loss: 1.5641669034957886\n",
      "training 94.18%: 0.608. Loss: 1.4654513597488403\n",
      "training 94.24%: 0.608. Loss: 1.5684700012207031\n",
      "training 94.31%: 0.608. Loss: 1.3342430591583252\n",
      "training 94.37%: 0.608. Loss: 2.215566635131836\n",
      "training 94.43%: 0.608. Loss: 1.6122806072235107\n",
      "training 94.50%: 0.608. Loss: 1.874433159828186\n",
      "training 94.56%: 0.608. Loss: 1.5393391847610474\n",
      "training 94.63%: 0.608. Loss: 1.6031585931777954\n",
      "training 94.69%: 0.608. Loss: 1.508605718612671\n",
      "training 94.75%: 0.608. Loss: 1.81477952003479\n",
      "training 94.82%: 0.608. Loss: 1.5709096193313599\n",
      "training 94.88%: 0.608. Loss: 1.829355001449585\n",
      "training 94.95%: 0.608. Loss: 1.538118600845337\n",
      "training 95.01%: 0.608. Loss: 1.4907457828521729\n",
      "training 95.07%: 0.608. Loss: 1.3212060928344727\n",
      "training 95.14%: 0.608. Loss: 1.3338537216186523\n",
      "training 95.20%: 0.608. Loss: 1.2844171524047852\n",
      "training 95.27%: 0.608. Loss: 1.3431426286697388\n",
      "training 95.33%: 0.608. Loss: 1.6286158561706543\n",
      "training 95.39%: 0.608. Loss: 1.4122744798660278\n",
      "training 95.46%: 0.608. Loss: 1.565157413482666\n",
      "training 95.52%: 0.608. Loss: 1.8422963619232178\n",
      "training 95.59%: 0.608. Loss: 1.3416156768798828\n",
      "training 95.65%: 0.608. Loss: 1.8008865118026733\n",
      "training 95.71%: 0.608. Loss: 1.663887858390808\n",
      "training 95.78%: 0.608. Loss: 1.7680492401123047\n",
      "training 95.84%: 0.608. Loss: 1.9114141464233398\n",
      "training 95.91%: 0.608. Loss: 1.1463649272918701\n",
      "training 95.97%: 0.608. Loss: 1.3888795375823975\n",
      "training 96.03%: 0.608. Loss: 1.3949065208435059\n",
      "training 96.10%: 0.608. Loss: 1.7830448150634766\n",
      "training 96.16%: 0.608. Loss: 1.77329421043396\n",
      "training 96.23%: 0.608. Loss: 1.4358576536178589\n",
      "training 96.29%: 0.608. Loss: 1.5329718589782715\n",
      "training 96.35%: 0.608. Loss: 1.4003024101257324\n",
      "training 96.42%: 0.608. Loss: 1.682292103767395\n",
      "training 96.48%: 0.608. Loss: 1.7641860246658325\n",
      "training 96.55%: 0.608. Loss: 1.220236897468567\n",
      "training 96.61%: 0.608. Loss: 1.6952104568481445\n",
      "training 96.67%: 0.608. Loss: 1.9654146432876587\n",
      "training 96.74%: 0.608. Loss: 1.4245799779891968\n",
      "training 96.80%: 0.608. Loss: 1.8875367641448975\n",
      "training 96.87%: 0.608. Loss: 1.3889918327331543\n",
      "training 96.93%: 0.608. Loss: 1.5488312244415283\n",
      "training 96.99%: 0.608. Loss: 1.5231964588165283\n",
      "training 97.06%: 0.608. Loss: 1.7235499620437622\n",
      "training 97.12%: 0.608. Loss: 1.5561851263046265\n",
      "training 97.18%: 0.608. Loss: 1.3080356121063232\n",
      "training 97.25%: 0.608. Loss: 1.530873417854309\n",
      "training 97.31%: 0.608. Loss: 2.0045838356018066\n",
      "training 97.38%: 0.608. Loss: 1.5308239459991455\n",
      "training 97.44%: 0.608. Loss: 2.0217137336730957\n",
      "training 97.50%: 0.608. Loss: 1.5339890718460083\n",
      "training 97.57%: 0.608. Loss: 1.699884057044983\n",
      "training 97.63%: 0.608. Loss: 2.0885164737701416\n",
      "training 97.70%: 0.608. Loss: 1.311146855354309\n",
      "training 97.76%: 0.608. Loss: 1.1994240283966064\n",
      "training 97.82%: 0.608. Loss: 1.3472850322723389\n",
      "training 97.89%: 0.608. Loss: 1.2891134023666382\n",
      "training 97.95%: 0.608. Loss: 1.7665470838546753\n",
      "training 98.02%: 0.608. Loss: 1.313340663909912\n",
      "training 98.08%: 0.608. Loss: 1.4262539148330688\n",
      "training 98.14%: 0.608. Loss: 1.4052528142929077\n",
      "training 98.21%: 0.608. Loss: 1.5780616998672485\n",
      "training 98.27%: 0.608. Loss: 1.9002914428710938\n",
      "training 98.34%: 0.608. Loss: 1.1509090662002563\n",
      "training 98.40%: 0.608. Loss: 1.7661964893341064\n",
      "training 98.46%: 0.608. Loss: 1.8484578132629395\n",
      "training 98.53%: 0.608. Loss: 1.4299780130386353\n",
      "training 98.59%: 0.608. Loss: 1.7096928358078003\n",
      "training 98.66%: 0.608. Loss: 1.32913339138031\n",
      "training 98.72%: 0.608. Loss: 1.5671218633651733\n",
      "training 98.78%: 0.608. Loss: 1.5072919130325317\n",
      "training 98.85%: 0.608. Loss: 1.334757924079895\n",
      "training 98.91%: 0.608. Loss: 1.4412578344345093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 98.98%: 0.608. Loss: 1.4153566360473633\n",
      "training 99.04%: 0.608. Loss: 1.440999984741211\n",
      "training 99.10%: 0.608. Loss: 1.699569582939148\n",
      "training 99.17%: 0.608. Loss: 1.892052412033081\n",
      "training 99.23%: 0.608. Loss: 1.9319546222686768\n",
      "training 99.30%: 0.608. Loss: 1.5973892211914062\n",
      "training 99.36%: 0.608. Loss: 1.4914038181304932\n",
      "training 99.42%: 0.608. Loss: 1.710519552230835\n",
      "training 99.49%: 0.608. Loss: 1.308923363685608\n",
      "training 99.55%: 0.608. Loss: 1.4577622413635254\n",
      "training 99.62%: 0.608. Loss: 1.4190431833267212\n",
      "training 99.68%: 0.608. Loss: 1.655630350112915\n",
      "training 99.74%: 0.608. Loss: 2.2998385429382324\n",
      "training 99.81%: 0.608. Loss: 1.9075608253479004\n",
      "training 99.87%: 0.608. Loss: 1.115625023841858\n",
      "training 99.94%: 0.608. Loss: 1.4213824272155762\n",
      "val 0.00%: 0.609. Loss: 1.472926139831543\n",
      "val 0.64%: 0.547. Loss: 1.743808388710022\n",
      "val 1.27%: 0.573. Loss: 1.5154166221618652\n",
      "val 1.91%: 0.566. Loss: 1.6578642129898071\n",
      "val 2.55%: 0.559. Loss: 1.8628666400909424\n",
      "val 3.18%: 0.555. Loss: 1.6785959005355835\n",
      "val 3.82%: 0.560. Loss: 1.5700011253356934\n",
      "val 4.46%: 0.545. Loss: 1.9586094617843628\n",
      "val 5.10%: 0.543. Loss: 1.722525954246521\n",
      "val 5.73%: 0.544. Loss: 1.8565435409545898\n",
      "val 6.37%: 0.541. Loss: 1.9917703866958618\n",
      "val 7.01%: 0.553. Loss: 1.3315620422363281\n",
      "val 7.64%: 0.552. Loss: 2.049313545227051\n",
      "val 8.28%: 0.551. Loss: 1.8484669923782349\n",
      "val 8.92%: 0.552. Loss: 1.8894927501678467\n",
      "val 9.55%: 0.551. Loss: 2.0639548301696777\n",
      "val 10.19%: 0.549. Loss: 2.0813076496124268\n",
      "val 10.83%: 0.552. Loss: 1.390135645866394\n",
      "val 11.46%: 0.553. Loss: 1.9433770179748535\n",
      "val 12.10%: 0.554. Loss: 1.7575693130493164\n",
      "val 12.74%: 0.556. Loss: 1.3054001331329346\n",
      "val 13.38%: 0.556. Loss: 1.5969974994659424\n",
      "val 14.01%: 0.556. Loss: 1.5187214612960815\n",
      "val 14.65%: 0.558. Loss: 1.6533992290496826\n",
      "val 15.29%: 0.559. Loss: 1.6956956386566162\n",
      "val 15.92%: 0.562. Loss: 1.5052354335784912\n",
      "val 16.56%: 0.565. Loss: 1.6727449893951416\n",
      "val 17.20%: 0.565. Loss: 1.6386953592300415\n",
      "val 17.83%: 0.565. Loss: 1.8058267831802368\n",
      "val 18.47%: 0.565. Loss: 1.8060287237167358\n",
      "val 19.11%: 0.565. Loss: 1.89887273311615\n",
      "val 19.75%: 0.564. Loss: 1.6615263223648071\n",
      "val 20.38%: 0.566. Loss: 1.5076299905776978\n",
      "val 21.02%: 0.569. Loss: 1.2843037843704224\n",
      "val 21.66%: 0.570. Loss: 1.5276713371276855\n",
      "val 22.29%: 0.569. Loss: 2.16806697845459\n",
      "val 22.93%: 0.567. Loss: 1.9808619022369385\n",
      "val 23.57%: 0.568. Loss: 1.3764753341674805\n",
      "val 24.20%: 0.569. Loss: 1.7773975133895874\n",
      "val 24.84%: 0.568. Loss: 1.8020727634429932\n",
      "val 25.48%: 0.566. Loss: 1.9610651731491089\n",
      "val 26.11%: 0.567. Loss: 1.70723295211792\n",
      "val 26.75%: 0.568. Loss: 1.7824794054031372\n",
      "val 27.39%: 0.568. Loss: 1.8131356239318848\n",
      "val 28.03%: 0.569. Loss: 1.520344853401184\n",
      "val 28.66%: 0.567. Loss: 1.974406361579895\n",
      "val 29.30%: 0.566. Loss: 2.0588395595550537\n",
      "val 29.94%: 0.568. Loss: 1.5793215036392212\n",
      "val 30.57%: 0.569. Loss: 1.4950379133224487\n",
      "val 31.21%: 0.569. Loss: 1.8002638816833496\n",
      "val 31.85%: 0.569. Loss: 1.7489854097366333\n",
      "val 32.48%: 0.569. Loss: 1.8252142667770386\n",
      "val 33.12%: 0.568. Loss: 1.6380248069763184\n",
      "val 33.76%: 0.569. Loss: 1.7518895864486694\n",
      "val 34.39%: 0.568. Loss: 1.9019322395324707\n",
      "val 35.03%: 0.569. Loss: 1.46378755569458\n",
      "val 35.67%: 0.569. Loss: 1.6782722473144531\n",
      "val 36.31%: 0.571. Loss: 1.1613773107528687\n",
      "val 36.94%: 0.572. Loss: 1.4484329223632812\n",
      "val 37.58%: 0.573. Loss: 2.000776529312134\n",
      "val 38.22%: 0.574. Loss: 1.7332488298416138\n",
      "val 38.85%: 0.574. Loss: 1.578084111213684\n",
      "val 39.49%: 0.573. Loss: 2.0991311073303223\n",
      "val 40.13%: 0.573. Loss: 1.896032452583313\n",
      "val 40.76%: 0.572. Loss: 2.0891246795654297\n",
      "val 41.40%: 0.572. Loss: 1.9430280923843384\n",
      "val 42.04%: 0.573. Loss: 1.6305941343307495\n",
      "val 42.68%: 0.573. Loss: 1.7338217496871948\n",
      "val 43.31%: 0.573. Loss: 1.7365827560424805\n",
      "val 43.95%: 0.573. Loss: 1.881173849105835\n",
      "val 44.59%: 0.575. Loss: 0.9359966516494751\n",
      "val 45.22%: 0.574. Loss: 1.9877816438674927\n",
      "val 45.86%: 0.574. Loss: 1.9069128036499023\n",
      "val 46.50%: 0.573. Loss: 2.05407977104187\n",
      "val 47.13%: 0.574. Loss: 1.660365104675293\n",
      "val 47.77%: 0.573. Loss: 2.073697805404663\n",
      "val 48.41%: 0.574. Loss: 1.47112238407135\n",
      "val 49.04%: 0.573. Loss: 2.145909547805786\n",
      "val 49.68%: 0.573. Loss: 1.8785837888717651\n",
      "val 50.32%: 0.571. Loss: 2.137577772140503\n",
      "val 50.96%: 0.572. Loss: 1.5003597736358643\n",
      "val 51.59%: 0.573. Loss: 1.562540888786316\n",
      "val 52.23%: 0.572. Loss: 2.0139572620391846\n",
      "val 52.87%: 0.572. Loss: 1.6012349128723145\n",
      "val 53.50%: 0.573. Loss: 1.4095269441604614\n",
      "val 54.14%: 0.573. Loss: 1.878355860710144\n",
      "val 54.78%: 0.573. Loss: 1.64344322681427\n",
      "val 55.41%: 0.573. Loss: 1.8105980157852173\n",
      "val 56.05%: 0.574. Loss: 1.6732097864151\n",
      "val 56.69%: 0.576. Loss: 1.250885009765625\n",
      "val 57.32%: 0.575. Loss: 1.4959391355514526\n",
      "val 57.96%: 0.575. Loss: 1.9591602087020874\n",
      "val 58.60%: 0.575. Loss: 1.502918004989624\n",
      "val 59.24%: 0.576. Loss: 1.3781390190124512\n",
      "val 59.87%: 0.577. Loss: 1.5890220403671265\n",
      "val 60.51%: 0.576. Loss: 1.9448662996292114\n",
      "val 61.15%: 0.577. Loss: 1.6878103017807007\n",
      "val 61.78%: 0.577. Loss: 1.4715214967727661\n",
      "val 62.42%: 0.578. Loss: 1.1593230962753296\n",
      "val 63.06%: 0.579. Loss: 1.2021757364273071\n",
      "val 63.69%: 0.579. Loss: 1.7871333360671997\n",
      "val 64.33%: 0.578. Loss: 1.8848148584365845\n",
      "val 64.97%: 0.578. Loss: 1.6584959030151367\n",
      "val 65.61%: 0.578. Loss: 1.473694086074829\n",
      "val 66.24%: 0.578. Loss: 1.521257758140564\n",
      "val 66.88%: 0.578. Loss: 1.9098838567733765\n",
      "val 67.52%: 0.578. Loss: 1.9223945140838623\n",
      "val 68.15%: 0.577. Loss: 2.225039005279541\n",
      "val 68.79%: 0.577. Loss: 1.5282622575759888\n",
      "val 69.43%: 0.577. Loss: 1.9491385221481323\n",
      "val 70.06%: 0.576. Loss: 1.657771348953247\n",
      "val 70.70%: 0.577. Loss: 1.8494480848312378\n",
      "val 71.34%: 0.577. Loss: 1.5394163131713867\n",
      "val 71.97%: 0.577. Loss: 1.7669721841812134\n",
      "val 72.61%: 0.577. Loss: 1.5105443000793457\n",
      "val 73.25%: 0.578. Loss: 1.8094500303268433\n",
      "val 73.89%: 0.578. Loss: 1.563927412033081\n",
      "val 74.52%: 0.578. Loss: 1.4644362926483154\n",
      "val 75.16%: 0.578. Loss: 1.703617811203003\n",
      "val 75.80%: 0.578. Loss: 1.7865021228790283\n",
      "val 76.43%: 0.578. Loss: 1.883829951286316\n",
      "val 77.07%: 0.577. Loss: 2.0573389530181885\n",
      "val 77.71%: 0.577. Loss: 1.8132110834121704\n",
      "val 78.34%: 0.577. Loss: 2.259258985519409\n",
      "val 78.98%: 0.576. Loss: 2.227383613586426\n",
      "val 79.62%: 0.577. Loss: 1.3218543529510498\n",
      "val 80.25%: 0.577. Loss: 1.707629919052124\n",
      "val 80.89%: 0.577. Loss: 1.653681755065918\n",
      "val 81.53%: 0.577. Loss: 2.0603320598602295\n",
      "val 82.17%: 0.577. Loss: 1.8990802764892578\n",
      "val 82.80%: 0.578. Loss: 1.30158269405365\n",
      "val 83.44%: 0.578. Loss: 1.7736082077026367\n",
      "val 84.08%: 0.577. Loss: 1.9794343709945679\n",
      "val 84.71%: 0.577. Loss: 1.8974518775939941\n",
      "val 85.35%: 0.577. Loss: 1.2208929061889648\n",
      "val 85.99%: 0.578. Loss: 1.4101290702819824\n",
      "val 86.62%: 0.578. Loss: 1.55409836769104\n",
      "val 87.26%: 0.578. Loss: 1.630484700202942\n",
      "val 87.90%: 0.577. Loss: 1.8106064796447754\n",
      "val 88.54%: 0.576. Loss: 2.0108423233032227\n",
      "val 89.17%: 0.576. Loss: 1.7914628982543945\n",
      "val 89.81%: 0.576. Loss: 1.8885444402694702\n",
      "val 90.45%: 0.577. Loss: 1.572737693786621\n",
      "val 91.08%: 0.576. Loss: 2.2005226612091064\n",
      "val 91.72%: 0.576. Loss: 1.7406303882598877\n",
      "val 92.36%: 0.576. Loss: 1.7921231985092163\n",
      "val 92.99%: 0.576. Loss: 1.929410696029663\n",
      "val 93.63%: 0.576. Loss: 1.5349007844924927\n",
      "val 94.27%: 0.576. Loss: 1.5535902976989746\n",
      "val 94.90%: 0.576. Loss: 2.0206122398376465\n",
      "val 95.54%: 0.576. Loss: 1.8421766757965088\n",
      "val 96.18%: 0.576. Loss: 1.5577428340911865\n",
      "val 96.82%: 0.576. Loss: 1.909923791885376\n",
      "val 97.45%: 0.576. Loss: 1.517238974571228\n",
      "val 98.09%: 0.576. Loss: 1.897020936012268\n",
      "val 98.73%: 0.576. Loss: 1.9460532665252686\n",
      "val 99.36%: 0.576. Loss: 2.6700632572174072\n",
      "training 0.00%: 0.594. Loss: 1.4785269498825073\n",
      "training 0.06%: 0.617. Loss: 1.4603644609451294\n",
      "training 0.13%: 0.630. Loss: 1.43621826171875\n",
      "training 0.19%: 0.645. Loss: 1.2431979179382324\n",
      "training 0.26%: 0.656. Loss: 1.213019609451294\n",
      "training 0.32%: 0.641. Loss: 1.6188639402389526\n",
      "training 0.38%: 0.634. Loss: 1.6652421951293945\n",
      "training 0.45%: 0.621. Loss: 1.6709606647491455\n",
      "training 0.51%: 0.616. Loss: 1.3683234453201294\n",
      "training 0.58%: 0.616. Loss: 1.5166350603103638\n",
      "training 0.64%: 0.625. Loss: 1.434746265411377\n",
      "training 0.70%: 0.621. Loss: 1.6358516216278076\n",
      "training 0.77%: 0.620. Loss: 1.7168086767196655\n",
      "training 0.83%: 0.619. Loss: 1.6566643714904785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 0.90%: 0.620. Loss: 1.7391055822372437\n",
      "training 0.96%: 0.621. Loss: 1.5244146585464478\n",
      "training 1.02%: 0.619. Loss: 1.7534016370773315\n",
      "training 1.09%: 0.616. Loss: 1.8298219442367554\n",
      "training 1.15%: 0.618. Loss: 1.2836849689483643\n",
      "training 1.22%: 0.617. Loss: 1.7466851472854614\n",
      "training 1.28%: 0.624. Loss: 1.0279245376586914\n",
      "training 1.34%: 0.621. Loss: 1.6471072435379028\n",
      "training 1.41%: 0.619. Loss: 1.8430204391479492\n",
      "training 1.47%: 0.618. Loss: 1.4763431549072266\n",
      "training 1.54%: 0.618. Loss: 1.5176242589950562\n",
      "training 1.60%: 0.618. Loss: 1.610938549041748\n",
      "training 1.66%: 0.619. Loss: 1.3344238996505737\n",
      "training 1.73%: 0.618. Loss: 1.6034529209136963\n",
      "training 1.79%: 0.618. Loss: 1.4526997804641724\n",
      "training 1.86%: 0.617. Loss: 1.6072319746017456\n",
      "training 1.92%: 0.621. Loss: 1.0646923780441284\n",
      "training 1.98%: 0.623. Loss: 1.3089449405670166\n",
      "training 2.05%: 0.623. Loss: 1.4173284769058228\n",
      "training 2.11%: 0.621. Loss: 1.635909080505371\n",
      "training 2.18%: 0.622. Loss: 1.441449761390686\n",
      "training 2.24%: 0.622. Loss: 1.4587994813919067\n",
      "training 2.30%: 0.619. Loss: 1.94315767288208\n",
      "training 2.37%: 0.619. Loss: 1.3796623945236206\n",
      "training 2.43%: 0.621. Loss: 1.10769784450531\n",
      "training 2.50%: 0.622. Loss: 1.2975711822509766\n",
      "training 2.56%: 0.624. Loss: 1.0551598072052002\n",
      "training 2.62%: 0.627. Loss: 1.0545598268508911\n",
      "training 2.69%: 0.626. Loss: 1.704634189605713\n",
      "training 2.75%: 0.623. Loss: 1.9333043098449707\n",
      "training 2.82%: 0.622. Loss: 1.6466671228408813\n",
      "training 2.88%: 0.620. Loss: 1.6653019189834595\n",
      "training 2.94%: 0.620. Loss: 1.3231788873672485\n",
      "training 3.01%: 0.619. Loss: 1.7510693073272705\n",
      "training 3.07%: 0.620. Loss: 1.5911152362823486\n",
      "training 3.13%: 0.617. Loss: 1.6755013465881348\n",
      "training 3.20%: 0.616. Loss: 1.5763353109359741\n",
      "training 3.26%: 0.614. Loss: 1.9946588277816772\n",
      "training 3.33%: 0.614. Loss: 1.3798500299453735\n",
      "training 3.39%: 0.614. Loss: 1.4929906129837036\n",
      "training 3.45%: 0.614. Loss: 1.491542935371399\n",
      "training 3.52%: 0.615. Loss: 1.3276532888412476\n",
      "training 3.58%: 0.615. Loss: 1.4671308994293213\n",
      "training 3.65%: 0.615. Loss: 1.5737696886062622\n",
      "training 3.71%: 0.616. Loss: 1.4077731370925903\n",
      "training 3.77%: 0.615. Loss: 1.5614620447158813\n",
      "training 3.84%: 0.618. Loss: 0.9507578015327454\n",
      "training 3.90%: 0.618. Loss: 1.6052546501159668\n",
      "training 3.97%: 0.619. Loss: 1.559579610824585\n",
      "training 4.03%: 0.619. Loss: 1.542230248451233\n",
      "training 4.09%: 0.618. Loss: 1.6668980121612549\n",
      "training 4.16%: 0.619. Loss: 1.3940538167953491\n",
      "training 4.22%: 0.618. Loss: 1.7211511135101318\n",
      "training 4.29%: 0.619. Loss: 1.2567667961120605\n",
      "training 4.35%: 0.618. Loss: 1.5423811674118042\n",
      "training 4.41%: 0.620. Loss: 0.9212908148765564\n",
      "training 4.48%: 0.620. Loss: 1.3296751976013184\n",
      "training 4.54%: 0.619. Loss: 1.8658796548843384\n",
      "training 4.61%: 0.621. Loss: 0.8734801411628723\n",
      "training 4.67%: 0.622. Loss: 1.0262819528579712\n",
      "training 4.73%: 0.623. Loss: 1.2860305309295654\n",
      "training 4.80%: 0.623. Loss: 1.2729569673538208\n",
      "training 4.86%: 0.623. Loss: 1.5837308168411255\n",
      "training 4.93%: 0.622. Loss: 1.945702314376831\n",
      "training 4.99%: 0.623. Loss: 1.2713099718093872\n",
      "training 5.05%: 0.622. Loss: 1.443753719329834\n",
      "training 5.12%: 0.623. Loss: 1.5107754468917847\n",
      "training 5.18%: 0.624. Loss: 1.3548762798309326\n",
      "training 5.25%: 0.625. Loss: 1.1533880233764648\n",
      "training 5.31%: 0.626. Loss: 1.4484997987747192\n",
      "training 5.37%: 0.627. Loss: 1.2723251581192017\n",
      "training 5.44%: 0.626. Loss: 1.51869535446167\n",
      "training 5.50%: 0.626. Loss: 1.0970954895019531\n",
      "training 5.57%: 0.626. Loss: 1.612414836883545\n",
      "training 5.63%: 0.625. Loss: 1.820258617401123\n",
      "training 5.69%: 0.624. Loss: 1.2080192565917969\n",
      "training 5.76%: 0.624. Loss: 1.5306693315505981\n",
      "training 5.82%: 0.626. Loss: 0.9509111046791077\n",
      "training 5.89%: 0.625. Loss: 1.44765305519104\n",
      "training 5.95%: 0.625. Loss: 1.735746145248413\n",
      "training 6.01%: 0.625. Loss: 1.5729657411575317\n",
      "training 6.08%: 0.625. Loss: 1.1387677192687988\n",
      "training 6.14%: 0.625. Loss: 1.5156525373458862\n",
      "training 6.21%: 0.625. Loss: 1.3947230577468872\n",
      "training 6.27%: 0.625. Loss: 1.2357145547866821\n",
      "training 6.33%: 0.624. Loss: 1.5440735816955566\n",
      "training 6.40%: 0.624. Loss: 1.2204737663269043\n",
      "training 6.46%: 0.625. Loss: 1.2004867792129517\n",
      "training 6.53%: 0.625. Loss: 1.7787455320358276\n",
      "training 6.59%: 0.624. Loss: 1.6491997241973877\n",
      "training 6.65%: 0.624. Loss: 1.791621208190918\n",
      "training 6.72%: 0.624. Loss: 1.7968099117279053\n",
      "training 6.78%: 0.623. Loss: 1.5140436887741089\n",
      "training 6.85%: 0.623. Loss: 1.435467004776001\n",
      "training 6.91%: 0.624. Loss: 1.4102463722229004\n",
      "training 6.97%: 0.625. Loss: 1.0243606567382812\n",
      "training 7.04%: 0.626. Loss: 1.123342752456665\n",
      "training 7.10%: 0.626. Loss: 1.8209494352340698\n",
      "training 7.17%: 0.626. Loss: 1.1288957595825195\n",
      "training 7.23%: 0.627. Loss: 1.233013391494751\n",
      "training 7.29%: 0.626. Loss: 1.6392097473144531\n",
      "training 7.36%: 0.626. Loss: 1.71896231174469\n",
      "training 7.42%: 0.625. Loss: 1.6773971319198608\n",
      "training 7.49%: 0.624. Loss: 1.6821608543395996\n",
      "training 7.55%: 0.625. Loss: 1.2475937604904175\n",
      "training 7.61%: 0.624. Loss: 1.534711480140686\n",
      "training 7.68%: 0.624. Loss: 1.3738925457000732\n",
      "training 7.74%: 0.624. Loss: 1.3629330396652222\n",
      "training 7.81%: 0.624. Loss: 1.8500187397003174\n",
      "training 7.87%: 0.624. Loss: 1.6395865678787231\n",
      "training 7.93%: 0.623. Loss: 1.944706916809082\n",
      "training 8.00%: 0.624. Loss: 1.1967573165893555\n",
      "training 8.06%: 0.624. Loss: 1.6102129220962524\n",
      "training 8.13%: 0.624. Loss: 1.6166496276855469\n",
      "training 8.19%: 0.624. Loss: 1.623536229133606\n",
      "training 8.25%: 0.623. Loss: 1.7919902801513672\n",
      "training 8.32%: 0.623. Loss: 1.1825218200683594\n",
      "training 8.38%: 0.623. Loss: 1.3471407890319824\n",
      "training 8.45%: 0.623. Loss: 1.457974910736084\n",
      "training 8.51%: 0.624. Loss: 1.1520309448242188\n",
      "training 8.57%: 0.623. Loss: 1.6375261545181274\n",
      "training 8.64%: 0.623. Loss: 1.758717656135559\n",
      "training 8.70%: 0.623. Loss: 1.4268405437469482\n",
      "training 8.77%: 0.624. Loss: 1.098915696144104\n",
      "training 8.83%: 0.624. Loss: 1.3492660522460938\n",
      "training 8.89%: 0.624. Loss: 1.191965937614441\n",
      "training 8.96%: 0.624. Loss: 1.757767677307129\n",
      "training 9.02%: 0.624. Loss: 1.5188660621643066\n",
      "training 9.09%: 0.624. Loss: 1.2991139888763428\n",
      "training 9.15%: 0.624. Loss: 1.6533408164978027\n",
      "training 9.21%: 0.624. Loss: 1.534517765045166\n",
      "training 9.28%: 0.624. Loss: 1.5785094499588013\n",
      "training 9.34%: 0.624. Loss: 1.5758053064346313\n",
      "training 9.40%: 0.624. Loss: 1.6600780487060547\n",
      "training 9.47%: 0.624. Loss: 1.6309683322906494\n",
      "training 9.53%: 0.624. Loss: 1.3466192483901978\n",
      "training 9.60%: 0.624. Loss: 1.3263578414916992\n",
      "training 9.66%: 0.624. Loss: 1.690787434577942\n",
      "training 9.72%: 0.624. Loss: 1.4308239221572876\n",
      "training 9.79%: 0.623. Loss: 1.7403758764266968\n",
      "training 9.85%: 0.624. Loss: 1.3385992050170898\n",
      "training 9.92%: 0.625. Loss: 1.0919163227081299\n",
      "training 9.98%: 0.624. Loss: 1.9182908535003662\n",
      "training 10.04%: 0.624. Loss: 1.4514163732528687\n",
      "training 10.11%: 0.624. Loss: 1.205370306968689\n",
      "training 10.17%: 0.625. Loss: 1.6884574890136719\n",
      "training 10.24%: 0.624. Loss: 1.3193931579589844\n",
      "training 10.30%: 0.624. Loss: 1.4202271699905396\n",
      "training 10.36%: 0.625. Loss: 1.3756898641586304\n",
      "training 10.43%: 0.625. Loss: 1.694453239440918\n",
      "training 10.49%: 0.625. Loss: 1.3201602697372437\n",
      "training 10.56%: 0.625. Loss: 1.2882421016693115\n",
      "training 10.62%: 0.625. Loss: 1.3393076658248901\n",
      "training 10.68%: 0.625. Loss: 1.5069968700408936\n",
      "training 10.75%: 0.624. Loss: 1.640630841255188\n",
      "training 10.81%: 0.624. Loss: 1.4725245237350464\n",
      "training 10.88%: 0.624. Loss: 1.3407825231552124\n",
      "training 10.94%: 0.625. Loss: 1.38191556930542\n",
      "training 11.00%: 0.624. Loss: 1.7059992551803589\n",
      "training 11.07%: 0.624. Loss: 1.536811351776123\n",
      "training 11.13%: 0.624. Loss: 1.3800286054611206\n",
      "training 11.20%: 0.624. Loss: 1.3544411659240723\n",
      "training 11.26%: 0.623. Loss: 1.5417901277542114\n",
      "training 11.32%: 0.624. Loss: 1.1849408149719238\n",
      "training 11.39%: 0.624. Loss: 1.5020678043365479\n",
      "training 11.45%: 0.623. Loss: 1.5380035638809204\n",
      "training 11.52%: 0.624. Loss: 1.2987715005874634\n",
      "training 11.58%: 0.623. Loss: 1.4622201919555664\n",
      "training 11.64%: 0.624. Loss: 1.6256024837493896\n",
      "training 11.71%: 0.624. Loss: 1.6704661846160889\n",
      "training 11.77%: 0.624. Loss: 1.2061532735824585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 11.84%: 0.624. Loss: 1.794081687927246\n",
      "training 11.90%: 0.624. Loss: 1.4382909536361694\n",
      "training 11.96%: 0.624. Loss: 1.3707808256149292\n",
      "training 12.03%: 0.623. Loss: 1.706527829170227\n",
      "training 12.09%: 0.624. Loss: 1.2824242115020752\n",
      "training 12.16%: 0.623. Loss: 1.797621726989746\n",
      "training 12.22%: 0.623. Loss: 1.566243290901184\n",
      "training 12.28%: 0.623. Loss: 1.5233155488967896\n",
      "training 12.35%: 0.623. Loss: 1.485430359840393\n",
      "training 12.41%: 0.623. Loss: 1.6933261156082153\n",
      "training 12.48%: 0.623. Loss: 1.3246619701385498\n",
      "training 12.54%: 0.622. Loss: 1.859532117843628\n",
      "training 12.60%: 0.622. Loss: 1.4472545385360718\n",
      "training 12.67%: 0.623. Loss: 1.0943503379821777\n",
      "training 12.73%: 0.623. Loss: 1.0241926908493042\n",
      "training 12.80%: 0.623. Loss: 1.6213243007659912\n",
      "training 12.86%: 0.624. Loss: 1.0720343589782715\n",
      "training 12.92%: 0.624. Loss: 1.6895620822906494\n",
      "training 12.99%: 0.623. Loss: 1.314253568649292\n",
      "training 13.05%: 0.624. Loss: 1.3941311836242676\n",
      "training 13.12%: 0.624. Loss: 1.585310459136963\n",
      "training 13.18%: 0.623. Loss: 2.050354480743408\n",
      "training 13.24%: 0.623. Loss: 1.4625706672668457\n",
      "training 13.31%: 0.624. Loss: 1.0941448211669922\n",
      "training 13.37%: 0.623. Loss: 1.7053751945495605\n",
      "training 13.44%: 0.623. Loss: 1.8408211469650269\n",
      "training 13.50%: 0.623. Loss: 1.9351778030395508\n",
      "training 13.56%: 0.623. Loss: 1.3986016511917114\n",
      "training 13.63%: 0.623. Loss: 1.5913312435150146\n",
      "training 13.69%: 0.622. Loss: 1.649662971496582\n",
      "training 13.76%: 0.622. Loss: 1.5285389423370361\n",
      "training 13.82%: 0.622. Loss: 1.2408802509307861\n",
      "training 13.88%: 0.623. Loss: 1.1769150495529175\n",
      "training 13.95%: 0.623. Loss: 1.3376668691635132\n",
      "training 14.01%: 0.623. Loss: 1.3851383924484253\n",
      "training 14.08%: 0.623. Loss: 2.051130533218384\n",
      "training 14.14%: 0.623. Loss: 1.3929427862167358\n",
      "training 14.20%: 0.623. Loss: 1.1021121740341187\n",
      "training 14.27%: 0.623. Loss: 1.8616796731948853\n",
      "training 14.33%: 0.622. Loss: 1.8615514039993286\n",
      "training 14.40%: 0.623. Loss: 1.3160734176635742\n",
      "training 14.46%: 0.622. Loss: 1.7206509113311768\n",
      "training 14.52%: 0.622. Loss: 1.4746257066726685\n",
      "training 14.59%: 0.622. Loss: 1.495818853378296\n",
      "training 14.65%: 0.622. Loss: 1.0586029291152954\n",
      "training 14.72%: 0.622. Loss: 1.517745852470398\n",
      "training 14.78%: 0.622. Loss: 1.820726752281189\n",
      "training 14.84%: 0.622. Loss: 1.2029591798782349\n",
      "training 14.91%: 0.622. Loss: 1.5874712467193604\n",
      "training 14.97%: 0.622. Loss: 1.7340794801712036\n",
      "training 15.04%: 0.622. Loss: 1.3629955053329468\n",
      "training 15.10%: 0.622. Loss: 1.4125747680664062\n",
      "training 15.16%: 0.622. Loss: 1.445477843284607\n",
      "training 15.23%: 0.622. Loss: 1.5216349363327026\n",
      "training 15.29%: 0.622. Loss: 1.034382939338684\n",
      "training 15.36%: 0.623. Loss: 1.385683298110962\n",
      "training 15.42%: 0.622. Loss: 1.391560673713684\n",
      "training 15.48%: 0.623. Loss: 1.0662002563476562\n",
      "training 15.55%: 0.623. Loss: 1.209290862083435\n",
      "training 15.61%: 0.623. Loss: 1.8138153553009033\n",
      "training 15.67%: 0.623. Loss: 1.6955294609069824\n",
      "training 15.74%: 0.623. Loss: 1.4602586030960083\n",
      "training 15.80%: 0.623. Loss: 1.600496530532837\n",
      "training 15.87%: 0.623. Loss: 1.413167953491211\n",
      "training 15.93%: 0.623. Loss: 1.4661847352981567\n",
      "training 15.99%: 0.624. Loss: 1.0712759494781494\n",
      "training 16.06%: 0.624. Loss: 1.5744353532791138\n",
      "training 16.12%: 0.624. Loss: 1.494797945022583\n",
      "training 16.19%: 0.624. Loss: 1.0666077136993408\n",
      "training 16.25%: 0.624. Loss: 1.6165447235107422\n",
      "training 16.31%: 0.623. Loss: 1.9310691356658936\n",
      "training 16.38%: 0.623. Loss: 1.5080517530441284\n",
      "training 16.44%: 0.623. Loss: 1.6355094909667969\n",
      "training 16.51%: 0.623. Loss: 1.6818655729293823\n",
      "training 16.57%: 0.623. Loss: 1.5042376518249512\n",
      "training 16.63%: 0.623. Loss: 1.2949966192245483\n",
      "training 16.70%: 0.623. Loss: 1.6625996828079224\n",
      "training 16.76%: 0.623. Loss: 1.7592226266860962\n",
      "training 16.83%: 0.623. Loss: 1.2105820178985596\n",
      "training 16.89%: 0.623. Loss: 1.1672403812408447\n",
      "training 16.95%: 0.623. Loss: 1.5314180850982666\n",
      "training 17.02%: 0.623. Loss: 1.7349286079406738\n",
      "training 17.08%: 0.623. Loss: 1.6827750205993652\n",
      "training 17.15%: 0.623. Loss: 1.6322214603424072\n",
      "training 17.21%: 0.623. Loss: 1.6757986545562744\n",
      "training 17.27%: 0.623. Loss: 1.2465298175811768\n",
      "training 17.34%: 0.623. Loss: 1.1212762594223022\n",
      "training 17.40%: 0.623. Loss: 1.3365691900253296\n",
      "training 17.47%: 0.623. Loss: 1.5356444120407104\n",
      "training 17.53%: 0.623. Loss: 1.8024829626083374\n",
      "training 17.59%: 0.623. Loss: 1.4563875198364258\n",
      "training 17.66%: 0.622. Loss: 1.6476696729660034\n",
      "training 17.72%: 0.623. Loss: 1.4165390729904175\n",
      "training 17.79%: 0.623. Loss: 1.3425904512405396\n",
      "training 17.85%: 0.623. Loss: 1.2872267961502075\n",
      "training 17.91%: 0.623. Loss: 1.347307801246643\n",
      "training 17.98%: 0.623. Loss: 1.673484206199646\n",
      "training 18.04%: 0.622. Loss: 2.110905647277832\n",
      "training 18.11%: 0.623. Loss: 1.4936697483062744\n",
      "training 18.17%: 0.622. Loss: 1.6283477544784546\n",
      "training 18.23%: 0.622. Loss: 1.422503113746643\n",
      "training 18.30%: 0.622. Loss: 1.502495527267456\n",
      "training 18.36%: 0.623. Loss: 1.3239259719848633\n",
      "training 18.43%: 0.622. Loss: 1.5949217081069946\n",
      "training 18.49%: 0.623. Loss: 1.2663664817810059\n",
      "training 18.55%: 0.622. Loss: 1.5110461711883545\n",
      "training 18.62%: 0.622. Loss: 1.7038536071777344\n",
      "training 18.68%: 0.622. Loss: 1.714138388633728\n",
      "training 18.75%: 0.622. Loss: 1.7608565092086792\n",
      "training 18.81%: 0.622. Loss: 1.210921287536621\n",
      "training 18.87%: 0.622. Loss: 1.2251715660095215\n",
      "training 18.94%: 0.622. Loss: 1.5394049882888794\n",
      "training 19.00%: 0.622. Loss: 1.3933284282684326\n",
      "training 19.07%: 0.623. Loss: 1.2702349424362183\n",
      "training 19.13%: 0.623. Loss: 1.4517230987548828\n",
      "training 19.19%: 0.623. Loss: 1.2667505741119385\n",
      "training 19.26%: 0.623. Loss: 1.0419187545776367\n",
      "training 19.32%: 0.623. Loss: 1.6751201152801514\n",
      "training 19.39%: 0.623. Loss: 1.2294304370880127\n",
      "training 19.45%: 0.623. Loss: 1.2759815454483032\n",
      "training 19.51%: 0.622. Loss: 1.9410309791564941\n",
      "training 19.58%: 0.623. Loss: 1.295303463935852\n",
      "training 19.64%: 0.623. Loss: 1.5722774267196655\n",
      "training 19.71%: 0.622. Loss: 1.5981898307800293\n",
      "training 19.77%: 0.622. Loss: 1.4054431915283203\n",
      "training 19.83%: 0.622. Loss: 1.7668101787567139\n",
      "training 19.90%: 0.622. Loss: 1.5564146041870117\n",
      "training 19.96%: 0.623. Loss: 1.4069079160690308\n",
      "training 20.03%: 0.622. Loss: 1.3178828954696655\n",
      "training 20.09%: 0.623. Loss: 1.0814625024795532\n",
      "training 20.15%: 0.623. Loss: 1.2819315195083618\n",
      "training 20.22%: 0.623. Loss: 1.5860192775726318\n",
      "training 20.28%: 0.623. Loss: 1.163076639175415\n",
      "training 20.35%: 0.623. Loss: 1.3742468357086182\n",
      "training 20.41%: 0.623. Loss: 1.4676711559295654\n",
      "training 20.47%: 0.623. Loss: 1.492542028427124\n",
      "training 20.54%: 0.623. Loss: 1.7357176542282104\n",
      "training 20.60%: 0.622. Loss: 1.7388362884521484\n",
      "training 20.67%: 0.622. Loss: 1.7515032291412354\n",
      "training 20.73%: 0.622. Loss: 1.6289167404174805\n",
      "training 20.79%: 0.622. Loss: 2.083055257797241\n",
      "training 20.86%: 0.622. Loss: 1.5504655838012695\n",
      "training 20.92%: 0.622. Loss: 0.8705925941467285\n",
      "training 20.99%: 0.622. Loss: 1.6312963962554932\n",
      "training 21.05%: 0.622. Loss: 1.6420199871063232\n",
      "training 21.11%: 0.622. Loss: 1.5794854164123535\n",
      "training 21.18%: 0.622. Loss: 1.9249200820922852\n",
      "training 21.24%: 0.622. Loss: 1.6801481246948242\n",
      "training 21.31%: 0.622. Loss: 1.5342813730239868\n",
      "training 21.37%: 0.622. Loss: 1.4187906980514526\n",
      "training 21.43%: 0.622. Loss: 1.3653026819229126\n",
      "training 21.50%: 0.622. Loss: 1.3985238075256348\n",
      "training 21.56%: 0.622. Loss: 1.1363930702209473\n",
      "training 21.63%: 0.622. Loss: 1.0887761116027832\n",
      "training 21.69%: 0.622. Loss: 1.4497984647750854\n",
      "training 21.75%: 0.622. Loss: 1.5882809162139893\n",
      "training 21.82%: 0.622. Loss: 1.0992333889007568\n",
      "training 21.88%: 0.623. Loss: 1.3832684755325317\n",
      "training 21.94%: 0.623. Loss: 1.456430196762085\n",
      "training 22.01%: 0.623. Loss: 1.074072241783142\n",
      "training 22.07%: 0.623. Loss: 1.5659934282302856\n",
      "training 22.14%: 0.623. Loss: 1.8280279636383057\n",
      "training 22.20%: 0.623. Loss: 1.2408138513565063\n",
      "training 22.26%: 0.623. Loss: 1.3321046829223633\n",
      "training 22.33%: 0.623. Loss: 1.472990870475769\n",
      "training 22.39%: 0.623. Loss: 1.1802796125411987\n",
      "training 22.46%: 0.623. Loss: 1.352171778678894\n",
      "training 22.52%: 0.623. Loss: 1.3622709512710571\n",
      "training 22.58%: 0.624. Loss: 1.5306665897369385\n",
      "training 22.65%: 0.623. Loss: 1.9482645988464355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 22.71%: 0.623. Loss: 1.8073761463165283\n",
      "training 22.78%: 0.623. Loss: 1.6783084869384766\n",
      "training 22.84%: 0.623. Loss: 1.5394636392593384\n",
      "training 22.90%: 0.623. Loss: 1.8639705181121826\n",
      "training 22.97%: 0.623. Loss: 1.3779608011245728\n",
      "training 23.03%: 0.623. Loss: 1.7626092433929443\n",
      "training 23.10%: 0.623. Loss: 1.275612711906433\n",
      "training 23.16%: 0.623. Loss: 1.8103030920028687\n",
      "training 23.22%: 0.623. Loss: 1.3230160474777222\n",
      "training 23.29%: 0.623. Loss: 1.1444077491760254\n",
      "training 23.35%: 0.623. Loss: 1.5425835847854614\n",
      "training 23.42%: 0.623. Loss: 1.3983622789382935\n",
      "training 23.48%: 0.623. Loss: 1.1554898023605347\n",
      "training 23.54%: 0.623. Loss: 1.462646484375\n",
      "training 23.61%: 0.623. Loss: 1.5350593328475952\n",
      "training 23.67%: 0.623. Loss: 1.362156629562378\n",
      "training 23.74%: 0.623. Loss: 1.1980648040771484\n",
      "training 23.80%: 0.623. Loss: 1.4443506002426147\n",
      "training 23.86%: 0.623. Loss: 2.061558723449707\n",
      "training 23.93%: 0.623. Loss: 1.5634853839874268\n",
      "training 23.99%: 0.623. Loss: 1.9055395126342773\n",
      "training 24.06%: 0.622. Loss: 1.5412349700927734\n",
      "training 24.12%: 0.622. Loss: 1.5154305696487427\n",
      "training 24.18%: 0.623. Loss: 1.2742817401885986\n",
      "training 24.25%: 0.623. Loss: 1.3744250535964966\n",
      "training 24.31%: 0.623. Loss: 1.4932304620742798\n",
      "training 24.38%: 0.623. Loss: 1.6516778469085693\n",
      "training 24.44%: 0.623. Loss: 1.1273729801177979\n",
      "training 24.50%: 0.623. Loss: 1.6159130334854126\n",
      "training 24.57%: 0.623. Loss: 1.8850048780441284\n",
      "training 24.63%: 0.623. Loss: 1.5671539306640625\n",
      "training 24.70%: 0.622. Loss: 1.6862808465957642\n",
      "training 24.76%: 0.622. Loss: 1.50736403465271\n",
      "training 24.82%: 0.622. Loss: 1.0874388217926025\n",
      "training 24.89%: 0.622. Loss: 1.3627252578735352\n",
      "training 24.95%: 0.623. Loss: 1.6783474683761597\n",
      "training 25.02%: 0.623. Loss: 1.2215962409973145\n",
      "training 25.08%: 0.623. Loss: 1.2775030136108398\n",
      "training 25.14%: 0.623. Loss: 1.5145647525787354\n",
      "training 25.21%: 0.623. Loss: 1.6546624898910522\n",
      "training 25.27%: 0.623. Loss: 1.1783115863800049\n",
      "training 25.34%: 0.623. Loss: 1.7554742097854614\n",
      "training 25.40%: 0.622. Loss: 1.8566886186599731\n",
      "training 25.46%: 0.623. Loss: 1.2347183227539062\n",
      "training 25.53%: 0.622. Loss: 1.8115249872207642\n",
      "training 25.59%: 0.622. Loss: 1.1483712196350098\n",
      "training 25.66%: 0.623. Loss: 1.2505748271942139\n",
      "training 25.72%: 0.622. Loss: 1.572029948234558\n",
      "training 25.78%: 0.623. Loss: 1.323994755744934\n",
      "training 25.85%: 0.623. Loss: 1.6037286520004272\n",
      "training 25.91%: 0.623. Loss: 1.1714847087860107\n",
      "training 25.98%: 0.623. Loss: 1.5342134237289429\n",
      "training 26.04%: 0.623. Loss: 1.2820740938186646\n",
      "training 26.10%: 0.623. Loss: 1.4015368223190308\n",
      "training 26.17%: 0.623. Loss: 1.413374662399292\n",
      "training 26.23%: 0.623. Loss: 1.2780529260635376\n",
      "training 26.30%: 0.623. Loss: 1.1327160596847534\n",
      "training 26.36%: 0.623. Loss: 1.3033305406570435\n",
      "training 26.42%: 0.623. Loss: 1.6433823108673096\n",
      "training 26.49%: 0.623. Loss: 1.4932596683502197\n",
      "training 26.55%: 0.623. Loss: 1.1327354907989502\n",
      "training 26.62%: 0.623. Loss: 1.486030101776123\n",
      "training 26.68%: 0.623. Loss: 1.8287580013275146\n",
      "training 26.74%: 0.623. Loss: 1.4763001203536987\n",
      "training 26.81%: 0.623. Loss: 1.2850316762924194\n",
      "training 26.87%: 0.623. Loss: 1.3772743940353394\n",
      "training 26.94%: 0.623. Loss: 1.483722448348999\n",
      "training 27.00%: 0.623. Loss: 1.299900770187378\n",
      "training 27.06%: 0.623. Loss: 1.379084587097168\n",
      "training 27.13%: 0.623. Loss: 1.193835735321045\n",
      "training 27.19%: 0.623. Loss: 1.6414748430252075\n",
      "training 27.26%: 0.623. Loss: 1.2133976221084595\n",
      "training 27.32%: 0.623. Loss: 1.575934648513794\n",
      "training 27.38%: 0.623. Loss: 1.6502649784088135\n",
      "training 27.45%: 0.623. Loss: 1.5325292348861694\n",
      "training 27.51%: 0.624. Loss: 1.1507104635238647\n",
      "training 27.58%: 0.624. Loss: 1.6685731410980225\n",
      "training 27.64%: 0.623. Loss: 1.4729923009872437\n",
      "training 27.70%: 0.624. Loss: 1.1854851245880127\n",
      "training 27.77%: 0.624. Loss: 1.7883193492889404\n",
      "training 27.83%: 0.624. Loss: 1.5154013633728027\n",
      "training 27.90%: 0.623. Loss: 1.935949444770813\n",
      "training 27.96%: 0.623. Loss: 1.4304473400115967\n",
      "training 28.02%: 0.624. Loss: 1.1644357442855835\n",
      "training 28.09%: 0.624. Loss: 1.467010259628296\n",
      "training 28.15%: 0.623. Loss: 1.598462462425232\n",
      "training 28.21%: 0.624. Loss: 1.4006540775299072\n",
      "training 28.28%: 0.623. Loss: 1.7826805114746094\n",
      "training 28.34%: 0.623. Loss: 1.4246329069137573\n",
      "training 28.41%: 0.623. Loss: 1.5858722925186157\n",
      "training 28.47%: 0.623. Loss: 1.283302664756775\n",
      "training 28.53%: 0.624. Loss: 1.3418912887573242\n",
      "training 28.60%: 0.624. Loss: 1.3176167011260986\n",
      "training 28.66%: 0.624. Loss: 1.648574709892273\n",
      "training 28.73%: 0.624. Loss: 1.6138384342193604\n",
      "training 28.79%: 0.624. Loss: 1.5587091445922852\n",
      "training 28.85%: 0.623. Loss: 1.5703730583190918\n",
      "training 28.92%: 0.623. Loss: 1.7426878213882446\n",
      "training 28.98%: 0.623. Loss: 1.6408437490463257\n",
      "training 29.05%: 0.623. Loss: 1.0579272508621216\n",
      "training 29.11%: 0.623. Loss: 1.2390941381454468\n",
      "training 29.17%: 0.624. Loss: 1.3586055040359497\n",
      "training 29.24%: 0.624. Loss: 1.4581983089447021\n",
      "training 29.30%: 0.624. Loss: 1.2996488809585571\n",
      "training 29.37%: 0.624. Loss: 1.449859857559204\n",
      "training 29.43%: 0.624. Loss: 1.5602456331253052\n",
      "training 29.49%: 0.624. Loss: 1.6310356855392456\n",
      "training 29.56%: 0.624. Loss: 1.631751298904419\n",
      "training 29.62%: 0.624. Loss: 1.6562424898147583\n",
      "training 29.69%: 0.624. Loss: 1.14559805393219\n",
      "training 29.75%: 0.624. Loss: 1.396459698677063\n",
      "training 29.81%: 0.624. Loss: 2.0808322429656982\n",
      "training 29.88%: 0.624. Loss: 1.254063367843628\n",
      "training 29.94%: 0.623. Loss: 1.966671109199524\n",
      "training 30.01%: 0.623. Loss: 1.5480748414993286\n",
      "training 30.07%: 0.623. Loss: 1.5681909322738647\n",
      "training 30.13%: 0.623. Loss: 2.0848047733306885\n",
      "training 30.20%: 0.623. Loss: 1.5304372310638428\n",
      "training 30.26%: 0.623. Loss: 1.5528614521026611\n",
      "training 30.33%: 0.623. Loss: 1.2715824842453003\n",
      "training 30.39%: 0.623. Loss: 1.7227483987808228\n",
      "training 30.45%: 0.623. Loss: 1.8993791341781616\n",
      "training 30.52%: 0.623. Loss: 1.8511580228805542\n",
      "training 30.58%: 0.623. Loss: 2.028665781021118\n",
      "training 30.65%: 0.623. Loss: 1.4812225103378296\n",
      "training 30.71%: 0.623. Loss: 1.3511815071105957\n",
      "training 30.77%: 0.623. Loss: 1.3213101625442505\n",
      "training 30.84%: 0.623. Loss: 1.4523158073425293\n",
      "training 30.90%: 0.623. Loss: 1.5180920362472534\n",
      "training 30.97%: 0.623. Loss: 1.4335722923278809\n",
      "training 31.03%: 0.623. Loss: 1.3480485677719116\n",
      "training 31.09%: 0.623. Loss: 1.2869147062301636\n",
      "training 31.16%: 0.623. Loss: 1.5426315069198608\n",
      "training 31.22%: 0.623. Loss: 1.2916114330291748\n",
      "training 31.29%: 0.623. Loss: 1.6876083612442017\n",
      "training 31.35%: 0.623. Loss: 1.7708821296691895\n",
      "training 31.41%: 0.623. Loss: 1.6385843753814697\n",
      "training 31.48%: 0.623. Loss: 1.5005946159362793\n",
      "training 31.54%: 0.623. Loss: 1.7132515907287598\n",
      "training 31.61%: 0.623. Loss: 1.3728550672531128\n",
      "training 31.67%: 0.623. Loss: 0.9860531687736511\n",
      "training 31.73%: 0.623. Loss: 1.7964277267456055\n",
      "training 31.80%: 0.623. Loss: 1.5273722410202026\n",
      "training 31.86%: 0.622. Loss: 2.0183193683624268\n",
      "training 31.93%: 0.622. Loss: 1.8507283926010132\n",
      "training 31.99%: 0.622. Loss: 1.7794575691223145\n",
      "training 32.05%: 0.622. Loss: 1.3860048055648804\n",
      "training 32.12%: 0.622. Loss: 1.2727411985397339\n",
      "training 32.18%: 0.622. Loss: 1.847872018814087\n",
      "training 32.25%: 0.622. Loss: 1.5682175159454346\n",
      "training 32.31%: 0.622. Loss: 1.2867646217346191\n",
      "training 32.37%: 0.622. Loss: 1.4215304851531982\n",
      "training 32.44%: 0.622. Loss: 1.410422921180725\n",
      "training 32.50%: 0.622. Loss: 1.5094579458236694\n",
      "training 32.57%: 0.622. Loss: 1.6822972297668457\n",
      "training 32.63%: 0.622. Loss: 1.6331425905227661\n",
      "training 32.69%: 0.622. Loss: 1.5292649269104004\n",
      "training 32.76%: 0.622. Loss: 1.4920765161514282\n",
      "training 32.82%: 0.622. Loss: 1.384798288345337\n",
      "training 32.89%: 0.622. Loss: 1.8013993501663208\n",
      "training 32.95%: 0.622. Loss: 1.2275055646896362\n",
      "training 33.01%: 0.622. Loss: 1.6620197296142578\n",
      "training 33.08%: 0.622. Loss: 1.6486707925796509\n",
      "training 33.14%: 0.621. Loss: 1.5372951030731201\n",
      "training 33.21%: 0.621. Loss: 1.5643094778060913\n",
      "training 33.27%: 0.621. Loss: 0.9901975393295288\n",
      "training 33.33%: 0.622. Loss: 1.4194602966308594\n",
      "training 33.40%: 0.622. Loss: 1.3664934635162354\n",
      "training 33.46%: 0.622. Loss: 1.5395742654800415\n",
      "training 33.53%: 0.622. Loss: 1.6782283782958984\n",
      "training 33.59%: 0.622. Loss: 1.472814679145813\n",
      "training 33.65%: 0.622. Loss: 1.113875389099121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 33.72%: 0.622. Loss: 1.469427466392517\n",
      "training 33.78%: 0.622. Loss: 1.3549550771713257\n",
      "training 33.85%: 0.622. Loss: 1.3961926698684692\n",
      "training 33.91%: 0.622. Loss: 1.4635752439498901\n",
      "training 33.97%: 0.622. Loss: 1.6004397869110107\n",
      "training 34.04%: 0.622. Loss: 1.5823614597320557\n",
      "training 34.10%: 0.622. Loss: 1.6567317247390747\n",
      "training 34.17%: 0.622. Loss: 1.5937061309814453\n",
      "training 34.23%: 0.622. Loss: 1.08449387550354\n",
      "training 34.29%: 0.622. Loss: 1.220154881477356\n",
      "training 34.36%: 0.622. Loss: 1.726071834564209\n",
      "training 34.42%: 0.622. Loss: 1.0337642431259155\n",
      "training 34.48%: 0.622. Loss: 1.6740831136703491\n",
      "training 34.55%: 0.622. Loss: 1.2987326383590698\n",
      "training 34.61%: 0.622. Loss: 1.78192138671875\n",
      "training 34.68%: 0.622. Loss: 1.8201850652694702\n",
      "training 34.74%: 0.622. Loss: 1.5317500829696655\n",
      "training 34.80%: 0.622. Loss: 0.9574997425079346\n",
      "training 34.87%: 0.622. Loss: 1.6645164489746094\n",
      "training 34.93%: 0.622. Loss: 2.006605386734009\n",
      "training 35.00%: 0.622. Loss: 1.6163434982299805\n",
      "training 35.06%: 0.622. Loss: 1.5593852996826172\n",
      "training 35.12%: 0.622. Loss: 1.2213199138641357\n",
      "training 35.19%: 0.622. Loss: 1.1947373151779175\n",
      "training 35.25%: 0.622. Loss: 1.5078024864196777\n",
      "training 35.32%: 0.622. Loss: 1.6413031816482544\n",
      "training 35.38%: 0.622. Loss: 1.4466686248779297\n",
      "training 35.44%: 0.622. Loss: 1.7653871774673462\n",
      "training 35.51%: 0.622. Loss: 1.3727093935012817\n",
      "training 35.57%: 0.622. Loss: 2.0314090251922607\n",
      "training 35.64%: 0.622. Loss: 1.6827791929244995\n",
      "training 35.70%: 0.622. Loss: 1.4659674167633057\n",
      "training 35.76%: 0.622. Loss: 1.2543939352035522\n",
      "training 35.83%: 0.622. Loss: 1.8230152130126953\n",
      "training 35.89%: 0.622. Loss: 1.2551213502883911\n",
      "training 35.96%: 0.622. Loss: 1.6760833263397217\n",
      "training 36.02%: 0.622. Loss: 1.409049153327942\n",
      "training 36.08%: 0.622. Loss: 1.4589051008224487\n",
      "training 36.15%: 0.622. Loss: 1.2975660562515259\n",
      "training 36.21%: 0.622. Loss: 1.3958585262298584\n",
      "training 36.28%: 0.622. Loss: 1.7911163568496704\n",
      "training 36.34%: 0.622. Loss: 1.1852819919586182\n",
      "training 36.40%: 0.622. Loss: 1.7306585311889648\n",
      "training 36.47%: 0.622. Loss: 1.56391179561615\n",
      "training 36.53%: 0.622. Loss: 1.2733443975448608\n",
      "training 36.60%: 0.622. Loss: 1.4330137968063354\n",
      "training 36.66%: 0.622. Loss: 1.3776077032089233\n",
      "training 36.72%: 0.622. Loss: 1.8860743045806885\n",
      "training 36.79%: 0.622. Loss: 1.597604513168335\n",
      "training 36.85%: 0.622. Loss: 1.833276629447937\n",
      "training 36.92%: 0.622. Loss: 1.4096215963363647\n",
      "training 36.98%: 0.622. Loss: 1.5282533168792725\n",
      "training 37.04%: 0.622. Loss: 1.2699528932571411\n",
      "training 37.11%: 0.622. Loss: 1.558042049407959\n",
      "training 37.17%: 0.622. Loss: 1.1857376098632812\n",
      "training 37.24%: 0.622. Loss: 1.9937044382095337\n",
      "training 37.30%: 0.622. Loss: 1.7135921716690063\n",
      "training 37.36%: 0.622. Loss: 1.516842246055603\n",
      "training 37.43%: 0.622. Loss: 1.1003674268722534\n",
      "training 37.49%: 0.622. Loss: 1.5710012912750244\n",
      "training 37.56%: 0.622. Loss: 1.3223003149032593\n",
      "training 37.62%: 0.622. Loss: 1.3373416662216187\n",
      "training 37.68%: 0.622. Loss: 1.5281283855438232\n",
      "training 37.75%: 0.622. Loss: 1.8120728731155396\n",
      "training 37.81%: 0.622. Loss: 1.5873632431030273\n",
      "training 37.88%: 0.622. Loss: 1.7161177396774292\n",
      "training 37.94%: 0.622. Loss: 1.735884666442871\n",
      "training 38.00%: 0.622. Loss: 1.8481725454330444\n",
      "training 38.07%: 0.621. Loss: 1.8095216751098633\n",
      "training 38.13%: 0.621. Loss: 1.9875906705856323\n",
      "training 38.20%: 0.621. Loss: 1.369732141494751\n",
      "training 38.26%: 0.621. Loss: 1.8806281089782715\n",
      "training 38.32%: 0.621. Loss: 1.6915229558944702\n",
      "training 38.39%: 0.621. Loss: 1.3190120458602905\n",
      "training 38.45%: 0.621. Loss: 1.4554346799850464\n",
      "training 38.52%: 0.621. Loss: 1.7705899477005005\n",
      "training 38.58%: 0.621. Loss: 1.1410143375396729\n",
      "training 38.64%: 0.621. Loss: 1.3740254640579224\n",
      "training 38.71%: 0.621. Loss: 1.6472437381744385\n",
      "training 38.77%: 0.621. Loss: 1.3904712200164795\n",
      "training 38.84%: 0.622. Loss: 1.3279386758804321\n",
      "training 38.90%: 0.622. Loss: 1.4647748470306396\n",
      "training 38.96%: 0.622. Loss: 1.5642688274383545\n",
      "training 39.03%: 0.622. Loss: 1.658658742904663\n",
      "training 39.09%: 0.622. Loss: 1.2447963953018188\n",
      "training 39.16%: 0.622. Loss: 1.404400110244751\n",
      "training 39.22%: 0.622. Loss: 1.337482213973999\n",
      "training 39.28%: 0.622. Loss: 1.5924217700958252\n",
      "training 39.35%: 0.622. Loss: 1.4204305410385132\n",
      "training 39.41%: 0.622. Loss: 1.4770278930664062\n",
      "training 39.48%: 0.622. Loss: 1.1685481071472168\n",
      "training 39.54%: 0.622. Loss: 1.2668181657791138\n",
      "training 39.60%: 0.622. Loss: 1.2448996305465698\n",
      "training 39.67%: 0.622. Loss: 1.6850566864013672\n",
      "training 39.73%: 0.622. Loss: 1.0777297019958496\n",
      "training 39.80%: 0.621. Loss: 1.7479190826416016\n",
      "training 39.86%: 0.622. Loss: 1.2249352931976318\n",
      "training 39.92%: 0.622. Loss: 1.3546769618988037\n",
      "training 39.99%: 0.622. Loss: 1.9966994524002075\n",
      "training 40.05%: 0.622. Loss: 1.7631359100341797\n",
      "training 40.12%: 0.621. Loss: 1.8796721696853638\n",
      "training 40.18%: 0.621. Loss: 1.9044052362442017\n",
      "training 40.24%: 0.621. Loss: 1.3211233615875244\n",
      "training 40.31%: 0.621. Loss: 1.3440521955490112\n",
      "training 40.37%: 0.621. Loss: 1.957655668258667\n",
      "training 40.44%: 0.621. Loss: 1.4985918998718262\n",
      "training 40.50%: 0.621. Loss: 1.5809844732284546\n",
      "training 40.56%: 0.621. Loss: 1.4138590097427368\n",
      "training 40.63%: 0.621. Loss: 1.5678801536560059\n",
      "training 40.69%: 0.621. Loss: 1.2605466842651367\n",
      "training 40.75%: 0.621. Loss: 1.660882830619812\n",
      "training 40.82%: 0.621. Loss: 1.9794673919677734\n",
      "training 40.88%: 0.621. Loss: 1.7898261547088623\n",
      "training 40.95%: 0.621. Loss: 1.5077544450759888\n",
      "training 41.01%: 0.621. Loss: 1.0312308073043823\n",
      "training 41.07%: 0.621. Loss: 1.4762033224105835\n",
      "training 41.14%: 0.621. Loss: 1.5353617668151855\n",
      "training 41.20%: 0.621. Loss: 1.5645519495010376\n",
      "training 41.27%: 0.621. Loss: 1.984263300895691\n",
      "training 41.33%: 0.621. Loss: 1.1158217191696167\n",
      "training 41.39%: 0.621. Loss: 1.4962427616119385\n",
      "training 41.46%: 0.621. Loss: 1.2071833610534668\n",
      "training 41.52%: 0.621. Loss: 1.3798211812973022\n",
      "training 41.59%: 0.620. Loss: 2.0796191692352295\n",
      "training 41.65%: 0.620. Loss: 1.4699794054031372\n",
      "training 41.71%: 0.620. Loss: 2.00313138961792\n",
      "training 41.78%: 0.620. Loss: 1.7175471782684326\n",
      "training 41.84%: 0.620. Loss: 1.2427728176116943\n",
      "training 41.91%: 0.620. Loss: 1.4557855129241943\n",
      "training 41.97%: 0.620. Loss: 1.3637720346450806\n",
      "training 42.03%: 0.620. Loss: 1.5149953365325928\n",
      "training 42.10%: 0.620. Loss: 1.1544392108917236\n",
      "training 42.16%: 0.620. Loss: 1.4689315557479858\n",
      "training 42.23%: 0.620. Loss: 1.815903902053833\n",
      "training 42.29%: 0.620. Loss: 1.6904131174087524\n",
      "training 42.35%: 0.620. Loss: 1.5395933389663696\n",
      "training 42.42%: 0.620. Loss: 1.5885623693466187\n",
      "training 42.48%: 0.620. Loss: 1.1307917833328247\n",
      "training 42.55%: 0.620. Loss: 1.804915428161621\n",
      "training 42.61%: 0.620. Loss: 1.4834210872650146\n",
      "training 42.67%: 0.620. Loss: 1.4238848686218262\n",
      "training 42.74%: 0.620. Loss: 1.4756839275360107\n",
      "training 42.80%: 0.620. Loss: 1.5297868251800537\n",
      "training 42.87%: 0.620. Loss: 1.4560590982437134\n",
      "training 42.93%: 0.620. Loss: 1.8635085821151733\n",
      "training 42.99%: 0.620. Loss: 1.1745940446853638\n",
      "training 43.06%: 0.620. Loss: 1.7855291366577148\n",
      "training 43.12%: 0.620. Loss: 1.2051581144332886\n",
      "training 43.19%: 0.620. Loss: 1.496769905090332\n",
      "training 43.25%: 0.620. Loss: 2.065845251083374\n",
      "training 43.31%: 0.620. Loss: 1.6180624961853027\n",
      "training 43.38%: 0.620. Loss: 1.457176923751831\n",
      "training 43.44%: 0.620. Loss: 1.7062592506408691\n",
      "training 43.51%: 0.620. Loss: 1.149067997932434\n",
      "training 43.57%: 0.620. Loss: 1.3307111263275146\n",
      "training 43.63%: 0.620. Loss: 1.1336777210235596\n",
      "training 43.70%: 0.620. Loss: 1.437890887260437\n",
      "training 43.76%: 0.620. Loss: 1.5309184789657593\n",
      "training 43.83%: 0.620. Loss: 1.3449277877807617\n",
      "training 43.89%: 0.620. Loss: 1.550901174545288\n",
      "training 43.95%: 0.620. Loss: 1.3023474216461182\n",
      "training 44.02%: 0.620. Loss: 1.560462236404419\n",
      "training 44.08%: 0.620. Loss: 1.5040467977523804\n",
      "training 44.15%: 0.620. Loss: 1.7656551599502563\n",
      "training 44.21%: 0.620. Loss: 1.9032162427902222\n",
      "training 44.27%: 0.620. Loss: 1.406417965888977\n",
      "training 44.34%: 0.620. Loss: 1.2823654413223267\n",
      "training 44.40%: 0.620. Loss: 2.052218437194824\n",
      "training 44.47%: 0.620. Loss: 1.3182235956192017\n",
      "training 44.53%: 0.620. Loss: 1.2108949422836304\n",
      "training 44.59%: 0.620. Loss: 1.4662020206451416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 44.66%: 0.620. Loss: 1.5272128582000732\n",
      "training 44.72%: 0.620. Loss: 1.485044240951538\n",
      "training 44.79%: 0.620. Loss: 1.490614891052246\n",
      "training 44.85%: 0.620. Loss: 1.6534647941589355\n",
      "training 44.91%: 0.620. Loss: 1.6318753957748413\n",
      "training 44.98%: 0.620. Loss: 1.2300039529800415\n",
      "training 45.04%: 0.620. Loss: 1.2119793891906738\n",
      "training 45.11%: 0.620. Loss: 1.1914640665054321\n",
      "training 45.17%: 0.620. Loss: 1.4358316659927368\n",
      "training 45.23%: 0.620. Loss: 1.478749394416809\n",
      "training 45.30%: 0.620. Loss: 1.4495211839675903\n",
      "training 45.36%: 0.620. Loss: 2.094506025314331\n",
      "training 45.43%: 0.620. Loss: 1.3699826002120972\n",
      "training 45.49%: 0.620. Loss: 1.5874398946762085\n",
      "training 45.55%: 0.620. Loss: 1.6672980785369873\n",
      "training 45.62%: 0.620. Loss: 1.8341166973114014\n",
      "training 45.68%: 0.620. Loss: 1.5359108448028564\n",
      "training 45.75%: 0.620. Loss: 1.5663102865219116\n",
      "training 45.81%: 0.620. Loss: 1.7425459623336792\n",
      "training 45.87%: 0.620. Loss: 1.2522188425064087\n",
      "training 45.94%: 0.620. Loss: 1.1464104652404785\n",
      "training 46.00%: 0.620. Loss: 1.5394519567489624\n",
      "training 46.07%: 0.620. Loss: 2.08408260345459\n",
      "training 46.13%: 0.620. Loss: 1.591566801071167\n",
      "training 46.19%: 0.620. Loss: 1.4655216932296753\n",
      "training 46.26%: 0.620. Loss: 1.6919711828231812\n",
      "training 46.32%: 0.619. Loss: 1.6802114248275757\n",
      "training 46.39%: 0.619. Loss: 1.8192481994628906\n",
      "training 46.45%: 0.619. Loss: 1.5618406534194946\n",
      "training 46.51%: 0.619. Loss: 2.0465526580810547\n",
      "training 46.58%: 0.619. Loss: 1.6252851486206055\n",
      "training 46.64%: 0.619. Loss: 1.1983363628387451\n",
      "training 46.71%: 0.619. Loss: 1.1292740106582642\n",
      "training 46.77%: 0.619. Loss: 1.7237485647201538\n",
      "training 46.83%: 0.619. Loss: 1.6368496417999268\n",
      "training 46.90%: 0.619. Loss: 1.159497857093811\n",
      "training 46.96%: 0.619. Loss: 1.0258128643035889\n",
      "training 47.02%: 0.620. Loss: 1.1634783744812012\n",
      "training 47.09%: 0.620. Loss: 1.5267605781555176\n",
      "training 47.15%: 0.620. Loss: 1.4302629232406616\n",
      "training 47.22%: 0.619. Loss: 2.192302942276001\n",
      "training 47.28%: 0.619. Loss: 1.548613429069519\n",
      "training 47.34%: 0.619. Loss: 1.419533133506775\n",
      "training 47.41%: 0.619. Loss: 1.1986432075500488\n",
      "training 47.47%: 0.619. Loss: 1.7484409809112549\n",
      "training 47.54%: 0.619. Loss: 1.7674115896224976\n",
      "training 47.60%: 0.619. Loss: 1.243788719177246\n",
      "training 47.66%: 0.619. Loss: 1.5275542736053467\n",
      "training 47.73%: 0.619. Loss: 0.9937782883644104\n",
      "training 47.79%: 0.619. Loss: 1.8313348293304443\n",
      "training 47.86%: 0.619. Loss: 1.7197314500808716\n",
      "training 47.92%: 0.619. Loss: 1.6956276893615723\n",
      "training 47.98%: 0.619. Loss: 1.5370066165924072\n",
      "training 48.05%: 0.619. Loss: 1.718153715133667\n",
      "training 48.11%: 0.619. Loss: 1.450918197631836\n",
      "training 48.18%: 0.619. Loss: 1.527895212173462\n",
      "training 48.24%: 0.619. Loss: 1.65970778465271\n",
      "training 48.30%: 0.619. Loss: 1.3645224571228027\n",
      "training 48.37%: 0.620. Loss: 1.2982321977615356\n",
      "training 48.43%: 0.620. Loss: 1.7004656791687012\n",
      "training 48.50%: 0.620. Loss: 1.6744298934936523\n",
      "training 48.56%: 0.619. Loss: 1.644372582435608\n",
      "training 48.62%: 0.619. Loss: 1.5223469734191895\n",
      "training 48.69%: 0.619. Loss: 1.4946743249893188\n",
      "training 48.75%: 0.619. Loss: 1.5781190395355225\n",
      "training 48.82%: 0.619. Loss: 1.460349440574646\n",
      "training 48.88%: 0.619. Loss: 1.6034702062606812\n",
      "training 48.94%: 0.620. Loss: 1.3200275897979736\n",
      "training 49.01%: 0.619. Loss: 1.82866370677948\n",
      "training 49.07%: 0.619. Loss: 1.1836578845977783\n",
      "training 49.14%: 0.619. Loss: 1.695426344871521\n",
      "training 49.20%: 0.619. Loss: 1.5563132762908936\n",
      "training 49.26%: 0.619. Loss: 1.426727294921875\n",
      "training 49.33%: 0.619. Loss: 1.2819268703460693\n",
      "training 49.39%: 0.619. Loss: 1.4265682697296143\n",
      "training 49.46%: 0.619. Loss: 1.7981513738632202\n",
      "training 49.52%: 0.619. Loss: 1.256136178970337\n",
      "training 49.58%: 0.619. Loss: 1.460989236831665\n",
      "training 49.65%: 0.619. Loss: 1.271400809288025\n",
      "training 49.71%: 0.619. Loss: 1.9691052436828613\n",
      "training 49.78%: 0.619. Loss: 1.7647366523742676\n",
      "training 49.84%: 0.619. Loss: 2.135502576828003\n",
      "training 49.90%: 0.619. Loss: 1.6485662460327148\n",
      "training 49.97%: 0.619. Loss: 1.5981131792068481\n",
      "training 50.03%: 0.619. Loss: 1.5267388820648193\n",
      "training 50.10%: 0.619. Loss: 1.7423087358474731\n",
      "training 50.16%: 0.619. Loss: 1.4625588655471802\n",
      "training 50.22%: 0.619. Loss: 1.8216136693954468\n",
      "training 50.29%: 0.619. Loss: 1.1874046325683594\n",
      "training 50.35%: 0.619. Loss: 1.3876489400863647\n",
      "training 50.42%: 0.619. Loss: 1.9974679946899414\n",
      "training 50.48%: 0.619. Loss: 1.575212836265564\n",
      "training 50.54%: 0.619. Loss: 1.9250551462173462\n",
      "training 50.61%: 0.619. Loss: 1.2553720474243164\n",
      "training 50.67%: 0.618. Loss: 1.8645853996276855\n",
      "training 50.74%: 0.618. Loss: 1.720106840133667\n",
      "training 50.80%: 0.619. Loss: 1.3827821016311646\n",
      "training 50.86%: 0.619. Loss: 1.3348488807678223\n",
      "training 50.93%: 0.619. Loss: 1.4001362323760986\n",
      "training 50.99%: 0.618. Loss: 1.8017055988311768\n",
      "training 51.06%: 0.618. Loss: 1.8317986726760864\n",
      "training 51.12%: 0.618. Loss: 1.2900391817092896\n",
      "training 51.18%: 0.618. Loss: 1.7322983741760254\n",
      "training 51.25%: 0.619. Loss: 1.2584139108657837\n",
      "training 51.31%: 0.618. Loss: 1.719438076019287\n",
      "training 51.38%: 0.618. Loss: 1.49781334400177\n",
      "training 51.44%: 0.618. Loss: 1.5848476886749268\n",
      "training 51.50%: 0.618. Loss: 1.7665389776229858\n",
      "training 51.57%: 0.618. Loss: 1.5070313215255737\n",
      "training 51.63%: 0.618. Loss: 1.655391812324524\n",
      "training 51.70%: 0.619. Loss: 1.4724622964859009\n",
      "training 51.76%: 0.618. Loss: 1.5299674272537231\n",
      "training 51.82%: 0.618. Loss: 1.497455358505249\n",
      "training 51.89%: 0.618. Loss: 1.9154274463653564\n",
      "training 51.95%: 0.618. Loss: 1.2361538410186768\n",
      "training 52.02%: 0.618. Loss: 1.4008439779281616\n",
      "training 52.08%: 0.619. Loss: 1.4101734161376953\n",
      "training 52.14%: 0.618. Loss: 1.9184726476669312\n",
      "training 52.21%: 0.618. Loss: 1.6545811891555786\n",
      "training 52.27%: 0.618. Loss: 1.7812045812606812\n",
      "training 52.34%: 0.618. Loss: 1.357596516609192\n",
      "training 52.40%: 0.618. Loss: 1.6984832286834717\n",
      "training 52.46%: 0.618. Loss: 1.5463838577270508\n",
      "training 52.53%: 0.618. Loss: 1.9083689451217651\n",
      "training 52.59%: 0.618. Loss: 1.4074674844741821\n",
      "training 52.66%: 0.619. Loss: 1.2978535890579224\n",
      "training 52.72%: 0.619. Loss: 1.584953784942627\n",
      "training 52.78%: 0.619. Loss: 1.5121276378631592\n",
      "training 52.85%: 0.619. Loss: 1.4818047285079956\n",
      "training 52.91%: 0.619. Loss: 1.5155930519104004\n",
      "training 52.98%: 0.619. Loss: 1.4471216201782227\n",
      "training 53.04%: 0.619. Loss: 1.002791166305542\n",
      "training 53.10%: 0.619. Loss: 1.7798317670822144\n",
      "training 53.17%: 0.619. Loss: 1.4577797651290894\n",
      "training 53.23%: 0.619. Loss: 1.9413232803344727\n",
      "training 53.29%: 0.618. Loss: 1.896113634109497\n",
      "training 53.36%: 0.618. Loss: 1.8751920461654663\n",
      "training 53.42%: 0.618. Loss: 1.5632511377334595\n",
      "training 53.49%: 0.618. Loss: 1.1745012998580933\n",
      "training 53.55%: 0.618. Loss: 1.7870604991912842\n",
      "training 53.61%: 0.618. Loss: 1.2680704593658447\n",
      "training 53.68%: 0.618. Loss: 1.802713394165039\n",
      "training 53.74%: 0.618. Loss: 1.8998749256134033\n",
      "training 53.81%: 0.618. Loss: 0.924705445766449\n",
      "training 53.87%: 0.618. Loss: 1.3415088653564453\n",
      "training 53.93%: 0.618. Loss: 1.6940288543701172\n",
      "training 54.00%: 0.618. Loss: 1.6386293172836304\n",
      "training 54.06%: 0.618. Loss: 1.2117469310760498\n",
      "training 54.13%: 0.618. Loss: 0.9591737389564514\n",
      "training 54.19%: 0.619. Loss: 1.3482228517532349\n",
      "training 54.25%: 0.619. Loss: 1.3246128559112549\n",
      "training 54.32%: 0.618. Loss: 1.5170369148254395\n",
      "training 54.38%: 0.618. Loss: 1.6679372787475586\n",
      "training 54.45%: 0.619. Loss: 1.1289416551589966\n",
      "training 54.51%: 0.618. Loss: 2.0092501640319824\n",
      "training 54.57%: 0.618. Loss: 1.5334209203720093\n",
      "training 54.64%: 0.618. Loss: 1.491034984588623\n",
      "training 54.70%: 0.618. Loss: 1.5295405387878418\n",
      "training 54.77%: 0.618. Loss: 2.0790188312530518\n",
      "training 54.83%: 0.618. Loss: 1.8397541046142578\n",
      "training 54.89%: 0.618. Loss: 1.4403432607650757\n",
      "training 54.96%: 0.618. Loss: 1.226616621017456\n",
      "training 55.02%: 0.618. Loss: 1.9628255367279053\n",
      "training 55.09%: 0.618. Loss: 1.4432250261306763\n",
      "training 55.15%: 0.618. Loss: 2.1089491844177246\n",
      "training 55.21%: 0.618. Loss: 1.5061928033828735\n",
      "training 55.28%: 0.618. Loss: 1.4234235286712646\n",
      "training 55.34%: 0.618. Loss: 1.3822063207626343\n",
      "training 55.41%: 0.618. Loss: 1.3846962451934814\n",
      "training 55.47%: 0.618. Loss: 1.7074321508407593\n",
      "training 55.53%: 0.618. Loss: 1.3577464818954468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 55.60%: 0.618. Loss: 1.086775541305542\n",
      "training 55.66%: 0.618. Loss: 1.7581803798675537\n",
      "training 55.73%: 0.618. Loss: 1.9565484523773193\n",
      "training 55.79%: 0.618. Loss: 1.313215970993042\n",
      "training 55.85%: 0.618. Loss: 1.3632370233535767\n",
      "training 55.92%: 0.618. Loss: 1.4562592506408691\n",
      "training 55.98%: 0.618. Loss: 1.4136383533477783\n",
      "training 56.05%: 0.618. Loss: 1.8304728269577026\n",
      "training 56.11%: 0.618. Loss: 1.3304229974746704\n",
      "training 56.17%: 0.618. Loss: 1.4625149965286255\n",
      "training 56.24%: 0.618. Loss: 1.2608624696731567\n",
      "training 56.30%: 0.618. Loss: 1.5786036252975464\n",
      "training 56.37%: 0.618. Loss: 1.456803321838379\n",
      "training 56.43%: 0.618. Loss: 1.6553345918655396\n",
      "training 56.49%: 0.618. Loss: 1.546221375465393\n",
      "training 56.56%: 0.618. Loss: 1.4330544471740723\n",
      "training 56.62%: 0.618. Loss: 0.9583258032798767\n",
      "training 56.69%: 0.618. Loss: 1.7582428455352783\n",
      "training 56.75%: 0.618. Loss: 1.3389943838119507\n",
      "training 56.81%: 0.618. Loss: 1.2905161380767822\n",
      "training 56.88%: 0.618. Loss: 1.8524703979492188\n",
      "training 56.94%: 0.618. Loss: 1.2910592555999756\n",
      "training 57.01%: 0.619. Loss: 1.29105544090271\n",
      "training 57.07%: 0.619. Loss: 1.2548573017120361\n",
      "training 57.13%: 0.619. Loss: 1.184827208518982\n",
      "training 57.20%: 0.619. Loss: 1.4803516864776611\n",
      "training 57.26%: 0.619. Loss: 1.3751238584518433\n",
      "training 57.33%: 0.619. Loss: 1.5724165439605713\n",
      "training 57.39%: 0.619. Loss: 1.402743935585022\n",
      "training 57.45%: 0.619. Loss: 1.5994452238082886\n",
      "training 57.52%: 0.619. Loss: 1.5143882036209106\n",
      "training 57.58%: 0.619. Loss: 1.4301725625991821\n",
      "training 57.65%: 0.619. Loss: 1.0810320377349854\n",
      "training 57.71%: 0.619. Loss: 1.8354380130767822\n",
      "training 57.77%: 0.619. Loss: 1.8006985187530518\n",
      "training 57.84%: 0.619. Loss: 1.4546945095062256\n",
      "training 57.90%: 0.618. Loss: 1.9864516258239746\n",
      "training 57.97%: 0.619. Loss: 1.5232460498809814\n",
      "training 58.03%: 0.618. Loss: 1.5951337814331055\n",
      "training 58.09%: 0.618. Loss: 1.5659980773925781\n",
      "training 58.16%: 0.619. Loss: 1.188090205192566\n",
      "training 58.22%: 0.619. Loss: 1.644243836402893\n",
      "training 58.29%: 0.618. Loss: 1.987188458442688\n",
      "training 58.35%: 0.618. Loss: 1.6918894052505493\n",
      "training 58.41%: 0.618. Loss: 1.3449366092681885\n",
      "training 58.48%: 0.618. Loss: 1.417057991027832\n",
      "training 58.54%: 0.619. Loss: 1.0175561904907227\n",
      "training 58.61%: 0.618. Loss: 1.5544596910476685\n",
      "training 58.67%: 0.618. Loss: 1.6830267906188965\n",
      "training 58.73%: 0.618. Loss: 1.3859021663665771\n",
      "training 58.80%: 0.619. Loss: 1.336085557937622\n",
      "training 58.86%: 0.619. Loss: 1.6473345756530762\n",
      "training 58.93%: 0.618. Loss: 1.9007675647735596\n",
      "training 58.99%: 0.618. Loss: 1.331234097480774\n",
      "training 59.05%: 0.618. Loss: 1.5961940288543701\n",
      "training 59.12%: 0.618. Loss: 1.3686940670013428\n",
      "training 59.18%: 0.618. Loss: 0.9559819102287292\n",
      "training 59.25%: 0.618. Loss: 1.7719299793243408\n",
      "training 59.31%: 0.618. Loss: 1.3244858980178833\n",
      "training 59.37%: 0.619. Loss: 1.237550973892212\n",
      "training 59.44%: 0.619. Loss: 1.4709913730621338\n",
      "training 59.50%: 0.619. Loss: 1.3500561714172363\n",
      "training 59.56%: 0.619. Loss: 1.6869697570800781\n",
      "training 59.63%: 0.619. Loss: 1.295613408088684\n",
      "training 59.69%: 0.619. Loss: 2.0569560527801514\n",
      "training 59.76%: 0.618. Loss: 1.8406965732574463\n",
      "training 59.82%: 0.618. Loss: 1.5801843404769897\n",
      "training 59.88%: 0.618. Loss: 1.336958885192871\n",
      "training 59.95%: 0.618. Loss: 1.482435941696167\n",
      "training 60.01%: 0.619. Loss: 1.254802942276001\n",
      "training 60.08%: 0.619. Loss: 1.112148404121399\n",
      "training 60.14%: 0.619. Loss: 1.4336764812469482\n",
      "training 60.20%: 0.619. Loss: 1.1633737087249756\n",
      "training 60.27%: 0.619. Loss: 1.2852487564086914\n",
      "training 60.33%: 0.619. Loss: 1.7991490364074707\n",
      "training 60.40%: 0.619. Loss: 1.5514392852783203\n",
      "training 60.46%: 0.619. Loss: 1.3903093338012695\n",
      "training 60.52%: 0.619. Loss: 1.6262996196746826\n",
      "training 60.59%: 0.619. Loss: 1.6483142375946045\n",
      "training 60.65%: 0.618. Loss: 1.6199181079864502\n",
      "training 60.72%: 0.618. Loss: 1.7195466756820679\n",
      "training 60.78%: 0.618. Loss: 1.2643996477127075\n",
      "training 60.84%: 0.618. Loss: 1.5359420776367188\n",
      "training 60.91%: 0.618. Loss: 1.6403058767318726\n",
      "training 60.97%: 0.618. Loss: 1.581437587738037\n",
      "training 61.04%: 0.618. Loss: 1.496201753616333\n",
      "training 61.10%: 0.618. Loss: 1.1728386878967285\n",
      "training 61.16%: 0.618. Loss: 1.7643183469772339\n",
      "training 61.23%: 0.618. Loss: 1.4039686918258667\n",
      "training 61.29%: 0.618. Loss: 1.370729684829712\n",
      "training 61.36%: 0.618. Loss: 1.2748104333877563\n",
      "training 61.42%: 0.618. Loss: 1.8732645511627197\n",
      "training 61.48%: 0.618. Loss: 1.4758044481277466\n",
      "training 61.55%: 0.618. Loss: 1.3367890119552612\n",
      "training 61.61%: 0.618. Loss: 1.281671166419983\n",
      "training 61.68%: 0.618. Loss: 1.778356909751892\n",
      "training 61.74%: 0.618. Loss: 1.8410593271255493\n",
      "training 61.80%: 0.618. Loss: 1.545636534690857\n",
      "training 61.87%: 0.618. Loss: 1.7037103176116943\n",
      "training 61.93%: 0.618. Loss: 1.222438931465149\n",
      "training 62.00%: 0.618. Loss: 1.7668017148971558\n",
      "training 62.06%: 0.618. Loss: 2.107867956161499\n",
      "training 62.12%: 0.618. Loss: 1.570659875869751\n",
      "training 62.19%: 0.618. Loss: 1.2203404903411865\n",
      "training 62.25%: 0.618. Loss: 1.1227538585662842\n",
      "training 62.32%: 0.618. Loss: 1.9444267749786377\n",
      "training 62.38%: 0.618. Loss: 1.767930269241333\n",
      "training 62.44%: 0.618. Loss: 1.8907508850097656\n",
      "training 62.51%: 0.618. Loss: 1.7314131259918213\n",
      "training 62.57%: 0.618. Loss: 1.6571578979492188\n",
      "training 62.64%: 0.618. Loss: 1.920115351676941\n",
      "training 62.70%: 0.618. Loss: 1.4369903802871704\n",
      "training 62.76%: 0.618. Loss: 1.3677994012832642\n",
      "training 62.83%: 0.618. Loss: 1.7301690578460693\n",
      "training 62.89%: 0.618. Loss: 1.5003827810287476\n",
      "training 62.96%: 0.618. Loss: 1.4204463958740234\n",
      "training 63.02%: 0.618. Loss: 1.787084937095642\n",
      "training 63.08%: 0.618. Loss: 1.7511626482009888\n",
      "training 63.15%: 0.617. Loss: 1.8712174892425537\n",
      "training 63.21%: 0.617. Loss: 2.0363550186157227\n",
      "training 63.28%: 0.617. Loss: 1.3454725742340088\n",
      "training 63.34%: 0.617. Loss: 1.8081111907958984\n",
      "training 63.40%: 0.617. Loss: 1.5120962858200073\n",
      "training 63.47%: 0.617. Loss: 1.3982770442962646\n",
      "training 63.53%: 0.617. Loss: 1.5041948556900024\n",
      "training 63.60%: 0.617. Loss: 1.391559362411499\n",
      "training 63.66%: 0.617. Loss: 1.6159515380859375\n",
      "training 63.72%: 0.617. Loss: 1.5931835174560547\n",
      "training 63.79%: 0.617. Loss: 1.5956928730010986\n",
      "training 63.85%: 0.617. Loss: 1.385553002357483\n",
      "training 63.92%: 0.617. Loss: 1.9175851345062256\n",
      "training 63.98%: 0.617. Loss: 1.8833237886428833\n",
      "training 64.04%: 0.617. Loss: 1.9537361860275269\n",
      "training 64.11%: 0.617. Loss: 1.4562885761260986\n",
      "training 64.17%: 0.617. Loss: 1.5236562490463257\n",
      "training 64.24%: 0.617. Loss: 1.4600660800933838\n",
      "training 64.30%: 0.617. Loss: 1.5925486087799072\n",
      "training 64.36%: 0.617. Loss: 1.6456894874572754\n",
      "training 64.43%: 0.617. Loss: 2.0999250411987305\n",
      "training 64.49%: 0.617. Loss: 0.992451012134552\n",
      "training 64.56%: 0.617. Loss: 1.8122239112854004\n",
      "training 64.62%: 0.617. Loss: 1.4985021352767944\n",
      "training 64.68%: 0.617. Loss: 1.3721070289611816\n",
      "training 64.75%: 0.617. Loss: 1.5639255046844482\n",
      "training 64.81%: 0.617. Loss: 1.4879781007766724\n",
      "training 64.88%: 0.617. Loss: 1.6819865703582764\n",
      "training 64.94%: 0.617. Loss: 1.3531479835510254\n",
      "training 65.00%: 0.617. Loss: 1.5699093341827393\n",
      "training 65.07%: 0.617. Loss: 1.784338355064392\n",
      "training 65.13%: 0.617. Loss: 1.5804328918457031\n",
      "training 65.20%: 0.617. Loss: 1.2757514715194702\n",
      "training 65.26%: 0.617. Loss: 2.029066801071167\n",
      "training 65.32%: 0.617. Loss: 1.5791385173797607\n",
      "training 65.39%: 0.617. Loss: 1.7334349155426025\n",
      "training 65.45%: 0.617. Loss: 1.7323784828186035\n",
      "training 65.52%: 0.617. Loss: 1.6584653854370117\n",
      "training 65.58%: 0.617. Loss: 1.456598162651062\n",
      "training 65.64%: 0.617. Loss: 1.591020941734314\n",
      "training 65.71%: 0.617. Loss: 1.713366985321045\n",
      "training 65.77%: 0.617. Loss: 1.4257500171661377\n",
      "training 65.83%: 0.617. Loss: 1.8682420253753662\n",
      "training 65.90%: 0.617. Loss: 1.7413119077682495\n",
      "training 65.96%: 0.616. Loss: 1.9636188745498657\n",
      "training 66.03%: 0.616. Loss: 1.246494174003601\n",
      "training 66.09%: 0.617. Loss: 1.4422634840011597\n",
      "training 66.15%: 0.617. Loss: 1.7647761106491089\n",
      "training 66.22%: 0.616. Loss: 1.7709451913833618\n",
      "training 66.28%: 0.616. Loss: 1.5644375085830688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 66.35%: 0.616. Loss: 1.7260771989822388\n",
      "training 66.41%: 0.616. Loss: 1.517836570739746\n",
      "training 66.47%: 0.616. Loss: 1.6074835062026978\n",
      "training 66.54%: 0.616. Loss: 2.148012638092041\n",
      "training 66.60%: 0.616. Loss: 1.6932945251464844\n",
      "training 66.67%: 0.616. Loss: 1.3809529542922974\n",
      "training 66.73%: 0.616. Loss: 1.5356892347335815\n",
      "training 66.79%: 0.616. Loss: 1.7290701866149902\n",
      "training 66.86%: 0.616. Loss: 1.3907145261764526\n",
      "training 66.92%: 0.616. Loss: 1.5294139385223389\n",
      "training 66.99%: 0.616. Loss: 1.0969734191894531\n",
      "training 67.05%: 0.616. Loss: 1.8549739122390747\n",
      "training 67.11%: 0.616. Loss: 1.398176670074463\n",
      "training 67.18%: 0.617. Loss: 1.0900248289108276\n",
      "training 67.24%: 0.617. Loss: 1.3469382524490356\n",
      "training 67.31%: 0.617. Loss: 1.844017744064331\n",
      "training 67.37%: 0.616. Loss: 1.747990369796753\n",
      "training 67.43%: 0.616. Loss: 1.5660134553909302\n",
      "training 67.50%: 0.616. Loss: 1.4137170314788818\n",
      "training 67.56%: 0.616. Loss: 1.3313990831375122\n",
      "training 67.63%: 0.617. Loss: 1.3136135339736938\n",
      "training 67.69%: 0.617. Loss: 1.3623729944229126\n",
      "training 67.75%: 0.617. Loss: 1.3150347471237183\n",
      "training 67.82%: 0.617. Loss: 1.4564236402511597\n",
      "training 67.88%: 0.617. Loss: 1.3385802507400513\n",
      "training 67.95%: 0.617. Loss: 1.2569594383239746\n",
      "training 68.01%: 0.617. Loss: 1.6159131526947021\n",
      "training 68.07%: 0.617. Loss: 1.4480777978897095\n",
      "training 68.14%: 0.617. Loss: 1.7242940664291382\n",
      "training 68.20%: 0.617. Loss: 1.5022618770599365\n",
      "training 68.27%: 0.617. Loss: 1.7777376174926758\n",
      "training 68.33%: 0.617. Loss: 1.5882532596588135\n",
      "training 68.39%: 0.617. Loss: 1.3071166276931763\n",
      "training 68.46%: 0.617. Loss: 1.7929000854492188\n",
      "training 68.52%: 0.617. Loss: 1.9588382244110107\n",
      "training 68.59%: 0.617. Loss: 1.322904348373413\n",
      "training 68.65%: 0.616. Loss: 1.9598133563995361\n",
      "training 68.71%: 0.616. Loss: 1.2359200716018677\n",
      "training 68.78%: 0.617. Loss: 1.503129482269287\n",
      "training 68.84%: 0.617. Loss: 1.5414049625396729\n",
      "training 68.91%: 0.617. Loss: 1.2232648134231567\n",
      "training 68.97%: 0.617. Loss: 1.508973479270935\n",
      "training 69.03%: 0.617. Loss: 1.511730670928955\n",
      "training 69.10%: 0.617. Loss: 1.9328054189682007\n",
      "training 69.16%: 0.617. Loss: 1.4077028036117554\n",
      "training 69.23%: 0.617. Loss: 1.3375221490859985\n",
      "training 69.29%: 0.617. Loss: 1.3889728784561157\n",
      "training 69.35%: 0.617. Loss: 1.3458558320999146\n",
      "training 69.42%: 0.617. Loss: 1.5216106176376343\n",
      "training 69.48%: 0.617. Loss: 1.5348341464996338\n",
      "training 69.55%: 0.617. Loss: 1.6101667881011963\n",
      "training 69.61%: 0.617. Loss: 1.5091381072998047\n",
      "training 69.67%: 0.617. Loss: 1.7878562211990356\n",
      "training 69.74%: 0.616. Loss: 1.7886545658111572\n",
      "training 69.80%: 0.616. Loss: 1.9347403049468994\n",
      "training 69.87%: 0.617. Loss: 1.457228183746338\n",
      "training 69.93%: 0.616. Loss: 1.847646951675415\n",
      "training 69.99%: 0.616. Loss: 1.6600630283355713\n",
      "training 70.06%: 0.616. Loss: 1.3739111423492432\n",
      "training 70.12%: 0.616. Loss: 2.0031940937042236\n",
      "training 70.19%: 0.616. Loss: 1.7766869068145752\n",
      "training 70.25%: 0.616. Loss: 1.409433126449585\n",
      "training 70.31%: 0.616. Loss: 1.341400146484375\n",
      "training 70.38%: 0.616. Loss: 1.1947208642959595\n",
      "training 70.44%: 0.617. Loss: 1.2981903553009033\n",
      "training 70.51%: 0.616. Loss: 1.7720979452133179\n",
      "training 70.57%: 0.616. Loss: 1.2862114906311035\n",
      "training 70.63%: 0.616. Loss: 1.8342880010604858\n",
      "training 70.70%: 0.616. Loss: 1.6944706439971924\n",
      "training 70.76%: 0.616. Loss: 1.571272373199463\n",
      "training 70.83%: 0.616. Loss: 1.1454942226409912\n",
      "training 70.89%: 0.616. Loss: 1.7849434614181519\n",
      "training 70.95%: 0.616. Loss: 1.8574845790863037\n",
      "training 71.02%: 0.616. Loss: 1.587402582168579\n",
      "training 71.08%: 0.616. Loss: 1.5212513208389282\n",
      "training 71.15%: 0.616. Loss: 1.7338820695877075\n",
      "training 71.21%: 0.616. Loss: 1.0791040658950806\n",
      "training 71.27%: 0.616. Loss: 1.1615736484527588\n",
      "training 71.34%: 0.616. Loss: 1.5652474164962769\n",
      "training 71.40%: 0.616. Loss: 1.4666457176208496\n",
      "training 71.47%: 0.617. Loss: 1.2261172533035278\n",
      "training 71.53%: 0.617. Loss: 1.4765774011611938\n",
      "training 71.59%: 0.617. Loss: 1.3700082302093506\n",
      "training 71.66%: 0.617. Loss: 1.5402781963348389\n",
      "training 71.72%: 0.617. Loss: 1.3600574731826782\n",
      "training 71.79%: 0.617. Loss: 1.061772108078003\n",
      "training 71.85%: 0.617. Loss: 1.6666951179504395\n",
      "training 71.91%: 0.617. Loss: 1.2115854024887085\n",
      "training 71.98%: 0.617. Loss: 1.4581974744796753\n",
      "training 72.04%: 0.617. Loss: 1.1791670322418213\n",
      "training 72.10%: 0.617. Loss: 1.3324267864227295\n",
      "training 72.17%: 0.617. Loss: 1.4344334602355957\n",
      "training 72.23%: 0.617. Loss: 1.8700783252716064\n",
      "training 72.30%: 0.617. Loss: 1.681300401687622\n",
      "training 72.36%: 0.617. Loss: 2.248574733734131\n",
      "training 72.42%: 0.617. Loss: 1.407228708267212\n",
      "training 72.49%: 0.617. Loss: 1.6792048215866089\n",
      "training 72.55%: 0.617. Loss: 1.7323311567306519\n",
      "training 72.62%: 0.617. Loss: 2.0110883712768555\n",
      "training 72.68%: 0.617. Loss: 1.56939697265625\n",
      "training 72.74%: 0.617. Loss: 1.6623728275299072\n",
      "training 72.81%: 0.617. Loss: 1.5288761854171753\n",
      "training 72.87%: 0.617. Loss: 1.5175108909606934\n",
      "training 72.94%: 0.617. Loss: 1.5247036218643188\n",
      "training 73.00%: 0.616. Loss: 1.7911912202835083\n",
      "training 73.06%: 0.616. Loss: 1.0562317371368408\n",
      "training 73.13%: 0.616. Loss: 1.5687286853790283\n",
      "training 73.19%: 0.616. Loss: 1.6418639421463013\n",
      "training 73.26%: 0.617. Loss: 1.284358263015747\n",
      "training 73.32%: 0.617. Loss: 1.3922935724258423\n",
      "training 73.38%: 0.617. Loss: 1.2012405395507812\n",
      "training 73.45%: 0.617. Loss: 1.415850281715393\n",
      "training 73.51%: 0.617. Loss: 1.287861704826355\n",
      "training 73.58%: 0.617. Loss: 1.5993338823318481\n",
      "training 73.64%: 0.617. Loss: 1.296340823173523\n",
      "training 73.70%: 0.617. Loss: 1.5357784032821655\n",
      "training 73.77%: 0.617. Loss: 1.2988203763961792\n",
      "training 73.83%: 0.617. Loss: 1.4048118591308594\n",
      "training 73.90%: 0.617. Loss: 1.6233940124511719\n",
      "training 73.96%: 0.617. Loss: 1.4283565282821655\n",
      "training 74.02%: 0.617. Loss: 1.6078357696533203\n",
      "training 74.09%: 0.617. Loss: 1.8725390434265137\n",
      "training 74.15%: 0.617. Loss: 1.6628398895263672\n",
      "training 74.22%: 0.617. Loss: 1.1061336994171143\n",
      "training 74.28%: 0.617. Loss: 1.5431175231933594\n",
      "training 74.34%: 0.617. Loss: 1.7712349891662598\n",
      "training 74.41%: 0.617. Loss: 1.5934494733810425\n",
      "training 74.47%: 0.617. Loss: 1.369429588317871\n",
      "training 74.54%: 0.617. Loss: 2.032487392425537\n",
      "training 74.60%: 0.617. Loss: 1.8129321336746216\n",
      "training 74.66%: 0.617. Loss: 1.7719498872756958\n",
      "training 74.73%: 0.617. Loss: 1.6572821140289307\n",
      "training 74.79%: 0.617. Loss: 1.4584450721740723\n",
      "training 74.86%: 0.617. Loss: 1.9639934301376343\n",
      "training 74.92%: 0.617. Loss: 1.4527173042297363\n",
      "training 74.98%: 0.617. Loss: 1.759783387184143\n",
      "training 75.05%: 0.617. Loss: 1.51007080078125\n",
      "training 75.11%: 0.617. Loss: 1.6235671043395996\n",
      "training 75.18%: 0.617. Loss: 1.5585616827011108\n",
      "training 75.24%: 0.617. Loss: 1.3423882722854614\n",
      "training 75.30%: 0.617. Loss: 1.5857726335525513\n",
      "training 75.37%: 0.617. Loss: 1.4773848056793213\n",
      "training 75.43%: 0.617. Loss: 1.4441616535186768\n",
      "training 75.50%: 0.617. Loss: 1.5531835556030273\n",
      "training 75.56%: 0.616. Loss: 1.863834023475647\n",
      "training 75.62%: 0.616. Loss: 1.660128116607666\n",
      "training 75.69%: 0.616. Loss: 1.1309306621551514\n",
      "training 75.75%: 0.616. Loss: 1.7503464221954346\n",
      "training 75.82%: 0.616. Loss: 1.2627145051956177\n",
      "training 75.88%: 0.616. Loss: 1.7219688892364502\n",
      "training 75.94%: 0.616. Loss: 1.6007980108261108\n",
      "training 76.01%: 0.616. Loss: 1.3216632604599\n",
      "training 76.07%: 0.616. Loss: 1.4925228357315063\n",
      "training 76.14%: 0.616. Loss: 1.6281377077102661\n",
      "training 76.20%: 0.616. Loss: 1.5787056684494019\n",
      "training 76.26%: 0.616. Loss: 1.921173334121704\n",
      "training 76.33%: 0.616. Loss: 1.7138468027114868\n",
      "training 76.39%: 0.616. Loss: 1.4922146797180176\n",
      "training 76.46%: 0.616. Loss: 1.306048035621643\n",
      "training 76.52%: 0.616. Loss: 1.4147685766220093\n",
      "training 76.58%: 0.616. Loss: 1.5370967388153076\n",
      "training 76.65%: 0.616. Loss: 1.4499175548553467\n",
      "training 76.71%: 0.616. Loss: 1.998875379562378\n",
      "training 76.78%: 0.616. Loss: 2.1518895626068115\n",
      "training 76.84%: 0.616. Loss: 1.5476099252700806\n",
      "training 76.90%: 0.616. Loss: 1.4164315462112427\n",
      "training 76.97%: 0.616. Loss: 1.1437867879867554\n",
      "training 77.03%: 0.616. Loss: 1.1679407358169556\n",
      "training 77.10%: 0.616. Loss: 1.017234444618225\n",
      "training 77.16%: 0.616. Loss: 1.7378684282302856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 77.22%: 0.616. Loss: 1.2450282573699951\n",
      "training 77.29%: 0.616. Loss: 1.9853016138076782\n",
      "training 77.35%: 0.616. Loss: 1.615322232246399\n",
      "training 77.42%: 0.616. Loss: 1.556884527206421\n",
      "training 77.48%: 0.616. Loss: 1.603930950164795\n",
      "training 77.54%: 0.616. Loss: 1.51432204246521\n",
      "training 77.61%: 0.616. Loss: 1.6870684623718262\n",
      "training 77.67%: 0.616. Loss: 1.2451647520065308\n",
      "training 77.74%: 0.616. Loss: 1.5473415851593018\n",
      "training 77.80%: 0.616. Loss: 1.3959099054336548\n",
      "training 77.86%: 0.616. Loss: 1.1702029705047607\n",
      "training 77.93%: 0.616. Loss: 1.7095575332641602\n",
      "training 77.99%: 0.616. Loss: 1.6690846681594849\n",
      "training 78.06%: 0.616. Loss: 1.3697874546051025\n",
      "training 78.12%: 0.616. Loss: 1.6511517763137817\n",
      "training 78.18%: 0.616. Loss: 1.639907956123352\n",
      "training 78.25%: 0.616. Loss: 1.441802740097046\n",
      "training 78.31%: 0.616. Loss: 1.7300872802734375\n",
      "training 78.37%: 0.616. Loss: 1.7398924827575684\n",
      "training 78.44%: 0.616. Loss: 1.2852593660354614\n",
      "training 78.50%: 0.616. Loss: 1.916367530822754\n",
      "training 78.57%: 0.616. Loss: 1.1053340435028076\n",
      "training 78.63%: 0.616. Loss: 1.4612632989883423\n",
      "training 78.69%: 0.616. Loss: 1.5222736597061157\n",
      "training 78.76%: 0.616. Loss: 1.7121626138687134\n",
      "training 78.82%: 0.616. Loss: 1.218140959739685\n",
      "training 78.89%: 0.616. Loss: 1.319356083869934\n",
      "training 78.95%: 0.616. Loss: 1.731815218925476\n",
      "training 79.01%: 0.616. Loss: 1.4618425369262695\n",
      "training 79.08%: 0.616. Loss: 1.022276520729065\n",
      "training 79.14%: 0.616. Loss: 1.254611849784851\n",
      "training 79.21%: 0.616. Loss: 2.1893861293792725\n",
      "training 79.27%: 0.616. Loss: 1.4391027688980103\n",
      "training 79.33%: 0.616. Loss: 1.8569344282150269\n",
      "training 79.40%: 0.616. Loss: 1.5407081842422485\n",
      "training 79.46%: 0.616. Loss: 1.6445939540863037\n",
      "training 79.53%: 0.616. Loss: 1.622793197631836\n",
      "training 79.59%: 0.616. Loss: 1.930344820022583\n",
      "training 79.65%: 0.616. Loss: 1.1910063028335571\n",
      "training 79.72%: 0.616. Loss: 1.950534701347351\n",
      "training 79.78%: 0.616. Loss: 1.5142382383346558\n",
      "training 79.85%: 0.616. Loss: 1.4433974027633667\n",
      "training 79.91%: 0.616. Loss: 1.3245900869369507\n",
      "training 79.97%: 0.616. Loss: 2.013824701309204\n",
      "training 80.04%: 0.616. Loss: 1.4399720430374146\n",
      "training 80.10%: 0.616. Loss: 1.9940179586410522\n",
      "training 80.17%: 0.616. Loss: 1.272958517074585\n",
      "training 80.23%: 0.616. Loss: 1.6405059099197388\n",
      "training 80.29%: 0.616. Loss: 1.521444320678711\n",
      "training 80.36%: 0.616. Loss: 1.2111835479736328\n",
      "training 80.42%: 0.616. Loss: 1.3561069965362549\n",
      "training 80.49%: 0.616. Loss: 1.9683027267456055\n",
      "training 80.55%: 0.616. Loss: 1.9959118366241455\n",
      "training 80.61%: 0.616. Loss: 1.4591953754425049\n",
      "training 80.68%: 0.616. Loss: 1.7175941467285156\n",
      "training 80.74%: 0.616. Loss: 1.6416573524475098\n",
      "training 80.81%: 0.616. Loss: 1.809241533279419\n",
      "training 80.87%: 0.616. Loss: 1.896143913269043\n",
      "training 80.93%: 0.616. Loss: 1.456412434577942\n",
      "training 81.00%: 0.616. Loss: 1.5428235530853271\n",
      "training 81.06%: 0.616. Loss: 1.6296676397323608\n",
      "training 81.13%: 0.616. Loss: 1.6392929553985596\n",
      "training 81.19%: 0.616. Loss: 2.131953477859497\n",
      "training 81.25%: 0.616. Loss: 1.4417474269866943\n",
      "training 81.32%: 0.616. Loss: 1.1918507814407349\n",
      "training 81.38%: 0.616. Loss: 1.391381025314331\n",
      "training 81.45%: 0.616. Loss: 1.6583614349365234\n",
      "training 81.51%: 0.616. Loss: 1.5014666318893433\n",
      "training 81.57%: 0.616. Loss: 1.6127368211746216\n",
      "training 81.64%: 0.616. Loss: 1.1434574127197266\n",
      "training 81.70%: 0.616. Loss: 1.4623230695724487\n",
      "training 81.77%: 0.616. Loss: 1.4318853616714478\n",
      "training 81.83%: 0.616. Loss: 1.6445188522338867\n",
      "training 81.89%: 0.616. Loss: 1.530855655670166\n",
      "training 81.96%: 0.616. Loss: 1.1960210800170898\n",
      "training 82.02%: 0.616. Loss: 1.6263630390167236\n",
      "training 82.09%: 0.616. Loss: 1.3965753316879272\n",
      "training 82.15%: 0.616. Loss: 1.3170561790466309\n",
      "training 82.21%: 0.616. Loss: 1.4982045888900757\n",
      "training 82.28%: 0.616. Loss: 1.6206849813461304\n",
      "training 82.34%: 0.616. Loss: 1.265599250793457\n",
      "training 82.41%: 0.616. Loss: 1.442657709121704\n",
      "training 82.47%: 0.616. Loss: 1.3643945455551147\n",
      "training 82.53%: 0.616. Loss: 1.20377779006958\n",
      "training 82.60%: 0.616. Loss: 1.5475904941558838\n",
      "training 82.66%: 0.616. Loss: 1.4662374258041382\n",
      "training 82.73%: 0.616. Loss: 1.6900582313537598\n",
      "training 82.79%: 0.616. Loss: 1.5002824068069458\n",
      "training 82.85%: 0.616. Loss: 1.7249397039413452\n",
      "training 82.92%: 0.616. Loss: 1.251652717590332\n",
      "training 82.98%: 0.616. Loss: 1.6114306449890137\n",
      "training 83.05%: 0.616. Loss: 1.5841352939605713\n",
      "training 83.11%: 0.616. Loss: 1.5138102769851685\n",
      "training 83.17%: 0.616. Loss: 1.1415385007858276\n",
      "training 83.24%: 0.616. Loss: 1.476666808128357\n",
      "training 83.30%: 0.616. Loss: 1.7413909435272217\n",
      "training 83.37%: 0.616. Loss: 1.1232141256332397\n",
      "training 83.43%: 0.616. Loss: 1.6462769508361816\n",
      "training 83.49%: 0.616. Loss: 1.5911540985107422\n",
      "training 83.56%: 0.616. Loss: 1.7240352630615234\n",
      "training 83.62%: 0.616. Loss: 1.4546421766281128\n",
      "training 83.69%: 0.616. Loss: 1.5566729307174683\n",
      "training 83.75%: 0.616. Loss: 1.509976863861084\n",
      "training 83.81%: 0.616. Loss: 1.22452974319458\n",
      "training 83.88%: 0.616. Loss: 1.2207696437835693\n",
      "training 83.94%: 0.616. Loss: 1.5342307090759277\n",
      "training 84.01%: 0.616. Loss: 1.399214267730713\n",
      "training 84.07%: 0.616. Loss: 1.5936713218688965\n",
      "training 84.13%: 0.616. Loss: 1.8358017206192017\n",
      "training 84.20%: 0.616. Loss: 1.595373511314392\n",
      "training 84.26%: 0.616. Loss: 1.274554967880249\n",
      "training 84.33%: 0.616. Loss: 1.4831128120422363\n",
      "training 84.39%: 0.616. Loss: 1.665490746498108\n",
      "training 84.45%: 0.616. Loss: 1.7591283321380615\n",
      "training 84.52%: 0.616. Loss: 1.4178528785705566\n",
      "training 84.58%: 0.616. Loss: 1.260239839553833\n",
      "training 84.64%: 0.616. Loss: 1.4575567245483398\n",
      "training 84.71%: 0.616. Loss: 1.7023528814315796\n",
      "training 84.77%: 0.616. Loss: 1.582104206085205\n",
      "training 84.84%: 0.616. Loss: 1.1789659261703491\n",
      "training 84.90%: 0.616. Loss: 1.5695642232894897\n",
      "training 84.96%: 0.616. Loss: 1.5540097951889038\n",
      "training 85.03%: 0.616. Loss: 1.3898125886917114\n",
      "training 85.09%: 0.616. Loss: 1.4410407543182373\n",
      "training 85.16%: 0.616. Loss: 1.6314808130264282\n",
      "training 85.22%: 0.616. Loss: 1.3186203241348267\n",
      "training 85.28%: 0.616. Loss: 1.6725305318832397\n",
      "training 85.35%: 0.616. Loss: 1.0752760171890259\n",
      "training 85.41%: 0.616. Loss: 1.3429362773895264\n",
      "training 85.48%: 0.616. Loss: 1.2725648880004883\n",
      "training 85.54%: 0.616. Loss: 1.62936532497406\n",
      "training 85.60%: 0.616. Loss: 1.7291628122329712\n",
      "training 85.67%: 0.616. Loss: 1.4150561094284058\n",
      "training 85.73%: 0.616. Loss: 1.1720860004425049\n",
      "training 85.80%: 0.616. Loss: 1.7548141479492188\n",
      "training 85.86%: 0.616. Loss: 1.5705137252807617\n",
      "training 85.92%: 0.616. Loss: 1.6637904644012451\n",
      "training 85.99%: 0.616. Loss: 1.669778823852539\n",
      "training 86.05%: 0.616. Loss: 1.318189263343811\n",
      "training 86.12%: 0.616. Loss: 1.8569839000701904\n",
      "training 86.18%: 0.616. Loss: 1.5395538806915283\n",
      "training 86.24%: 0.616. Loss: 1.8206266164779663\n",
      "training 86.31%: 0.616. Loss: 1.693271517753601\n",
      "training 86.37%: 0.616. Loss: 1.3294533491134644\n",
      "training 86.44%: 0.616. Loss: 1.5005813837051392\n",
      "training 86.50%: 0.616. Loss: 1.6769846677780151\n",
      "training 86.56%: 0.616. Loss: 1.6290394067764282\n",
      "training 86.63%: 0.616. Loss: 1.924705147743225\n",
      "training 86.69%: 0.616. Loss: 1.3669856786727905\n",
      "training 86.76%: 0.616. Loss: 1.340308666229248\n",
      "training 86.82%: 0.616. Loss: 1.2252901792526245\n",
      "training 86.88%: 0.616. Loss: 1.4246749877929688\n",
      "training 86.95%: 0.616. Loss: 1.4572995901107788\n",
      "training 87.01%: 0.616. Loss: 1.1641393899917603\n",
      "training 87.08%: 0.616. Loss: 1.174759030342102\n",
      "training 87.14%: 0.616. Loss: 1.3971836566925049\n",
      "training 87.20%: 0.616. Loss: 1.5769786834716797\n",
      "training 87.27%: 0.616. Loss: 1.3185874223709106\n",
      "training 87.33%: 0.616. Loss: 1.6227062940597534\n",
      "training 87.40%: 0.616. Loss: 1.7416858673095703\n",
      "training 87.46%: 0.616. Loss: 1.5118353366851807\n",
      "training 87.52%: 0.616. Loss: 1.6845102310180664\n",
      "training 87.59%: 0.616. Loss: 1.8992960453033447\n",
      "training 87.65%: 0.616. Loss: 1.7222375869750977\n",
      "training 87.72%: 0.616. Loss: 1.073600172996521\n",
      "training 87.78%: 0.616. Loss: 1.1287651062011719\n",
      "training 87.84%: 0.616. Loss: 1.7047665119171143\n",
      "training 87.91%: 0.616. Loss: 1.4604912996292114\n",
      "training 87.97%: 0.616. Loss: 1.5062109231948853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 88.04%: 0.616. Loss: 1.3165076971054077\n",
      "training 88.10%: 0.616. Loss: 1.0994313955307007\n",
      "training 88.16%: 0.616. Loss: 1.5116798877716064\n",
      "training 88.23%: 0.616. Loss: 1.834980845451355\n",
      "training 88.29%: 0.616. Loss: 1.3042057752609253\n",
      "training 88.36%: 0.616. Loss: 1.4792941808700562\n",
      "training 88.42%: 0.616. Loss: 1.7088314294815063\n",
      "training 88.48%: 0.616. Loss: 1.3681834936141968\n",
      "training 88.55%: 0.616. Loss: 1.5164618492126465\n",
      "training 88.61%: 0.616. Loss: 1.8630237579345703\n",
      "training 88.68%: 0.616. Loss: 1.2182987928390503\n",
      "training 88.74%: 0.616. Loss: 1.9465532302856445\n",
      "training 88.80%: 0.616. Loss: 1.8043146133422852\n",
      "training 88.87%: 0.616. Loss: 1.5019612312316895\n",
      "training 88.93%: 0.616. Loss: 0.9712775349617004\n",
      "training 89.00%: 0.616. Loss: 1.5838245153427124\n",
      "training 89.06%: 0.616. Loss: 1.6630302667617798\n",
      "training 89.12%: 0.616. Loss: 1.3496302366256714\n",
      "training 89.19%: 0.616. Loss: 1.7467671632766724\n",
      "training 89.25%: 0.616. Loss: 1.90376615524292\n",
      "training 89.32%: 0.616. Loss: 1.6557191610336304\n",
      "training 89.38%: 0.616. Loss: 2.0774283409118652\n",
      "training 89.44%: 0.616. Loss: 1.7506330013275146\n",
      "training 89.51%: 0.616. Loss: 1.491235613822937\n",
      "training 89.57%: 0.616. Loss: 1.3039494752883911\n",
      "training 89.64%: 0.616. Loss: 1.2987749576568604\n",
      "training 89.70%: 0.616. Loss: 1.2775393724441528\n",
      "training 89.76%: 0.616. Loss: 1.669260859489441\n",
      "training 89.83%: 0.616. Loss: 1.1309869289398193\n",
      "training 89.89%: 0.616. Loss: 1.5551137924194336\n",
      "training 89.96%: 0.616. Loss: 1.7155933380126953\n",
      "training 90.02%: 0.616. Loss: 1.368852972984314\n",
      "training 90.08%: 0.616. Loss: 1.58903169631958\n",
      "training 90.15%: 0.616. Loss: 2.1871635913848877\n",
      "training 90.21%: 0.616. Loss: 1.5082731246948242\n",
      "training 90.28%: 0.616. Loss: 0.8252765536308289\n",
      "training 90.34%: 0.616. Loss: 1.4486804008483887\n",
      "training 90.40%: 0.616. Loss: 1.4314509630203247\n",
      "training 90.47%: 0.616. Loss: 1.5834659337997437\n",
      "training 90.53%: 0.616. Loss: 1.459477186203003\n",
      "training 90.60%: 0.616. Loss: 1.8802099227905273\n",
      "training 90.66%: 0.616. Loss: 1.5560548305511475\n",
      "training 90.72%: 0.616. Loss: 1.2854785919189453\n",
      "training 90.79%: 0.616. Loss: 1.3265200853347778\n",
      "training 90.85%: 0.616. Loss: 1.2913825511932373\n",
      "training 90.91%: 0.616. Loss: 1.6359996795654297\n",
      "training 90.98%: 0.616. Loss: 1.0773149728775024\n",
      "training 91.04%: 0.616. Loss: 1.9683241844177246\n",
      "training 91.11%: 0.616. Loss: 1.7377469539642334\n",
      "training 91.17%: 0.616. Loss: 1.485249400138855\n",
      "training 91.23%: 0.616. Loss: 1.4373470544815063\n",
      "training 91.30%: 0.616. Loss: 1.6045726537704468\n",
      "training 91.36%: 0.616. Loss: 1.4198901653289795\n",
      "training 91.43%: 0.616. Loss: 1.6974246501922607\n",
      "training 91.49%: 0.616. Loss: 1.7198612689971924\n",
      "training 91.55%: 0.616. Loss: 1.1822861433029175\n",
      "training 91.62%: 0.616. Loss: 1.5762414932250977\n",
      "training 91.68%: 0.616. Loss: 1.733370304107666\n",
      "training 91.75%: 0.616. Loss: 2.1951026916503906\n",
      "training 91.81%: 0.616. Loss: 1.9055668115615845\n",
      "training 91.87%: 0.616. Loss: 1.5400301218032837\n",
      "training 91.94%: 0.616. Loss: 1.4606153964996338\n",
      "training 92.00%: 0.616. Loss: 1.3292226791381836\n",
      "training 92.07%: 0.616. Loss: 1.6022181510925293\n",
      "training 92.13%: 0.616. Loss: 1.8764811754226685\n",
      "training 92.19%: 0.616. Loss: 1.474656343460083\n",
      "training 92.26%: 0.616. Loss: 0.9996446967124939\n",
      "training 92.32%: 0.616. Loss: 1.7948989868164062\n",
      "training 92.39%: 0.616. Loss: 1.5431686639785767\n",
      "training 92.45%: 0.616. Loss: 1.7349541187286377\n",
      "training 92.51%: 0.616. Loss: 1.632053017616272\n",
      "training 92.58%: 0.616. Loss: 1.7289385795593262\n",
      "training 92.64%: 0.616. Loss: 1.5713682174682617\n",
      "training 92.71%: 0.616. Loss: 1.6552051305770874\n",
      "training 92.77%: 0.616. Loss: 1.4848405122756958\n",
      "training 92.83%: 0.616. Loss: 1.6903618574142456\n",
      "training 92.90%: 0.616. Loss: 1.8939242362976074\n",
      "training 92.96%: 0.616. Loss: 1.5113717317581177\n",
      "training 93.03%: 0.616. Loss: 1.42561674118042\n",
      "training 93.09%: 0.616. Loss: 1.7144185304641724\n",
      "training 93.15%: 0.616. Loss: 1.3680078983306885\n",
      "training 93.22%: 0.616. Loss: 1.5726622343063354\n",
      "training 93.28%: 0.616. Loss: 1.469468355178833\n",
      "training 93.35%: 0.616. Loss: 1.7187190055847168\n",
      "training 93.41%: 0.616. Loss: 1.7733044624328613\n",
      "training 93.47%: 0.616. Loss: 1.633715271949768\n",
      "training 93.54%: 0.616. Loss: 1.546600341796875\n",
      "training 93.60%: 0.616. Loss: 1.7380815744400024\n",
      "training 93.67%: 0.616. Loss: 2.035557270050049\n",
      "training 93.73%: 0.616. Loss: 2.0011491775512695\n",
      "training 93.79%: 0.616. Loss: 1.6608381271362305\n",
      "training 93.86%: 0.616. Loss: 1.701311707496643\n",
      "training 93.92%: 0.616. Loss: 1.5315542221069336\n",
      "training 93.99%: 0.616. Loss: 1.390384316444397\n",
      "training 94.05%: 0.616. Loss: 1.4815319776535034\n",
      "training 94.11%: 0.616. Loss: 1.684568166732788\n",
      "training 94.18%: 0.616. Loss: 1.4245082139968872\n",
      "training 94.24%: 0.616. Loss: 1.8116178512573242\n",
      "training 94.31%: 0.616. Loss: 1.447506070137024\n",
      "training 94.37%: 0.616. Loss: 1.3808187246322632\n",
      "training 94.43%: 0.616. Loss: 2.1128201484680176\n",
      "training 94.50%: 0.616. Loss: 1.6773229837417603\n",
      "training 94.56%: 0.616. Loss: 1.6354100704193115\n",
      "training 94.63%: 0.616. Loss: 1.6292762756347656\n",
      "training 94.69%: 0.616. Loss: 1.481150507926941\n",
      "training 94.75%: 0.615. Loss: 1.823499321937561\n",
      "training 94.82%: 0.615. Loss: 1.7722467184066772\n",
      "training 94.88%: 0.616. Loss: 1.1341040134429932\n",
      "training 94.95%: 0.615. Loss: 1.6659055948257446\n",
      "training 95.01%: 0.616. Loss: 1.222368836402893\n",
      "training 95.07%: 0.616. Loss: 1.2374968528747559\n",
      "training 95.14%: 0.616. Loss: 1.6978332996368408\n",
      "training 95.20%: 0.616. Loss: 1.8914713859558105\n",
      "training 95.27%: 0.616. Loss: 1.3203567266464233\n",
      "training 95.33%: 0.616. Loss: 1.2425168752670288\n",
      "training 95.39%: 0.616. Loss: 1.373891830444336\n",
      "training 95.46%: 0.616. Loss: 2.098452568054199\n",
      "training 95.52%: 0.616. Loss: 1.7696726322174072\n",
      "training 95.59%: 0.616. Loss: 1.3468629121780396\n",
      "training 95.65%: 0.616. Loss: 1.45402193069458\n",
      "training 95.71%: 0.616. Loss: 1.5386775732040405\n",
      "training 95.78%: 0.616. Loss: 1.440911889076233\n",
      "training 95.84%: 0.616. Loss: 1.9481630325317383\n",
      "training 95.91%: 0.616. Loss: 1.700043797492981\n",
      "training 95.97%: 0.616. Loss: 1.5887970924377441\n",
      "training 96.03%: 0.615. Loss: 1.7963577508926392\n",
      "training 96.10%: 0.616. Loss: 1.3174598217010498\n",
      "training 96.16%: 0.616. Loss: 1.7256550788879395\n",
      "training 96.23%: 0.615. Loss: 1.9458187818527222\n",
      "training 96.29%: 0.615. Loss: 1.4675850868225098\n",
      "training 96.35%: 0.616. Loss: 1.2521287202835083\n",
      "training 96.42%: 0.616. Loss: 1.3204156160354614\n",
      "training 96.48%: 0.616. Loss: 1.8079484701156616\n",
      "training 96.55%: 0.615. Loss: 1.6281561851501465\n",
      "training 96.61%: 0.615. Loss: 1.854787826538086\n",
      "training 96.67%: 0.615. Loss: 1.706520438194275\n",
      "training 96.74%: 0.615. Loss: 1.4155762195587158\n",
      "training 96.80%: 0.615. Loss: 0.9541255831718445\n",
      "training 96.87%: 0.615. Loss: 1.6896824836730957\n",
      "training 96.93%: 0.616. Loss: 1.427130937576294\n",
      "training 96.99%: 0.616. Loss: 1.2043365240097046\n",
      "training 97.06%: 0.616. Loss: 1.8233178853988647\n",
      "training 97.12%: 0.615. Loss: 2.1484453678131104\n",
      "training 97.18%: 0.615. Loss: 1.671457290649414\n",
      "training 97.25%: 0.615. Loss: 1.8066177368164062\n",
      "training 97.31%: 0.616. Loss: 1.0829362869262695\n",
      "training 97.38%: 0.616. Loss: 1.639378547668457\n",
      "training 97.44%: 0.616. Loss: 1.7658889293670654\n",
      "training 97.50%: 0.616. Loss: 1.5033093690872192\n",
      "training 97.57%: 0.615. Loss: 1.925972580909729\n",
      "training 97.63%: 0.615. Loss: 1.5182337760925293\n",
      "training 97.70%: 0.615. Loss: 1.3276900053024292\n",
      "training 97.76%: 0.615. Loss: 1.9020006656646729\n",
      "training 97.82%: 0.615. Loss: 1.6403313875198364\n",
      "training 97.89%: 0.615. Loss: 1.6065397262573242\n",
      "training 97.95%: 0.615. Loss: 1.8094929456710815\n",
      "training 98.02%: 0.615. Loss: 1.5712502002716064\n",
      "training 98.08%: 0.615. Loss: 1.219767451286316\n",
      "training 98.14%: 0.615. Loss: 1.3516337871551514\n",
      "training 98.21%: 0.616. Loss: 1.4287513494491577\n",
      "training 98.27%: 0.615. Loss: 1.6490098237991333\n",
      "training 98.34%: 0.615. Loss: 1.7899894714355469\n",
      "training 98.40%: 0.616. Loss: 1.0938057899475098\n",
      "training 98.46%: 0.616. Loss: 1.5519802570343018\n",
      "training 98.53%: 0.616. Loss: 1.8854193687438965\n",
      "training 98.59%: 0.616. Loss: 1.7394038438796997\n",
      "training 98.66%: 0.616. Loss: 1.6449295282363892\n",
      "training 98.72%: 0.615. Loss: 2.0151872634887695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 98.78%: 0.616. Loss: 1.2889736890792847\n",
      "training 98.85%: 0.616. Loss: 1.5528662204742432\n",
      "training 98.91%: 0.616. Loss: 1.4017584323883057\n",
      "training 98.98%: 0.616. Loss: 1.506514310836792\n",
      "training 99.04%: 0.616. Loss: 1.1576372385025024\n",
      "training 99.10%: 0.616. Loss: 1.2839208841323853\n",
      "training 99.17%: 0.616. Loss: 1.4608560800552368\n",
      "training 99.23%: 0.616. Loss: 1.301050066947937\n",
      "training 99.30%: 0.616. Loss: 1.8953174352645874\n",
      "training 99.36%: 0.616. Loss: 1.9099416732788086\n",
      "training 99.42%: 0.616. Loss: 1.691429615020752\n",
      "training 99.49%: 0.616. Loss: 1.8759970664978027\n",
      "training 99.55%: 0.616. Loss: 1.481203317642212\n",
      "training 99.62%: 0.616. Loss: 1.4492226839065552\n",
      "training 99.68%: 0.616. Loss: 1.4209816455841064\n",
      "training 99.74%: 0.615. Loss: 2.125890016555786\n",
      "training 99.81%: 0.616. Loss: 1.2470927238464355\n",
      "training 99.87%: 0.616. Loss: 1.4684240818023682\n",
      "training 99.94%: 0.616. Loss: 1.596555233001709\n",
      "val 0.00%: 0.578. Loss: 1.691964864730835\n",
      "val 0.64%: 0.586. Loss: 1.6716833114624023\n",
      "val 1.27%: 0.562. Loss: 1.8215347528457642\n",
      "val 1.91%: 0.555. Loss: 1.9964380264282227\n",
      "val 2.55%: 0.559. Loss: 1.674728512763977\n",
      "val 3.18%: 0.581. Loss: 1.1956053972244263\n",
      "val 3.82%: 0.589. Loss: 1.8040825128555298\n",
      "val 4.46%: 0.596. Loss: 1.3848837614059448\n",
      "val 5.10%: 0.595. Loss: 1.7546671628952026\n",
      "val 5.73%: 0.594. Loss: 1.6759963035583496\n",
      "val 6.37%: 0.591. Loss: 1.781496524810791\n",
      "val 7.01%: 0.596. Loss: 1.2533447742462158\n",
      "val 7.64%: 0.593. Loss: 1.886751651763916\n",
      "val 8.28%: 0.592. Loss: 1.7648382186889648\n",
      "val 8.92%: 0.585. Loss: 1.9909073114395142\n",
      "val 9.55%: 0.593. Loss: 1.6906758546829224\n",
      "val 10.19%: 0.584. Loss: 2.1878957748413086\n",
      "val 10.83%: 0.583. Loss: 1.7643346786499023\n",
      "val 11.46%: 0.581. Loss: 1.78538978099823\n",
      "val 12.10%: 0.583. Loss: 1.5098116397857666\n",
      "val 12.74%: 0.581. Loss: 1.8298603296279907\n",
      "val 13.38%: 0.581. Loss: 1.7129647731781006\n",
      "val 14.01%: 0.581. Loss: 1.8149006366729736\n",
      "val 14.65%: 0.581. Loss: 1.4996235370635986\n",
      "val 15.29%: 0.583. Loss: 1.4442600011825562\n",
      "val 15.92%: 0.579. Loss: 1.8359370231628418\n",
      "val 16.56%: 0.580. Loss: 1.65231192111969\n",
      "val 17.20%: 0.584. Loss: 1.4931106567382812\n",
      "val 17.83%: 0.586. Loss: 1.3598308563232422\n",
      "val 18.47%: 0.588. Loss: 1.5622369050979614\n",
      "val 19.11%: 0.590. Loss: 1.488066554069519\n",
      "val 19.75%: 0.587. Loss: 2.2340686321258545\n",
      "val 20.38%: 0.588. Loss: 1.7374789714813232\n",
      "val 21.02%: 0.586. Loss: 1.722261667251587\n",
      "val 21.66%: 0.586. Loss: 1.8024603128433228\n",
      "val 22.29%: 0.584. Loss: 2.074974536895752\n",
      "val 22.93%: 0.584. Loss: 1.8518664836883545\n",
      "val 23.57%: 0.586. Loss: 1.194293737411499\n",
      "val 24.20%: 0.586. Loss: 1.4803141355514526\n",
      "val 24.84%: 0.582. Loss: 2.425588846206665\n",
      "val 25.48%: 0.580. Loss: 2.1652753353118896\n",
      "val 26.11%: 0.580. Loss: 2.0583770275115967\n",
      "val 26.75%: 0.582. Loss: 1.3535593748092651\n",
      "val 27.39%: 0.582. Loss: 1.8316681385040283\n",
      "val 28.03%: 0.578. Loss: 2.3028082847595215\n",
      "val 28.66%: 0.581. Loss: 1.3377511501312256\n",
      "val 29.30%: 0.579. Loss: 2.0804073810577393\n",
      "val 29.94%: 0.579. Loss: 1.7583869695663452\n",
      "val 30.57%: 0.579. Loss: 1.8053570985794067\n",
      "val 31.21%: 0.578. Loss: 1.9849687814712524\n",
      "val 31.85%: 0.578. Loss: 1.8646637201309204\n",
      "val 32.48%: 0.581. Loss: 1.2066370248794556\n",
      "val 33.12%: 0.580. Loss: 1.6779061555862427\n",
      "val 33.76%: 0.581. Loss: 1.3690516948699951\n",
      "val 34.39%: 0.580. Loss: 1.9869377613067627\n",
      "val 35.03%: 0.579. Loss: 1.7049310207366943\n",
      "val 35.67%: 0.578. Loss: 2.0307252407073975\n",
      "val 36.31%: 0.577. Loss: 1.996852159500122\n",
      "val 36.94%: 0.576. Loss: 1.8625471591949463\n",
      "val 37.58%: 0.575. Loss: 1.7988783121109009\n",
      "val 38.22%: 0.575. Loss: 1.5770082473754883\n",
      "val 38.85%: 0.576. Loss: 1.3596173524856567\n",
      "val 39.49%: 0.577. Loss: 1.5953974723815918\n",
      "val 40.13%: 0.578. Loss: 1.6315858364105225\n",
      "val 40.76%: 0.580. Loss: 1.1343071460723877\n",
      "val 41.40%: 0.579. Loss: 1.8482136726379395\n",
      "val 42.04%: 0.577. Loss: 2.505378246307373\n",
      "val 42.68%: 0.578. Loss: 1.601401925086975\n",
      "val 43.31%: 0.578. Loss: 1.8728171586990356\n",
      "val 43.95%: 0.579. Loss: 1.4660553932189941\n",
      "val 44.59%: 0.577. Loss: 1.9509364366531372\n",
      "val 45.22%: 0.577. Loss: 1.9485288858413696\n",
      "val 45.86%: 0.577. Loss: 1.6788867712020874\n",
      "val 46.50%: 0.578. Loss: 1.436887264251709\n",
      "val 47.13%: 0.578. Loss: 1.699002742767334\n",
      "val 47.77%: 0.578. Loss: 1.76912260055542\n",
      "val 48.41%: 0.577. Loss: 1.7793972492218018\n",
      "val 49.04%: 0.577. Loss: 1.5966882705688477\n",
      "val 49.68%: 0.578. Loss: 1.6174445152282715\n",
      "val 50.32%: 0.579. Loss: 1.1611015796661377\n",
      "val 50.96%: 0.579. Loss: 1.4404023885726929\n",
      "val 51.59%: 0.580. Loss: 1.5842152833938599\n",
      "val 52.23%: 0.579. Loss: 2.730191230773926\n",
      "val 52.87%: 0.578. Loss: 1.7733949422836304\n",
      "val 53.50%: 0.578. Loss: 1.6418001651763916\n",
      "val 54.14%: 0.578. Loss: 1.519680380821228\n",
      "val 54.78%: 0.578. Loss: 2.0498063564300537\n",
      "val 55.41%: 0.578. Loss: 2.1251301765441895\n",
      "val 56.05%: 0.578. Loss: 1.979609489440918\n",
      "val 56.69%: 0.578. Loss: 2.0405023097991943\n",
      "val 57.32%: 0.579. Loss: 1.623849868774414\n",
      "val 57.96%: 0.578. Loss: 1.6994602680206299\n",
      "val 58.60%: 0.577. Loss: 1.7922343015670776\n",
      "val 59.24%: 0.578. Loss: 1.817402958869934\n",
      "val 59.87%: 0.577. Loss: 2.034539222717285\n",
      "val 60.51%: 0.577. Loss: 1.6598838567733765\n",
      "val 61.15%: 0.577. Loss: 2.004350423812866\n",
      "val 61.78%: 0.576. Loss: 1.879927635192871\n",
      "val 62.42%: 0.577. Loss: 1.6044280529022217\n",
      "val 63.06%: 0.577. Loss: 1.8044546842575073\n",
      "val 63.69%: 0.576. Loss: 2.140012741088867\n",
      "val 64.33%: 0.576. Loss: 2.1199467182159424\n",
      "val 64.97%: 0.577. Loss: 1.7595691680908203\n",
      "val 65.61%: 0.577. Loss: 1.5954546928405762\n",
      "val 66.24%: 0.576. Loss: 1.6837304830551147\n",
      "val 66.88%: 0.576. Loss: 1.9869556427001953\n",
      "val 67.52%: 0.576. Loss: 1.6132789850234985\n",
      "val 68.15%: 0.574. Loss: 2.5969185829162598\n",
      "val 68.79%: 0.576. Loss: 1.1758546829223633\n",
      "val 69.43%: 0.576. Loss: 1.5918904542922974\n",
      "val 70.06%: 0.575. Loss: 2.0814881324768066\n",
      "val 70.70%: 0.574. Loss: 2.38381028175354\n",
      "val 71.34%: 0.575. Loss: 1.811340093612671\n",
      "val 71.97%: 0.574. Loss: 2.0168941020965576\n",
      "val 72.61%: 0.574. Loss: 1.5661753416061401\n",
      "val 73.25%: 0.574. Loss: 1.8920871019363403\n",
      "val 73.89%: 0.574. Loss: 1.6270043849945068\n",
      "val 74.52%: 0.573. Loss: 1.7984899282455444\n",
      "val 75.16%: 0.574. Loss: 1.376381754875183\n",
      "val 75.80%: 0.575. Loss: 1.1577321290969849\n",
      "val 76.43%: 0.575. Loss: 1.4420183897018433\n",
      "val 77.07%: 0.576. Loss: 1.8264669179916382\n",
      "val 77.71%: 0.576. Loss: 1.8378978967666626\n",
      "val 78.34%: 0.576. Loss: 1.5533325672149658\n",
      "val 78.98%: 0.577. Loss: 1.5257667303085327\n",
      "val 79.62%: 0.576. Loss: 1.7926814556121826\n",
      "val 80.25%: 0.576. Loss: 1.8405098915100098\n",
      "val 80.89%: 0.576. Loss: 1.5671508312225342\n",
      "val 81.53%: 0.576. Loss: 1.5368356704711914\n",
      "val 82.17%: 0.575. Loss: 2.262033462524414\n",
      "val 82.80%: 0.576. Loss: 1.1505225896835327\n",
      "val 83.44%: 0.576. Loss: 1.5896891355514526\n",
      "val 84.08%: 0.576. Loss: 1.6913104057312012\n",
      "val 84.71%: 0.577. Loss: 1.3499969244003296\n",
      "val 85.35%: 0.576. Loss: 2.1293227672576904\n",
      "val 85.99%: 0.575. Loss: 1.9184468984603882\n",
      "val 86.62%: 0.576. Loss: 1.6677148342132568\n",
      "val 87.26%: 0.576. Loss: 1.2941644191741943\n",
      "val 87.90%: 0.577. Loss: 1.280259609222412\n",
      "val 88.54%: 0.577. Loss: 1.9833606481552124\n",
      "val 89.17%: 0.577. Loss: 1.619848370552063\n",
      "val 89.81%: 0.577. Loss: 1.6624715328216553\n",
      "val 90.45%: 0.576. Loss: 2.267979860305786\n",
      "val 91.08%: 0.576. Loss: 1.5052745342254639\n",
      "val 91.72%: 0.576. Loss: 1.5872441530227661\n",
      "val 92.36%: 0.576. Loss: 1.5525568723678589\n",
      "val 92.99%: 0.576. Loss: 1.9083892107009888\n",
      "val 93.63%: 0.577. Loss: 1.433111548423767\n",
      "val 94.27%: 0.577. Loss: 1.4339619874954224\n",
      "val 94.90%: 0.576. Loss: 2.105163812637329\n",
      "val 95.54%: 0.577. Loss: 2.1812729835510254\n",
      "val 96.18%: 0.577. Loss: 1.4766701459884644\n",
      "val 96.82%: 0.576. Loss: 1.8815654516220093\n",
      "val 97.45%: 0.576. Loss: 1.6460775136947632\n",
      "val 98.09%: 0.576. Loss: 1.3477429151535034\n",
      "val 98.73%: 0.576. Loss: 1.2944364547729492\n",
      "val 99.36%: 0.576. Loss: 1.40403413772583\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "# Create a simple model\n",
    "model = resnet18\n",
    "model.to(device)\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    model.train()\n",
    "    train_total, train_correct = 0,0\n",
    "    for idx, (inputs, targets) in enumerate(train_loader):\n",
    "        \n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optim.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_total += targets.size(0)\n",
    "        train_correct += predicted.eq(targets).sum().item()\n",
    "        print(f'training {100 * idx / len(train_loader):.2f}%: {train_correct / train_total:.3f}. Loss: {loss.item()}')\n",
    "    \n",
    "    torch.save({\n",
    "        'net': model.state_dict(),\n",
    "    }, 'latest.pt')\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss_epoch = 0\n",
    "        val_total, val_correct = 0,0\n",
    "        for idx, (inputs, targets) in enumerate(val_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss_epoch += loss.item()\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += targets.size(0)\n",
    "            val_correct += predicted.eq(targets).sum().item()\n",
    "            print(f'val {100 * idx / len(val_loader):.2f}%: {val_correct / val_total:.3f}. Loss: {loss.item()}')\n",
    "            \n",
    "    val_losses.append(val_loss_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26f32706c70>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26f14d7eaf0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
